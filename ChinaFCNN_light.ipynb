{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvpNHOs_nTQK",
    "outputId": "58e5e73c-d790-40a6-a1dc-1f6638a75f55"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')\n",
    "\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDXvdYFuLYSI",
    "outputId": "db9c1dcc-d2d2-450c-bab9-29f775f571d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hy-tmp\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "home_dir = '/content/gdrive/My Drive/AChina' \n",
    "home_dir = '/hy-tmp'\n",
    "os.chdir(home_dir)\n",
    "!pwd\n",
    "\n",
    "!pip install tqdm\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WPwRIbsMnaq8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "# os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYbhRWaxneDl",
    "outputId": "c79dccdb-c661-4f1c-ca13-a14d7bd2c1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.22.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.0+cu113)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (1.8.6)\n",
      "Requirement already satisfied: pytorch_forecasting in /usr/local/lib/python3.8/dist-packages (0.10.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.22.3)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.11.0)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2.5.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (1.4.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (3.5.2)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.24 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (1.1.1)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (0.13.5)\n",
      "Requirement already satisfied: optuna<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (2.10.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.9.0)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.4.45)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.1.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (3.1.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (1.4.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (4.34.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (9.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pytorch_forecasting) (0.5.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.2->statsmodels->pytorch_forecasting) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.0.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.2.4)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.12.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (5.8.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.5.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (3.5.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.4.2)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (3.8.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (5.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.8/dist-packages (12.6.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from rich) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich) (4.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision\n",
    "# !pip install pytorch_lightning\n",
    "# !pip install pytorch_forecasting\n",
    "\n",
    "# !pip install torch -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install pytorch-forecasting\n",
    "\n",
    "!pip install scipy\n",
    "!pip install torch pytorch-lightning pytorch_forecasting\n",
    "!pip install rich\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAPE, SMAPE, PoissonLoss, QuantileLoss\n",
    "# from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "65_fJ6MIbncZ",
    "outputId": "06e9c0ab-8d58-480b-86d1-4ca275159e4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>sownareas</th>\n",
       "      <th>yieldvals</th>\n",
       "      <th>county</th>\n",
       "      <th>bands</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>bin0</th>\n",
       "      <th>bin1</th>\n",
       "      <th>...</th>\n",
       "      <th>bin502</th>\n",
       "      <th>bin503</th>\n",
       "      <th>bin504</th>\n",
       "      <th>bin505</th>\n",
       "      <th>bin506</th>\n",
       "      <th>bin507</th>\n",
       "      <th>bin508</th>\n",
       "      <th>bin509</th>\n",
       "      <th>bin510</th>\n",
       "      <th>bin511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>band_5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  years    yield  sownareas  yieldvals  county   bands  \\\n",
       "0            0   2003  0.61295      75.21       46.1       0  band_0   \n",
       "1            1   2003  0.61295      75.21       46.1       0  band_1   \n",
       "2            2   2003  0.61295      75.21       46.1       0  band_2   \n",
       "3            3   2003  0.61295      75.21       46.1       0  band_3   \n",
       "4            4   2003  0.61295      75.21       46.1       0  band_4   \n",
       "5            5   2003  0.61295      75.21       46.1       0  band_5   \n",
       "6            6   2003  0.61295      75.21       46.1       0  band_6   \n",
       "7            7   2003  0.61295      75.21       46.1       0  band_7   \n",
       "8            8   2003  0.61295      75.21       46.1       0  band_8   \n",
       "9            9   2003  0.61295      75.21       46.1       0  band_0   \n",
       "10          10   2003  0.61295      75.21       46.1       0  band_1   \n",
       "11          11   2003  0.61295      75.21       46.1       0  band_2   \n",
       "12          12   2003  0.61295      75.21       46.1       0  band_3   \n",
       "13          13   2003  0.61295      75.21       46.1       0  band_4   \n",
       "14          14   2003  0.61295      75.21       46.1       0  band_5   \n",
       "\n",
       "    time_idx  bin0  bin1  ...    bin502    bin503    bin504    bin505  \\\n",
       "0          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8          0   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9          1   0.0   0.0  ...  0.001077  0.000833  0.001126  0.000098   \n",
       "10         1   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11         1   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "12         1   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "13         1   0.0   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "14         1   0.0   0.0  ...  0.000097  0.000484  0.000242  0.000339   \n",
       "\n",
       "      bin506    bin507    bin508    bin509    bin510    bin511  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000784  0.000881  0.000979  0.000441  0.000294  0.000196  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000048  0.000000  0.000145  0.000194  0.000000  0.000000  \n",
       "\n",
       "[15 rows x 520 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('corn_china_pandas.csv')  # encoding= 'unicode_escape')\n",
    "\n",
    "data[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TOncsJYonfF_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>sownareas</th>\n",
       "      <th>yieldvals</th>\n",
       "      <th>county</th>\n",
       "      <th>MODIS</th>\n",
       "      <th>bands</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>bin0</th>\n",
       "      <th>...</th>\n",
       "      <th>bin502</th>\n",
       "      <th>bin503</th>\n",
       "      <th>bin504</th>\n",
       "      <th>bin505</th>\n",
       "      <th>bin506</th>\n",
       "      <th>bin507</th>\n",
       "      <th>bin508</th>\n",
       "      <th>bin509</th>\n",
       "      <th>bin510</th>\n",
       "      <th>bin511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.10</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.10</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.10</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.10</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.10</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91867</th>\n",
       "      <td>8347</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.701433</td>\n",
       "      <td>306.33</td>\n",
       "      <td>214.87</td>\n",
       "      <td>29</td>\n",
       "      <td>MOD_31</td>\n",
       "      <td>band_4</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91868</th>\n",
       "      <td>8348</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.701433</td>\n",
       "      <td>306.33</td>\n",
       "      <td>214.87</td>\n",
       "      <td>29</td>\n",
       "      <td>MOD_31</td>\n",
       "      <td>band_5</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91869</th>\n",
       "      <td>8349</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.701433</td>\n",
       "      <td>306.33</td>\n",
       "      <td>214.87</td>\n",
       "      <td>29</td>\n",
       "      <td>MOD_31</td>\n",
       "      <td>band_6</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91870</th>\n",
       "      <td>8350</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.701433</td>\n",
       "      <td>306.33</td>\n",
       "      <td>214.87</td>\n",
       "      <td>29</td>\n",
       "      <td>MOD_31</td>\n",
       "      <td>band_7</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91871</th>\n",
       "      <td>8351</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.701433</td>\n",
       "      <td>306.33</td>\n",
       "      <td>214.87</td>\n",
       "      <td>29</td>\n",
       "      <td>MOD_31</td>\n",
       "      <td>band_8</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91872 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  years     yield  sownareas  yieldvals  county   MODIS  \\\n",
       "0               0   2003  0.612950      75.21      46.10       0   MOD_0   \n",
       "1               1   2003  0.612950      75.21      46.10       0   MOD_0   \n",
       "2               2   2003  0.612950      75.21      46.10       0   MOD_0   \n",
       "3               3   2003  0.612950      75.21      46.10       0   MOD_0   \n",
       "4               4   2003  0.612950      75.21      46.10       0   MOD_0   \n",
       "...           ...    ...       ...        ...        ...     ...     ...   \n",
       "91867        8347   2017  0.701433     306.33     214.87      29  MOD_31   \n",
       "91868        8348   2017  0.701433     306.33     214.87      29  MOD_31   \n",
       "91869        8349   2017  0.701433     306.33     214.87      29  MOD_31   \n",
       "91870        8350   2017  0.701433     306.33     214.87      29  MOD_31   \n",
       "91871        8351   2017  0.701433     306.33     214.87      29  MOD_31   \n",
       "\n",
       "        bands  time_idx      bin0  ...  bin502  bin503  bin504  bin505  \\\n",
       "0      band_0         0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "1      band_1         0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "2      band_2         0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "3      band_3         0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "4      band_4         0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "...       ...       ...       ...  ...     ...     ...     ...     ...   \n",
       "91867  band_4        31  0.000099  ...     0.0     0.0     0.0     0.0   \n",
       "91868  band_5        31  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "91869  band_6        31  0.000049  ...     0.0     0.0     0.0     0.0   \n",
       "91870  band_7        31  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "91871  band_8        31  0.000000  ...     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       bin506  bin507  bin508  bin509  bin510  bin511  \n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "91867     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "91868     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "91869     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "91870     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "91871     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[91872 rows x 521 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = ['MOD_' + str(time_idx) for time_idx in data['time_idx']]\n",
    "\n",
    "# df = data.copy()\n",
    "\n",
    "data.insert(6, \"MODIS\", mod, True)\n",
    "\n",
    "data\n",
    "\n",
    "# print(mod)\n",
    "\n",
    "# years = [x for x in range(2003, 2019)]\n",
    "\n",
    "# data.rename(columns={'time_idx' : 'time'}, inplace=True)  \n",
    "\n",
    "# # data[5:15]  \n",
    "# data.insert(1, \"time_idx\", data['years'])  \n",
    "# # df = data.assign(time_dx = data.time * 10)\n",
    "\n",
    "# time_idx = 0\n",
    "# for year in years:\n",
    "#     data['time_idx'] = data['time_idx'].replace([year], time_idx)\n",
    "#     time_idx = time_idx + 1\n",
    "    \n",
    "# data['years'] = data['years'].astype(str)\n",
    "# data['county'] = data['county'].astype(str)\n",
    "# data['time'] = data['time'].astype(str)\n",
    "\n",
    "# dff = data[ data['years'] == '2018' ]\n",
    "# dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "F-uXD_srqwLW",
    "outputId": "8a8a0424-2e67-4dd2-be62-b6b0bf46bfc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>sownareas</th>\n",
       "      <th>yieldvals</th>\n",
       "      <th>county</th>\n",
       "      <th>MODIS</th>\n",
       "      <th>bands</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>bin0</th>\n",
       "      <th>...</th>\n",
       "      <th>bin502</th>\n",
       "      <th>bin503</th>\n",
       "      <th>bin504</th>\n",
       "      <th>bin505</th>\n",
       "      <th>bin506</th>\n",
       "      <th>bin507</th>\n",
       "      <th>bin508</th>\n",
       "      <th>bin509</th>\n",
       "      <th>bin510</th>\n",
       "      <th>bin511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>75.21</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0</td>\n",
       "      <td>MOD_0</td>\n",
       "      <td>band_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 years    yield  sownareas  yieldvals county  MODIS   bands  \\\n",
       "0           0  2003  0.61295      75.21       46.1      0  MOD_0  band_0   \n",
       "1           1  2003  0.61295      75.21       46.1      0  MOD_0  band_1   \n",
       "2           2  2003  0.61295      75.21       46.1      0  MOD_0  band_2   \n",
       "3           3  2003  0.61295      75.21       46.1      0  MOD_0  band_3   \n",
       "4           4  2003  0.61295      75.21       46.1      0  MOD_0  band_4   \n",
       "\n",
       "   time_idx  bin0  ...  bin502  bin503  bin504  bin505  bin506  bin507  \\\n",
       "0         0   0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0   0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0   0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0   0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0   0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   bin508  bin509  bin510  bin511  \n",
       "0     0.0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['years'] = data['years'].astype(str)\n",
    "data['county'] = data['county'].astype(str)\n",
    "data['time_idx'] = data['time_idx'].astype(int)\n",
    "data.head()\n",
    "# print(type(data['bin500'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "LL4gooLRnkdv",
    "outputId": "cb1d012b-c336-4683-d2d9-f454d61c1cb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>yield</th>\n",
       "      <th>sownareas</th>\n",
       "      <th>yieldvals</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>bin0</th>\n",
       "      <th>bin1</th>\n",
       "      <th>bin2</th>\n",
       "      <th>bin3</th>\n",
       "      <th>bin4</th>\n",
       "      <th>...</th>\n",
       "      <th>bin502</th>\n",
       "      <th>bin503</th>\n",
       "      <th>bin504</th>\n",
       "      <th>bin505</th>\n",
       "      <th>bin506</th>\n",
       "      <th>bin507</th>\n",
       "      <th>bin508</th>\n",
       "      <th>bin509</th>\n",
       "      <th>bin510</th>\n",
       "      <th>bin511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "      <td>91872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4175.500000</td>\n",
       "      <td>0.517953</td>\n",
       "      <td>1054.189060</td>\n",
       "      <td>564.198213</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2411.027829</td>\n",
       "      <td>0.106652</td>\n",
       "      <td>1126.086187</td>\n",
       "      <td>659.807771</td>\n",
       "      <td>9.233143</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276526</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2087.750000</td>\n",
       "      <td>0.438383</td>\n",
       "      <td>192.340000</td>\n",
       "      <td>116.940000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4175.500000</td>\n",
       "      <td>0.518895</td>\n",
       "      <td>577.010000</td>\n",
       "      <td>263.520000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6263.250000</td>\n",
       "      <td>0.574336</td>\n",
       "      <td>1559.340000</td>\n",
       "      <td>736.100000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8351.000000</td>\n",
       "      <td>0.855448</td>\n",
       "      <td>4210.460000</td>\n",
       "      <td>2662.150000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.027569</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         yield     sownareas     yieldvals      time_idx  \\\n",
       "count  91872.000000  91872.000000  91872.000000  91872.000000  91872.000000   \n",
       "mean    4175.500000      0.517953   1054.189060    564.198213     15.500000   \n",
       "std     2411.027829      0.106652   1126.086187    659.807771      9.233143   \n",
       "min        0.000000      0.276526      1.810000      1.250000      0.000000   \n",
       "25%     2087.750000      0.438383    192.340000    116.940000      7.750000   \n",
       "50%     4175.500000      0.518895    577.010000    263.520000     15.500000   \n",
       "75%     6263.250000      0.574336   1559.340000    736.100000     23.250000   \n",
       "max     8351.000000      0.855448   4210.460000   2662.150000     31.000000   \n",
       "\n",
       "               bin0          bin1          bin2          bin3          bin4  \\\n",
       "count  91872.000000  91872.000000  91872.000000  91872.000000  91872.000000   \n",
       "mean       0.000733      0.000152      0.000182      0.000171      0.000206   \n",
       "std        0.003606      0.000685      0.000838      0.000762      0.000930   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000059      0.000020      0.000023      0.000023      0.000026   \n",
       "max        0.111111      0.025479      0.027569      0.024157      0.028934   \n",
       "\n",
       "       ...        bin502        bin503        bin504        bin505  \\\n",
       "count  ...  91872.000000  91872.000000  91872.000000  91872.000000   \n",
       "mean   ...      0.000247      0.000256      0.000257      0.000240   \n",
       "std    ...      0.000711      0.000745      0.000783      0.000701   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000148      0.000156      0.000151      0.000142   \n",
       "max    ...      0.026096      0.040541      0.054054      0.024242   \n",
       "\n",
       "             bin506        bin507        bin508        bin509        bin510  \\\n",
       "count  91872.000000  91872.000000  91872.000000  91872.000000  91872.000000   \n",
       "mean       0.000252      0.000254      0.000228      0.000244      0.000231   \n",
       "std        0.003375      0.001853      0.000673      0.000899      0.000685   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000141      0.000144      0.000127      0.000135      0.000129   \n",
       "max        1.000000      0.500000      0.021858      0.157895      0.032663   \n",
       "\n",
       "             bin511  \n",
       "count  91872.000000  \n",
       "mean       0.000254  \n",
       "std        0.000792  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000141  \n",
       "max        0.066667  \n",
       "\n",
       "[8 rows x 517 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class FullyConnectedModule(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, n_hidden_layers: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # input layer\n",
    "        module_list = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "        # hidden layers\n",
    "        for _ in range(n_hidden_layers):\n",
    "            module_list.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "        # output layer\n",
    "        module_list.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.sequential = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x of shape: batch_size x n_timesteps_in\n",
    "        # output of shape batch_size x n_timesteps_out\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "# test that network works as intended\n",
    "network = FullyConnectedModule(input_size=5, output_size=2, hidden_size=10, n_hidden_layers=2)\n",
    "x = torch.rand(20, 5)\n",
    "network(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from pytorch_forecasting.models.nn import MultiEmbedding\n",
    "from pytorch_forecasting.models import BaseModelWithCovariates\n",
    "\n",
    "class FullyConnectedModelWithCovariates(BaseModelWithCovariates):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        x_reals: List[str],\n",
    "        x_categoricals: List[str],\n",
    "        embedding_sizes: Dict[str, Tuple[int, int]],\n",
    "        embedding_labels: Dict[str, List[str]],\n",
    "        static_categoricals: List[str],\n",
    "        static_reals: List[str],\n",
    "        time_varying_categoricals_encoder: List[str],\n",
    "        time_varying_categoricals_decoder: List[str],\n",
    "        time_varying_reals_encoder: List[str],\n",
    "        time_varying_reals_decoder: List[str],\n",
    "        embedding_paddings: List[str],\n",
    "        categorical_groups: Dict[str, List[str]],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # create embedder - can be fed with x[\"encoder_cat\"] or x[\"decoder_cat\"] and will return\n",
    "        # dictionary of category names mapped to embeddings\n",
    "        self.input_embeddings = MultiEmbedding(\n",
    "            embedding_sizes=self.hparams.embedding_sizes,\n",
    "            categorical_groups=self.hparams.categorical_groups,\n",
    "            embedding_paddings=self.hparams.embedding_paddings,\n",
    "            x_categoricals=self.hparams.x_categoricals,\n",
    "            max_embedding_size=self.hparams.hidden_size,\n",
    "        )\n",
    "        \n",
    "        # calculate the size of all concatenated embeddings + continous variables\n",
    "        n_features = sum(\n",
    "            embedding_size for classes_size, embedding_size in self.hparams.embedding_sizes.values()\n",
    "        ) + len(self.reals)\n",
    "\n",
    "        # create network that will be fed with continious variables and embeddings\n",
    "        self.network = FullyConnectedModule(\n",
    "            input_size=self.hparams.input_size * n_features,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        batch_size = x[\"encoder_lengths\"].size(0)\n",
    "        embeddings = self.input_embeddings(x[\"encoder_cat\"])  # returns dictionary with embedding tensors\n",
    "        network_input = torch.cat(\n",
    "            [x[\"encoder_cont\"]]\n",
    "            + [\n",
    "                emb\n",
    "                for name, emb in embeddings.items()\n",
    "                if name in self.encoder_variables or name in self.static_variables\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        prediction = self.network(network_input.view(batch_size, -1))\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction.\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(kwargs)  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert dataset.max_prediction_length == dataset.min_prediction_length, \"Decoder only supports a fixed length\"\n",
    "        assert dataset.min_encoder_length == dataset.max_encoder_length, \"Encoder only supports a fixed length\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categorical_groups\":                {}\n",
       "\"embedding_labels\":                  {}\n",
       "\"embedding_paddings\":                []\n",
       "\"embedding_sizes\":                   {}\n",
       "\"hidden_size\":                       50\n",
       "\"input_size\":                        8\n",
       "\"learning_rate\":                     0.001\n",
       "\"log_gradient_flow\":                 False\n",
       "\"log_interval\":                      -1\n",
       "\"log_val_interval\":                  -1\n",
       "\"logging_metrics\":                   ModuleList()\n",
       "\"loss\":                              SMAPE()\n",
       "\"monotone_constaints\":               {}\n",
       "\"n_hidden_layers\":                   10\n",
       "\"optimizer\":                         ranger\n",
       "\"optimizer_params\":                  None\n",
       "\"output_size\":                       1\n",
       "\"output_transformer\":                GroupNormalizer(\n",
       "\tmethod='standard',\n",
       "\tgroups=[],\n",
       "\tcenter=True,\n",
       "\tscale_by_group=False,\n",
       "\ttransformation='relu',\n",
       "\tmethod_kwargs={}\n",
       ")\n",
       "\"reduce_on_plateau_min_lr\":          1e-05\n",
       "\"reduce_on_plateau_patience\":        1000\n",
       "\"reduce_on_plateau_reduction\":       2.0\n",
       "\"static_categoricals\":               []\n",
       "\"static_reals\":                      []\n",
       "\"time_varying_categoricals_decoder\": []\n",
       "\"time_varying_categoricals_encoder\": []\n",
       "\"time_varying_reals_decoder\":        ['sownareas']\n",
       "\"time_varying_reals_encoder\":        ['sownareas', 'bin0', 'bin1', 'bin2', 'bin3', 'bin4', 'bin5', 'bin6', 'bin7', 'bin8', 'bin9', 'bin10', 'bin11', 'bin12', 'bin13', 'bin14', 'bin15', 'bin16', 'bin17', 'bin18', 'bin19', 'bin20', 'bin21', 'bin22', 'bin23', 'bin24', 'bin25', 'bin26', 'bin27', 'bin28', 'bin29', 'bin30', 'bin31', 'bin32', 'bin33', 'bin34', 'bin35', 'bin36', 'bin37', 'bin38', 'bin39', 'bin40', 'bin41', 'bin42', 'bin43', 'bin44', 'bin45', 'bin46', 'bin47', 'bin48', 'bin49', 'bin50', 'bin51', 'bin52', 'bin53', 'bin54', 'bin55', 'bin56', 'bin57', 'bin58', 'bin59', 'bin60', 'bin61', 'bin62', 'bin63', 'bin64', 'bin65', 'bin66', 'bin67', 'bin68', 'bin69', 'bin70', 'bin71', 'bin72', 'bin73', 'bin74', 'bin75', 'bin76', 'bin77', 'bin78', 'bin79', 'bin80', 'bin81', 'bin82', 'bin83', 'bin84', 'bin85', 'bin86', 'bin87', 'bin88', 'bin89', 'bin90', 'bin91', 'bin92', 'bin93', 'bin94', 'bin95', 'bin96', 'bin97', 'bin98', 'bin99', 'bin100', 'bin101', 'bin102', 'bin103', 'bin104', 'bin105', 'bin106', 'bin107', 'bin108', 'bin109', 'bin110', 'bin111', 'bin112', 'bin113', 'bin114', 'bin115', 'bin116', 'bin117', 'bin118', 'bin119', 'bin120', 'bin121', 'bin122', 'bin123', 'bin124', 'bin125', 'bin126', 'bin127', 'bin128', 'bin129', 'bin130', 'bin131', 'bin132', 'bin133', 'bin134', 'bin135', 'bin136', 'bin137', 'bin138', 'bin139', 'bin140', 'bin141', 'bin142', 'bin143', 'bin144', 'bin145', 'bin146', 'bin147', 'bin148', 'bin149', 'bin150', 'bin151', 'bin152', 'bin153', 'bin154', 'bin155', 'bin156', 'bin157', 'bin158', 'bin159', 'bin160', 'bin161', 'bin162', 'bin163', 'bin164', 'bin165', 'bin166', 'bin167', 'bin168', 'bin169', 'bin170', 'bin171', 'bin172', 'bin173', 'bin174', 'bin175', 'bin176', 'bin177', 'bin178', 'bin179', 'bin180', 'bin181', 'bin182', 'bin183', 'bin184', 'bin185', 'bin186', 'bin187', 'bin188', 'bin189', 'bin190', 'bin191', 'bin192', 'bin193', 'bin194', 'bin195', 'bin196', 'bin197', 'bin198', 'bin199', 'bin200', 'bin201', 'bin202', 'bin203', 'bin204', 'bin205', 'bin206', 'bin207', 'bin208', 'bin209', 'bin210', 'bin211', 'bin212', 'bin213', 'bin214', 'bin215', 'bin216', 'bin217', 'bin218', 'bin219', 'bin220', 'bin221', 'bin222', 'bin223', 'bin224', 'bin225', 'bin226', 'bin227', 'bin228', 'bin229', 'bin230', 'bin231', 'bin232', 'bin233', 'bin234', 'bin235', 'bin236', 'bin237', 'bin238', 'bin239', 'bin240', 'bin241', 'bin242', 'bin243', 'bin244', 'bin245', 'bin246', 'bin247', 'bin248', 'bin249', 'bin250', 'bin251', 'bin252', 'bin253', 'bin254', 'bin255', 'bin256', 'bin257', 'bin258', 'bin259', 'bin260', 'bin261', 'bin262', 'bin263', 'bin264', 'bin265', 'bin266', 'bin267', 'bin268', 'bin269', 'bin270', 'bin271', 'bin272', 'bin273', 'bin274', 'bin275', 'bin276', 'bin277', 'bin278', 'bin279', 'bin280', 'bin281', 'bin282', 'bin283', 'bin284', 'bin285', 'bin286', 'bin287', 'bin288', 'bin289', 'bin290', 'bin291', 'bin292', 'bin293', 'bin294', 'bin295', 'bin296', 'bin297', 'bin298', 'bin299', 'bin300', 'bin301', 'bin302', 'bin303', 'bin304', 'bin305', 'bin306', 'bin307', 'bin308', 'bin309', 'bin310', 'bin311', 'bin312', 'bin313', 'bin314', 'bin315', 'bin316', 'bin317', 'bin318', 'bin319', 'bin320', 'bin321', 'bin322', 'bin323', 'bin324', 'bin325', 'bin326', 'bin327', 'bin328', 'bin329', 'bin330', 'bin331', 'bin332', 'bin333', 'bin334', 'bin335', 'bin336', 'bin337', 'bin338', 'bin339', 'bin340', 'bin341', 'bin342', 'bin343', 'bin344', 'bin345', 'bin346', 'bin347', 'bin348', 'bin349', 'bin350', 'bin351', 'bin352', 'bin353', 'bin354', 'bin355', 'bin356', 'bin357', 'bin358', 'bin359', 'bin360', 'bin361', 'bin362', 'bin363', 'bin364', 'bin365', 'bin366', 'bin367', 'bin368', 'bin369', 'bin370', 'bin371', 'bin372', 'bin373', 'bin374', 'bin375', 'bin376', 'bin377', 'bin378', 'bin379', 'bin380', 'bin381', 'bin382', 'bin383', 'bin384', 'bin385', 'bin386', 'bin387', 'bin388', 'bin389', 'bin390', 'bin391', 'bin392', 'bin393', 'bin394', 'bin395', 'bin396', 'bin397', 'bin398', 'bin399', 'bin400', 'bin401', 'bin402', 'bin403', 'bin404', 'bin405', 'bin406', 'bin407', 'bin408', 'bin409', 'bin410', 'bin411', 'bin412', 'bin413', 'bin414', 'bin415', 'bin416', 'bin417', 'bin418', 'bin419', 'bin420', 'bin421', 'bin422', 'bin423', 'bin424', 'bin425', 'bin426', 'bin427', 'bin428', 'bin429', 'bin430', 'bin431', 'bin432', 'bin433', 'bin434', 'bin435', 'bin436', 'bin437', 'bin438', 'bin439', 'bin440', 'bin441', 'bin442', 'bin443', 'bin444', 'bin445', 'bin446', 'bin447', 'bin448', 'bin449', 'bin450', 'bin451', 'bin452', 'bin453', 'bin454', 'bin455', 'bin456', 'bin457', 'bin458', 'bin459', 'bin460', 'bin461', 'bin462', 'bin463', 'bin464', 'bin465', 'bin466', 'bin467', 'bin468', 'bin469', 'bin470', 'bin471', 'bin472', 'bin473', 'bin474', 'bin475', 'bin476', 'bin477', 'bin478', 'bin479', 'bin480', 'bin481', 'bin482', 'bin483', 'bin484', 'bin485', 'bin486', 'bin487', 'bin488', 'bin489', 'bin490', 'bin491', 'bin492', 'bin493', 'bin494', 'bin495', 'bin496', 'bin497', 'bin498', 'bin499', 'bin500', 'bin501', 'bin502', 'bin503', 'bin504', 'bin505', 'bin506', 'bin507', 'bin508', 'bin509', 'bin510', 'bin511']\n",
       "\"weight_decay\":                      0.0\n",
       "\"x_categoricals\":                    []\n",
       "\"x_reals\":                           ['sownareas', 'bin0', 'bin1', 'bin2', 'bin3', 'bin4', 'bin5', 'bin6', 'bin7', 'bin8', 'bin9', 'bin10', 'bin11', 'bin12', 'bin13', 'bin14', 'bin15', 'bin16', 'bin17', 'bin18', 'bin19', 'bin20', 'bin21', 'bin22', 'bin23', 'bin24', 'bin25', 'bin26', 'bin27', 'bin28', 'bin29', 'bin30', 'bin31', 'bin32', 'bin33', 'bin34', 'bin35', 'bin36', 'bin37', 'bin38', 'bin39', 'bin40', 'bin41', 'bin42', 'bin43', 'bin44', 'bin45', 'bin46', 'bin47', 'bin48', 'bin49', 'bin50', 'bin51', 'bin52', 'bin53', 'bin54', 'bin55', 'bin56', 'bin57', 'bin58', 'bin59', 'bin60', 'bin61', 'bin62', 'bin63', 'bin64', 'bin65', 'bin66', 'bin67', 'bin68', 'bin69', 'bin70', 'bin71', 'bin72', 'bin73', 'bin74', 'bin75', 'bin76', 'bin77', 'bin78', 'bin79', 'bin80', 'bin81', 'bin82', 'bin83', 'bin84', 'bin85', 'bin86', 'bin87', 'bin88', 'bin89', 'bin90', 'bin91', 'bin92', 'bin93', 'bin94', 'bin95', 'bin96', 'bin97', 'bin98', 'bin99', 'bin100', 'bin101', 'bin102', 'bin103', 'bin104', 'bin105', 'bin106', 'bin107', 'bin108', 'bin109', 'bin110', 'bin111', 'bin112', 'bin113', 'bin114', 'bin115', 'bin116', 'bin117', 'bin118', 'bin119', 'bin120', 'bin121', 'bin122', 'bin123', 'bin124', 'bin125', 'bin126', 'bin127', 'bin128', 'bin129', 'bin130', 'bin131', 'bin132', 'bin133', 'bin134', 'bin135', 'bin136', 'bin137', 'bin138', 'bin139', 'bin140', 'bin141', 'bin142', 'bin143', 'bin144', 'bin145', 'bin146', 'bin147', 'bin148', 'bin149', 'bin150', 'bin151', 'bin152', 'bin153', 'bin154', 'bin155', 'bin156', 'bin157', 'bin158', 'bin159', 'bin160', 'bin161', 'bin162', 'bin163', 'bin164', 'bin165', 'bin166', 'bin167', 'bin168', 'bin169', 'bin170', 'bin171', 'bin172', 'bin173', 'bin174', 'bin175', 'bin176', 'bin177', 'bin178', 'bin179', 'bin180', 'bin181', 'bin182', 'bin183', 'bin184', 'bin185', 'bin186', 'bin187', 'bin188', 'bin189', 'bin190', 'bin191', 'bin192', 'bin193', 'bin194', 'bin195', 'bin196', 'bin197', 'bin198', 'bin199', 'bin200', 'bin201', 'bin202', 'bin203', 'bin204', 'bin205', 'bin206', 'bin207', 'bin208', 'bin209', 'bin210', 'bin211', 'bin212', 'bin213', 'bin214', 'bin215', 'bin216', 'bin217', 'bin218', 'bin219', 'bin220', 'bin221', 'bin222', 'bin223', 'bin224', 'bin225', 'bin226', 'bin227', 'bin228', 'bin229', 'bin230', 'bin231', 'bin232', 'bin233', 'bin234', 'bin235', 'bin236', 'bin237', 'bin238', 'bin239', 'bin240', 'bin241', 'bin242', 'bin243', 'bin244', 'bin245', 'bin246', 'bin247', 'bin248', 'bin249', 'bin250', 'bin251', 'bin252', 'bin253', 'bin254', 'bin255', 'bin256', 'bin257', 'bin258', 'bin259', 'bin260', 'bin261', 'bin262', 'bin263', 'bin264', 'bin265', 'bin266', 'bin267', 'bin268', 'bin269', 'bin270', 'bin271', 'bin272', 'bin273', 'bin274', 'bin275', 'bin276', 'bin277', 'bin278', 'bin279', 'bin280', 'bin281', 'bin282', 'bin283', 'bin284', 'bin285', 'bin286', 'bin287', 'bin288', 'bin289', 'bin290', 'bin291', 'bin292', 'bin293', 'bin294', 'bin295', 'bin296', 'bin297', 'bin298', 'bin299', 'bin300', 'bin301', 'bin302', 'bin303', 'bin304', 'bin305', 'bin306', 'bin307', 'bin308', 'bin309', 'bin310', 'bin311', 'bin312', 'bin313', 'bin314', 'bin315', 'bin316', 'bin317', 'bin318', 'bin319', 'bin320', 'bin321', 'bin322', 'bin323', 'bin324', 'bin325', 'bin326', 'bin327', 'bin328', 'bin329', 'bin330', 'bin331', 'bin332', 'bin333', 'bin334', 'bin335', 'bin336', 'bin337', 'bin338', 'bin339', 'bin340', 'bin341', 'bin342', 'bin343', 'bin344', 'bin345', 'bin346', 'bin347', 'bin348', 'bin349', 'bin350', 'bin351', 'bin352', 'bin353', 'bin354', 'bin355', 'bin356', 'bin357', 'bin358', 'bin359', 'bin360', 'bin361', 'bin362', 'bin363', 'bin364', 'bin365', 'bin366', 'bin367', 'bin368', 'bin369', 'bin370', 'bin371', 'bin372', 'bin373', 'bin374', 'bin375', 'bin376', 'bin377', 'bin378', 'bin379', 'bin380', 'bin381', 'bin382', 'bin383', 'bin384', 'bin385', 'bin386', 'bin387', 'bin388', 'bin389', 'bin390', 'bin391', 'bin392', 'bin393', 'bin394', 'bin395', 'bin396', 'bin397', 'bin398', 'bin399', 'bin400', 'bin401', 'bin402', 'bin403', 'bin404', 'bin405', 'bin406', 'bin407', 'bin408', 'bin409', 'bin410', 'bin411', 'bin412', 'bin413', 'bin414', 'bin415', 'bin416', 'bin417', 'bin418', 'bin419', 'bin420', 'bin421', 'bin422', 'bin423', 'bin424', 'bin425', 'bin426', 'bin427', 'bin428', 'bin429', 'bin430', 'bin431', 'bin432', 'bin433', 'bin434', 'bin435', 'bin436', 'bin437', 'bin438', 'bin439', 'bin440', 'bin441', 'bin442', 'bin443', 'bin444', 'bin445', 'bin446', 'bin447', 'bin448', 'bin449', 'bin450', 'bin451', 'bin452', 'bin453', 'bin454', 'bin455', 'bin456', 'bin457', 'bin458', 'bin459', 'bin460', 'bin461', 'bin462', 'bin463', 'bin464', 'bin465', 'bin466', 'bin467', 'bin468', 'bin469', 'bin470', 'bin471', 'bin472', 'bin473', 'bin474', 'bin475', 'bin476', 'bin477', 'bin478', 'bin479', 'bin480', 'bin481', 'bin482', 'bin483', 'bin484', 'bin485', 'bin486', 'bin487', 'bin488', 'bin489', 'bin490', 'bin491', 'bin492', 'bin493', 'bin494', 'bin495', 'bin496', 'bin497', 'bin498', 'bin499', 'bin500', 'bin501', 'bin502', 'bin503', 'bin504', 'bin505', 'bin506', 'bin507', 'bin508', 'bin509', 'bin510', 'bin511']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "# create the dataset from the pandas dataframe\n",
    "train_data = data[ data[\"years\"] != \"2018\" ]\n",
    "valid_data = data[ data[\"years\"] == \"2018\" ]\n",
    "\n",
    "bins_name = list()   #list([\"yield\"])\n",
    "for bin in range(0, 512):\n",
    "    bins_name.append(f'bin{bin}')\n",
    "\n",
    "# print(bins_name)  \n",
    "\n",
    "encoder_length = 8\n",
    "group=[\"years\", \"county\", \"bands\"]\n",
    "unknown_categoricals=[\"years\", \"county\", \"bands\"]\n",
    "static_categoricals=[\"county\", \"years\"]\n",
    "known_reals=[\"sownareas\"]\n",
    "\n",
    "train_dataset_with_covariates = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    group_ids=group,\n",
    "    target=\"yield\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=encoder_length,\n",
    "    max_encoder_length=encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=1,\n",
    "    time_varying_unknown_reals=bins_name,  #[\"yield\"],\n",
    "    # time_varying_unknown_categoricals=unknown_categoricals,\n",
    "    time_varying_known_reals=known_reals,\n",
    "    # time_varying_known_categoricals=[\"years\", \"county\"],\n",
    "    # static_categoricals=static_categoricals,\n",
    "    # allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "valid_dataset_with_covariates = TimeSeriesDataSet(\n",
    "    valid_data,\n",
    "    group_ids=group,\n",
    "    target=\"yield\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=encoder_length,\n",
    "    max_encoder_length=encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=1,\n",
    "    time_varying_unknown_reals=bins_name,   #[\"yield\"],\n",
    "    # time_varying_unknown_categoricals=unknown_categoricals,\n",
    "    time_varying_known_reals=known_reals,\n",
    "    # time_varying_known_categoricals=[\"years\", \"county\"],\n",
    "    # static_categoricals=static_categoricals,\n",
    "    # allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "hidden_size=50\n",
    "n_hidden_layers=10\n",
    "model = FullyConnectedModelWithCovariates.from_dataset(train_dataset_with_covariates, \\\n",
    "                                                       hidden_size=hidden_size, n_hidden_layers=n_hidden_layers)\n",
    "summarize(model,max_depth=-1)  # print model summary\n",
    "model.hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import MAE, MAPE\n",
    "\n",
    "# model = FullyConnectedModelWithCovariates.from_dataset(train_dataset_with_covariates,\n",
    "#                                                        hidden_size=20, n_hidden_layers=5)\n",
    "\n",
    "# convert datasets to dataloaders for training\n",
    "batch_size = 32\n",
    "train_dataloader = train_dataset_with_covariates.to_dataloader(train=True,  batch_size=batch_size, num_workers=2)\n",
    "valid_dataloader = valid_dataset_with_covariates.to_dataloader(train=False, batch_size=batch_size, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tencoder_cat = torch.Size([32, 8, 0])\n",
      "\tencoder_cont = torch.Size([32, 8, 513])\n",
      "\tencoder_target = torch.Size([32, 8])\n",
      "\tencoder_lengths = torch.Size([32])\n",
      "\tdecoder_cat = torch.Size([32, 1, 0])\n",
      "\tdecoder_cont = torch.Size([32, 1, 513])\n",
      "\tdecoder_target = torch.Size([32, 1])\n",
      "\tdecoder_lengths = torch.Size([32])\n",
      "\tdecoder_time_idx = torch.Size([32, 1])\n",
      "\tgroups = torch.Size([32, 3])\n",
      "\ttarget_scale = torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to a dataloader\n",
    "# dataloader = dataset.to_dataloader(batch_size=4)\n",
    "\n",
    "# and load the first batch\n",
    "x, y = next(iter(valid_dataloader))\n",
    "# print(\"x =\", x)\n",
    "# print(\"\\ny =\", y)\n",
    "# print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /tf_logs/FCNN: batch_size=32, encoder_length=8,                             group=['years', 'county', 'bands'],                             known_reals=['sownareas'],                             hidden_size=50, n_hidden_layers=10\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                 | Params\n",
      "----------------------------------------------------------\n",
      "0 | loss             | SMAPE                | 0     \n",
      "1 | logging_metrics  | ModuleList           | 0     \n",
      "2 | input_embeddings | MultiEmbedding       | 0     \n",
      "3 | network          | FullyConnectedModule | 230 K \n",
      "----------------------------------------------------------\n",
      "230 K     Trainable params\n",
      "0         Non-trainable params\n",
      "230 K     Total params\n",
      "0.923     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|█████████▍| 2025/2154 [03:17<00:12, 10.23it/s, loss=0.147, v_num=0, train_loss_step=0.146] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 2026/2154 [03:18<00:12, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2027/2154 [03:18<00:12, 10.21it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2028/2154 [03:18<00:12, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2029/2154 [03:18<00:12, 10.21it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2030/2154 [03:18<00:12, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.21it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2032/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2034/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  94%|█████████▍| 2035/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2036/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2037/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2038/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2039/2154 [03:19<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2042/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2044/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2045/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▍| 2046/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2047/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2048/2154 [03:20<00:10, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2049/2154 [03:20<00:10, 10.20it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2052/2154 [03:21<00:10, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2054/2154 [03:21<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2055/2154 [03:21<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2056/2154 [03:21<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  95%|█████████▌| 2057/2154 [03:21<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2058/2154 [03:22<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2059/2154 [03:22<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2062/2154 [03:22<00:09, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2064/2154 [03:22<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2065/2154 [03:22<00:08, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2066/2154 [03:22<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2067/2154 [03:22<00:08, 10.19it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2068/2154 [03:23<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2069/2154 [03:23<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2070/2154 [03:23<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2071/2154 [03:23<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▋| 2074/2154 [03:23<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▋| 2075/2154 [03:23<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▋| 2076/2154 [03:23<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▋| 2077/2154 [03:24<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  96%|█████████▋| 2078/2154 [03:24<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2079/2154 [03:24<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2080/2154 [03:24<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2081/2154 [03:24<00:07, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2084/2154 [03:24<00:06, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2085/2154 [03:24<00:06, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2087/2154 [03:25<00:06, 10.18it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2088/2154 [03:25<00:06, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2089/2154 [03:25<00:06, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2090/2154 [03:25<00:06, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2091/2154 [03:25<00:06, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2093/2154 [03:25<00:05, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2095/2154 [03:26<00:05, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2096/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2097/2154 [03:26<00:05, 10.17it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2098/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2099/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  97%|█████████▋| 2100/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2101/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2103/2154 [03:26<00:05, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2104/2154 [03:27<00:04, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2105/2154 [03:27<00:04, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2106/2154 [03:27<00:04, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2107/2154 [03:27<00:04, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2108/2154 [03:27<00:04, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2109/2154 [03:27<00:04, 10.16it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2110/2154 [03:27<00:04, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2111/2154 [03:27<00:04, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2114/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2115/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2116/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2117/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2118/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2119/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2120/2154 [03:28<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▊| 2124/2154 [03:29<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▊| 2125/2154 [03:29<00:02, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▊| 2126/2154 [03:29<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▊| 2127/2154 [03:29<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2128/2154 [03:29<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2129/2154 [03:29<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2134/2154 [03:30<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2135/2154 [03:30<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2136/2154 [03:30<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2137/2154 [03:30<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2138/2154 [03:30<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2139/2154 [03:30<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2144/2154 [03:31<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2145/2154 [03:31<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2146/2154 [03:31<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2147/2154 [03:31<00:00, 10.13it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2148/2154 [03:31<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.13it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.13it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.14it/s, loss=0.147, v_num=0, train_loss_step=0.146]\n",
      "Epoch 0: 100%|██████████| 2154/2154 [03:32<00:00, 10.15it/s, loss=0.147, v_num=0, train_loss_step=0.146, val_loss=0.118]\n",
      "Epoch 1:  94%|█████████▍| 2025/2154 [03:18<00:12, 10.19it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 2026/2154 [03:19<00:12, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2027/2154 [03:19<00:12, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2028/2154 [03:19<00:12, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2029/2154 [03:19<00:12, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2030/2154 [03:19<00:12, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2032/2154 [03:19<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2034/2154 [03:19<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2036/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2037/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2038/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2039/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2042/2154 [03:20<00:11, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2044/2154 [03:20<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▍| 2046/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2047/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2048/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2049/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2052/2154 [03:21<00:10, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2054/2154 [03:21<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2055/2154 [03:21<00:09, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2056/2154 [03:22<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  95%|█████████▌| 2057/2154 [03:22<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2058/2154 [03:22<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2059/2154 [03:22<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2062/2154 [03:22<00:09, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2064/2154 [03:22<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2065/2154 [03:22<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2066/2154 [03:23<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2067/2154 [03:23<00:08, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2068/2154 [03:23<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2069/2154 [03:23<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2070/2154 [03:23<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2071/2154 [03:23<00:08, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▋| 2074/2154 [03:23<00:07, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▋| 2075/2154 [03:23<00:07, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▋| 2076/2154 [03:24<00:07, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▋| 2077/2154 [03:24<00:07, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  96%|█████████▋| 2078/2154 [03:24<00:07, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2079/2154 [03:24<00:07, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2080/2154 [03:24<00:07, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2081/2154 [03:24<00:07, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2084/2154 [03:24<00:06, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2085/2154 [03:24<00:06, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2087/2154 [03:25<00:06, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2088/2154 [03:25<00:06, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2089/2154 [03:25<00:06, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2090/2154 [03:25<00:06, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2091/2154 [03:25<00:06, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2093/2154 [03:25<00:05, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2094/2154 [03:25<00:05, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2095/2154 [03:25<00:05, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2096/2154 [03:26<00:05, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2097/2154 [03:26<00:05, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2098/2154 [03:26<00:05, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2099/2154 [03:26<00:05, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  97%|█████████▋| 2100/2154 [03:26<00:05, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2101/2154 [03:26<00:05, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2103/2154 [03:26<00:05, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2104/2154 [03:26<00:04, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2105/2154 [03:26<00:04, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2106/2154 [03:27<00:04, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2107/2154 [03:27<00:04, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2108/2154 [03:27<00:04, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2109/2154 [03:27<00:04, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2110/2154 [03:27<00:04, 10.17it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2111/2154 [03:27<00:04, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2112/2154 [03:27<00:04, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2113/2154 [03:27<00:04, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2114/2154 [03:27<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2115/2154 [03:27<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2116/2154 [03:27<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2117/2154 [03:27<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2118/2154 [03:28<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2119/2154 [03:28<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2120/2154 [03:28<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  98%|█████████▊| 2121/2154 [03:28<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▊| 2122/2154 [03:28<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▊| 2123/2154 [03:28<00:03, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▊| 2124/2154 [03:28<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▊| 2125/2154 [03:28<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▊| 2126/2154 [03:28<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▊| 2127/2154 [03:28<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2128/2154 [03:29<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2129/2154 [03:29<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2130/2154 [03:29<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2131/2154 [03:29<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2132/2154 [03:29<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2133/2154 [03:29<00:02, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2134/2154 [03:29<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2135/2154 [03:29<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2136/2154 [03:29<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2137/2154 [03:29<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2138/2154 [03:30<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2139/2154 [03:30<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2140/2154 [03:30<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2141/2154 [03:30<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2142/2154 [03:30<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1:  99%|█████████▉| 2143/2154 [03:30<00:01, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2144/2154 [03:30<00:00, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2145/2154 [03:30<00:00, 10.19it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2146/2154 [03:30<00:00, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2147/2154 [03:30<00:00, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2148/2154 [03:30<00:00, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2149/2154 [03:30<00:00, 10.19it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2150/2154 [03:31<00:00, 10.18it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2151/2154 [03:31<00:00, 10.19it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2152/2154 [03:31<00:00, 10.19it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|█████████▉| 2153/2154 [03:31<00:00, 10.19it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.118, train_loss_epoch=0.161]\n",
      "Epoch 1: 100%|██████████| 2154/2154 [03:31<00:00, 10.20it/s, loss=0.148, v_num=0, train_loss_step=0.165, val_loss=0.110, train_loss_epoch=0.161]\n",
      "Epoch 2:  94%|█████████▍| 2025/2154 [03:22<00:12,  9.99it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 2026/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2027/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2028/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2029/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2030/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2031/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2032/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2033/2154 [03:23<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2034/2154 [03:24<00:12,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  94%|█████████▍| 2035/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2036/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2037/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2038/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2039/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2040/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2041/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2042/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2043/2154 [03:24<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2044/2154 [03:25<00:11,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2045/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▍| 2046/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2047/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2048/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2049/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2050/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2051/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2052/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2053/2154 [03:25<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2054/2154 [03:26<00:10,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2055/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2056/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  95%|█████████▌| 2057/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2058/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2059/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2060/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2061/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2062/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2063/2154 [03:26<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2064/2154 [03:27<00:09,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2065/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2066/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2067/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2068/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2069/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2070/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2071/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2072/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▌| 2073/2154 [03:27<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▋| 2074/2154 [03:28<00:08,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▋| 2075/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▋| 2076/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▋| 2077/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  96%|█████████▋| 2078/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2079/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2080/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2081/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2082/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2083/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2084/2154 [03:28<00:07,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2085/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2086/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2087/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2088/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2089/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2090/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2091/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2092/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2093/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2094/2154 [03:29<00:06,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2095/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2096/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2097/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2098/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2099/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  97%|█████████▋| 2100/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2101/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2102/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2103/2154 [03:30<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2104/2154 [03:31<00:05,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2105/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2106/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2107/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2108/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2109/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2110/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2111/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2112/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2113/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2114/2154 [03:31<00:04,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2115/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2116/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2117/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2118/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2119/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2120/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  98%|█████████▊| 2121/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▊| 2122/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▊| 2123/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▊| 2124/2154 [03:32<00:03,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▊| 2125/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▊| 2126/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▊| 2127/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2128/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2129/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2130/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2131/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2132/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2133/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2134/2154 [03:33<00:02,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2135/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2136/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2137/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2138/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2139/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2140/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2141/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2142/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2:  99%|█████████▉| 2143/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2144/2154 [03:34<00:01,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2145/2154 [03:35<00:00,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2146/2154 [03:35<00:00,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2147/2154 [03:35<00:00,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2148/2154 [03:35<00:00,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2149/2154 [03:35<00:00,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2150/2154 [03:35<00:00,  9.98it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2151/2154 [03:35<00:00,  9.97it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2152/2154 [03:35<00:00,  9.98it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|█████████▉| 2153/2154 [03:35<00:00,  9.98it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.110, train_loss_epoch=0.146]\n",
      "Epoch 2: 100%|██████████| 2154/2154 [03:35<00:00,  9.98it/s, loss=0.147, v_num=0, train_loss_step=0.162, val_loss=0.106, train_loss_epoch=0.146]\n",
      "Epoch 3:  94%|█████████▍| 2025/2154 [03:22<00:12, 10.01it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 2026/2154 [03:22<00:12,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2027/2154 [03:22<00:12,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2028/2154 [03:23<00:12,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2029/2154 [03:23<00:12,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2030/2154 [03:23<00:12,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2031/2154 [03:23<00:12,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2032/2154 [03:23<00:12,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2033/2154 [03:23<00:12,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2034/2154 [03:23<00:12,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  94%|█████████▍| 2035/2154 [03:23<00:11,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2036/2154 [03:23<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2037/2154 [03:23<00:11,  9.99it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2038/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2039/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2040/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2041/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2042/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2043/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2044/2154 [03:24<00:11,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2045/2154 [03:24<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▍| 2046/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2047/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2048/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2049/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2050/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2051/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2052/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2053/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2054/2154 [03:25<00:10,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2055/2154 [03:25<00:09,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2056/2154 [03:26<00:09,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  95%|█████████▌| 2057/2154 [03:26<00:09,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2058/2154 [03:26<00:09,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2059/2154 [03:26<00:09,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2060/2154 [03:26<00:09,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2061/2154 [03:26<00:09,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2062/2154 [03:26<00:09,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2063/2154 [03:26<00:09,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2064/2154 [03:26<00:09,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2065/2154 [03:27<00:08,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2066/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2067/2154 [03:27<00:08,  9.98it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2068/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2069/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2070/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2071/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2072/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▌| 2073/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▋| 2074/2154 [03:27<00:08,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▋| 2075/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▋| 2076/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▋| 2077/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  96%|█████████▋| 2078/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2079/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2080/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2081/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2082/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2083/2154 [03:28<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2084/2154 [03:29<00:07,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2085/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2086/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2087/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2088/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2089/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2090/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2091/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2092/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2093/2154 [03:29<00:06,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2094/2154 [03:30<00:06,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2095/2154 [03:30<00:05,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2096/2154 [03:30<00:05,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2097/2154 [03:30<00:05,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2098/2154 [03:30<00:05,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2099/2154 [03:30<00:05,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  97%|█████████▋| 2100/2154 [03:30<00:05,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2101/2154 [03:30<00:05,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2102/2154 [03:30<00:05,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2103/2154 [03:31<00:05,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2104/2154 [03:31<00:05,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2105/2154 [03:31<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2106/2154 [03:31<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2107/2154 [03:31<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2108/2154 [03:31<00:04,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2109/2154 [03:31<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2110/2154 [03:31<00:04,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2111/2154 [03:31<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2112/2154 [03:31<00:04,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2113/2154 [03:32<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2114/2154 [03:32<00:04,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2115/2154 [03:32<00:03,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2116/2154 [03:32<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2117/2154 [03:32<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2118/2154 [03:32<00:03,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2119/2154 [03:32<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2120/2154 [03:32<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  98%|█████████▊| 2121/2154 [03:32<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▊| 2122/2154 [03:32<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▊| 2123/2154 [03:33<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▊| 2124/2154 [03:33<00:03,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▊| 2125/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▊| 2126/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▊| 2127/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2128/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2129/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2130/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2131/2154 [03:33<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2132/2154 [03:34<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2133/2154 [03:34<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2134/2154 [03:34<00:02,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2135/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2136/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2137/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2138/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2139/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2140/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2141/2154 [03:34<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2142/2154 [03:35<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3:  99%|█████████▉| 2143/2154 [03:35<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2144/2154 [03:35<00:01,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2145/2154 [03:35<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2146/2154 [03:35<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2147/2154 [03:35<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2148/2154 [03:35<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2149/2154 [03:35<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2150/2154 [03:35<00:00,  9.95it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2151/2154 [03:35<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2152/2154 [03:36<00:00,  9.96it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|█████████▉| 2153/2154 [03:36<00:00,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.106, train_loss_epoch=0.140]\n",
      "Epoch 3: 100%|██████████| 2154/2154 [03:36<00:00,  9.97it/s, loss=0.125, v_num=0, train_loss_step=0.121, val_loss=0.104, train_loss_epoch=0.140]\n",
      "Epoch 4:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.57it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2027/2154 [03:32<00:13,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2028/2154 [03:32<00:13,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2029/2154 [03:32<00:13,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2038/2154 [03:33<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2039/2154 [03:33<00:12,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2047/2154 [03:34<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2048/2154 [03:34<00:11,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2049/2154 [03:34<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2055/2154 [03:35<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2056/2154 [03:35<00:10,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  95%|█████████▌| 2057/2154 [03:35<00:10,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2065/2154 [03:36<00:09,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2066/2154 [03:36<00:09,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2067/2154 [03:36<00:09,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2068/2154 [03:36<00:09,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2072/2154 [03:37<00:08,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▌| 2073/2154 [03:37<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▋| 2074/2154 [03:37<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▋| 2075/2154 [03:37<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▋| 2076/2154 [03:37<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▋| 2077/2154 [03:37<00:08,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2082/2154 [03:38<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2084/2154 [03:38<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2085/2154 [03:38<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2086/2154 [03:38<00:07,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2087/2154 [03:38<00:07,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2091/2154 [03:39<00:06,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2092/2154 [03:39<00:06,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2093/2154 [03:39<00:06,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2094/2154 [03:39<00:06,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2095/2154 [03:39<00:06,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2101/2154 [03:40<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2102/2154 [03:40<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2103/2154 [03:40<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2104/2154 [03:40<00:05,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2105/2154 [03:40<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2110/2154 [03:41<00:04,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2111/2154 [03:41<00:04,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2112/2154 [03:41<00:04,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2113/2154 [03:41<00:04,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2114/2154 [03:41<00:04,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2120/2154 [03:42<00:03,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  98%|█████████▊| 2121/2154 [03:42<00:03,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▊| 2122/2154 [03:42<00:03,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.54it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2130/2154 [03:43<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2131/2154 [03:43<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2132/2154 [03:43<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2134/2154 [03:43<00:02,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2139/2154 [03:44<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2140/2154 [03:44<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2141/2154 [03:44<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4:  99%|█████████▉| 2143/2154 [03:44<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2149/2154 [03:45<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2150/2154 [03:45<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2151/2154 [03:45<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2152/2154 [03:45<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|█████████▉| 2153/2154 [03:45<00:00,  9.55it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.104, train_loss_epoch=0.135]\n",
      "Epoch 4: 100%|██████████| 2154/2154 [03:45<00:00,  9.56it/s, loss=0.123, v_num=0, train_loss_step=0.132, val_loss=0.0987, train_loss_epoch=0.135]\n",
      "Epoch 5:  94%|█████████▍| 2025/2154 [03:29<00:13,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 2026/2154 [03:30<00:13,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2027/2154 [03:30<00:13,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2028/2154 [03:30<00:13,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2029/2154 [03:30<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2030/2154 [03:30<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2031/2154 [03:30<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2032/2154 [03:30<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2033/2154 [03:30<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2034/2154 [03:31<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  94%|█████████▍| 2035/2154 [03:31<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2036/2154 [03:31<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2037/2154 [03:31<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2038/2154 [03:31<00:12,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2039/2154 [03:31<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2040/2154 [03:31<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2041/2154 [03:31<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2042/2154 [03:31<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2043/2154 [03:31<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2044/2154 [03:32<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2045/2154 [03:32<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▍| 2046/2154 [03:32<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2047/2154 [03:32<00:11,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2048/2154 [03:32<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2049/2154 [03:32<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2050/2154 [03:32<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2051/2154 [03:32<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2052/2154 [03:32<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2053/2154 [03:32<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2054/2154 [03:33<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2055/2154 [03:33<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2056/2154 [03:33<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  95%|█████████▌| 2057/2154 [03:33<00:10,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2058/2154 [03:33<00:09,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2059/2154 [03:33<00:09,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2060/2154 [03:33<00:09,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2061/2154 [03:33<00:09,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2062/2154 [03:33<00:09,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2063/2154 [03:33<00:09,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2064/2154 [03:34<00:09,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2065/2154 [03:34<00:09,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2066/2154 [03:34<00:09,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2067/2154 [03:34<00:09,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2068/2154 [03:34<00:08,  9.64it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2069/2154 [03:34<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2070/2154 [03:34<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2071/2154 [03:34<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2072/2154 [03:34<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▌| 2073/2154 [03:34<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▋| 2074/2154 [03:34<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▋| 2075/2154 [03:35<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▋| 2076/2154 [03:35<00:08,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▋| 2077/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  96%|█████████▋| 2078/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2079/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2080/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2081/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2082/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2083/2154 [03:35<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2084/2154 [03:36<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2085/2154 [03:36<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2086/2154 [03:36<00:07,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2087/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2088/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2089/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2090/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2091/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2092/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2093/2154 [03:36<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2094/2154 [03:37<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2095/2154 [03:37<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2096/2154 [03:37<00:06,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2097/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2098/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2099/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  97%|█████████▋| 2100/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2101/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2102/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2103/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2104/2154 [03:37<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2105/2154 [03:38<00:05,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2106/2154 [03:38<00:04,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2107/2154 [03:38<00:04,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2108/2154 [03:38<00:04,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2109/2154 [03:38<00:04,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2110/2154 [03:38<00:04,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2111/2154 [03:38<00:04,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2112/2154 [03:38<00:04,  9.65it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2113/2154 [03:38<00:04,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2114/2154 [03:38<00:04,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2115/2154 [03:38<00:04,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2116/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2117/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2118/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2119/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2120/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  98%|█████████▊| 2121/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▊| 2122/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▊| 2123/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▊| 2124/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▊| 2125/2154 [03:39<00:03,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▊| 2126/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▊| 2127/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2128/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2129/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2130/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2131/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2132/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2133/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2134/2154 [03:40<00:02,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2135/2154 [03:40<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2136/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2137/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2138/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2139/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2140/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2141/2154 [03:41<00:01,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2142/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5:  99%|█████████▉| 2143/2154 [03:41<00:01,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2144/2154 [03:41<00:01,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2145/2154 [03:41<00:00,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2146/2154 [03:42<00:00,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2147/2154 [03:42<00:00,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2148/2154 [03:42<00:00,  9.66it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2149/2154 [03:42<00:00,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2150/2154 [03:42<00:00,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2151/2154 [03:42<00:00,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2152/2154 [03:42<00:00,  9.67it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|█████████▉| 2153/2154 [03:42<00:00,  9.68it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.0987, train_loss_epoch=0.130]\n",
      "Epoch 5: 100%|██████████| 2154/2154 [03:42<00:00,  9.68it/s, loss=0.125, v_num=0, train_loss_step=0.138, val_loss=0.101, train_loss_epoch=0.130] \n",
      "Epoch 6:  94%|█████████▍| 2025/2154 [03:30<00:13,  9.62it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 2026/2154 [03:31<00:13,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2027/2154 [03:31<00:13,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2028/2154 [03:31<00:13,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2029/2154 [03:31<00:13,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2030/2154 [03:31<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2031/2154 [03:31<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2032/2154 [03:31<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2033/2154 [03:31<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2034/2154 [03:31<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  94%|█████████▍| 2035/2154 [03:32<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2036/2154 [03:32<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2037/2154 [03:32<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2038/2154 [03:32<00:12,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2039/2154 [03:32<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2040/2154 [03:32<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2041/2154 [03:32<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2042/2154 [03:32<00:11,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2043/2154 [03:32<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2044/2154 [03:33<00:11,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2045/2154 [03:33<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▍| 2046/2154 [03:33<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2047/2154 [03:33<00:11,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2048/2154 [03:33<00:11,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2049/2154 [03:33<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2050/2154 [03:33<00:10,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2051/2154 [03:33<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2052/2154 [03:33<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2053/2154 [03:33<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2054/2154 [03:34<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2055/2154 [03:34<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2056/2154 [03:34<00:10,  9.60it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  95%|█████████▌| 2057/2154 [03:34<00:10,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2058/2154 [03:34<00:10,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2059/2154 [03:34<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2060/2154 [03:34<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2061/2154 [03:34<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2062/2154 [03:34<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2063/2154 [03:35<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2064/2154 [03:35<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2065/2154 [03:35<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2066/2154 [03:35<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2067/2154 [03:35<00:09,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2068/2154 [03:35<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2069/2154 [03:35<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2070/2154 [03:35<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2071/2154 [03:35<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2072/2154 [03:36<00:08,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▌| 2073/2154 [03:36<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▋| 2074/2154 [03:36<00:08,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▋| 2075/2154 [03:36<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▋| 2076/2154 [03:36<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▋| 2077/2154 [03:36<00:08,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  96%|█████████▋| 2078/2154 [03:36<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2079/2154 [03:36<00:07,  9.59it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2082/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2083/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2084/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2085/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2086/2154 [03:37<00:07,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2087/2154 [03:37<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2088/2154 [03:37<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2091/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2092/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2093/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2094/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2095/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2096/2154 [03:38<00:06,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2097/2154 [03:38<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2098/2154 [03:38<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  97%|█████████▋| 2100/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2101/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2102/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2103/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2104/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2105/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2106/2154 [03:39<00:05,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2107/2154 [03:39<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2110/2154 [03:40<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2111/2154 [03:40<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2112/2154 [03:40<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2113/2154 [03:40<00:04,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2114/2154 [03:40<00:04,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2115/2154 [03:40<00:04,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2120/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  98%|█████████▊| 2121/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▊| 2122/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▊| 2123/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▊| 2124/2154 [03:41<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2129/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2130/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2131/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2132/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2133/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2134/2154 [03:42<00:02,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2139/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2140/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2141/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2142/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6:  99%|█████████▉| 2143/2154 [03:43<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.56it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2149/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2150/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2151/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2152/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|█████████▉| 2153/2154 [03:44<00:00,  9.57it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 6: 100%|██████████| 2154/2154 [03:44<00:00,  9.58it/s, loss=0.118, v_num=0, train_loss_step=0.113, val_loss=0.101, train_loss_epoch=0.125]\n",
      "Epoch 7:  94%|█████████▍| 2025/2154 [03:39<00:13,  9.24it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 2026/2154 [03:39<00:13,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2027/2154 [03:39<00:13,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2028/2154 [03:39<00:13,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2029/2154 [03:39<00:13,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2030/2154 [03:40<00:13,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2031/2154 [03:40<00:13,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2032/2154 [03:40<00:13,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2033/2154 [03:40<00:13,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2034/2154 [03:40<00:13,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  94%|█████████▍| 2035/2154 [03:40<00:12,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2036/2154 [03:40<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2037/2154 [03:40<00:12,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2038/2154 [03:41<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2039/2154 [03:41<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2040/2154 [03:41<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2041/2154 [03:41<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2042/2154 [03:41<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2043/2154 [03:41<00:12,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2044/2154 [03:41<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2045/2154 [03:41<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▍| 2046/2154 [03:41<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2047/2154 [03:41<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2048/2154 [03:42<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2049/2154 [03:42<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2050/2154 [03:42<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2051/2154 [03:42<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2052/2154 [03:42<00:11,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2053/2154 [03:42<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2054/2154 [03:42<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2055/2154 [03:42<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2056/2154 [03:42<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  95%|█████████▌| 2057/2154 [03:43<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2058/2154 [03:43<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2059/2154 [03:43<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2060/2154 [03:43<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2061/2154 [03:43<00:10,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2062/2154 [03:43<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2063/2154 [03:43<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2064/2154 [03:43<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2065/2154 [03:43<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2066/2154 [03:43<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2067/2154 [03:44<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2068/2154 [03:44<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2069/2154 [03:44<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2070/2154 [03:44<00:09,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2071/2154 [03:44<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2072/2154 [03:44<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▌| 2073/2154 [03:44<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▋| 2074/2154 [03:44<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▋| 2075/2154 [03:44<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▋| 2076/2154 [03:45<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▋| 2077/2154 [03:45<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  96%|█████████▋| 2078/2154 [03:45<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2079/2154 [03:45<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2080/2154 [03:45<00:08,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2081/2154 [03:45<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2082/2154 [03:45<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2083/2154 [03:45<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2084/2154 [03:45<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2085/2154 [03:46<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2086/2154 [03:46<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2087/2154 [03:46<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2088/2154 [03:46<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2089/2154 [03:46<00:07,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2090/2154 [03:46<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2091/2154 [03:46<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2092/2154 [03:46<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2093/2154 [03:46<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2094/2154 [03:47<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2095/2154 [03:47<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2096/2154 [03:47<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2097/2154 [03:47<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2098/2154 [03:47<00:06,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2099/2154 [03:47<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  97%|█████████▋| 2100/2154 [03:47<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2101/2154 [03:47<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2102/2154 [03:47<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2103/2154 [03:48<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2104/2154 [03:48<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2105/2154 [03:48<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2106/2154 [03:48<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2107/2154 [03:48<00:05,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2108/2154 [03:48<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2109/2154 [03:48<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2110/2154 [03:48<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2111/2154 [03:48<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2112/2154 [03:49<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2113/2154 [03:49<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2114/2154 [03:49<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2115/2154 [03:49<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2116/2154 [03:49<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2117/2154 [03:49<00:04,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2118/2154 [03:49<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2119/2154 [03:49<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2120/2154 [03:49<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  98%|█████████▊| 2121/2154 [03:50<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▊| 2122/2154 [03:50<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▊| 2123/2154 [03:50<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▊| 2124/2154 [03:50<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▊| 2125/2154 [03:50<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▊| 2126/2154 [03:50<00:03,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▊| 2127/2154 [03:50<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2128/2154 [03:50<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2129/2154 [03:50<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2130/2154 [03:51<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2131/2154 [03:51<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2132/2154 [03:51<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2133/2154 [03:51<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2134/2154 [03:51<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2135/2154 [03:51<00:02,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2136/2154 [03:51<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2137/2154 [03:51<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2138/2154 [03:51<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2139/2154 [03:52<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2140/2154 [03:52<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2141/2154 [03:52<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2142/2154 [03:52<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7:  99%|█████████▉| 2143/2154 [03:52<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2144/2154 [03:52<00:01,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2145/2154 [03:52<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2146/2154 [03:52<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2147/2154 [03:52<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2148/2154 [03:53<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2149/2154 [03:53<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2150/2154 [03:53<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2151/2154 [03:53<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2152/2154 [03:53<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|█████████▉| 2153/2154 [03:53<00:00,  9.22it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.101, train_loss_epoch=0.122]\n",
      "Epoch 7: 100%|██████████| 2154/2154 [03:53<00:00,  9.23it/s, loss=0.12, v_num=0, train_loss_step=0.132, val_loss=0.0972, train_loss_epoch=0.122]\n",
      "Epoch 8:  94%|█████████▍| 2025/2154 [03:27<00:13,  9.76it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 2026/2154 [03:28<00:13,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2027/2154 [03:28<00:13,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2028/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2029/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2030/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2031/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2032/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2033/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2034/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  94%|█████████▍| 2035/2154 [03:28<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2036/2154 [03:29<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2037/2154 [03:29<00:12,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2038/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2039/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2040/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2041/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2042/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2043/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2044/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2045/2154 [03:29<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▍| 2046/2154 [03:30<00:11,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2047/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2048/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2049/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2050/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2051/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2052/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2053/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2054/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2055/2154 [03:30<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2056/2154 [03:31<00:10,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  95%|█████████▌| 2057/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2058/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2059/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2060/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2061/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2062/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2063/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2064/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2065/2154 [03:31<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2066/2154 [03:32<00:09,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2067/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2068/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2069/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2070/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2071/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2072/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▌| 2073/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▋| 2074/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▋| 2075/2154 [03:32<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▋| 2076/2154 [03:33<00:08,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▋| 2077/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  96%|█████████▋| 2078/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2079/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2080/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2081/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2082/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2083/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2084/2154 [03:33<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2085/2154 [03:34<00:07,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2086/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2087/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2088/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2089/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2090/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2091/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2092/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2093/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2094/2154 [03:34<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2095/2154 [03:35<00:06,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2096/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2097/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2098/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2099/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  97%|█████████▋| 2100/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2101/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2102/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2103/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2104/2154 [03:35<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2105/2154 [03:36<00:05,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2106/2154 [03:36<00:04,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2107/2154 [03:36<00:04,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2108/2154 [03:36<00:04,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2109/2154 [03:36<00:04,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2110/2154 [03:36<00:04,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2111/2154 [03:36<00:04,  9.74it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2112/2154 [03:36<00:04,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2113/2154 [03:36<00:04,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2114/2154 [03:36<00:04,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2115/2154 [03:37<00:04,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2116/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2117/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2118/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2119/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2120/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  98%|█████████▊| 2121/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▊| 2122/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▊| 2123/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▊| 2124/2154 [03:37<00:03,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▊| 2125/2154 [03:37<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▊| 2126/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▊| 2127/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2128/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2129/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2130/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2131/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2132/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2133/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2134/2154 [03:38<00:02,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2135/2154 [03:38<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2136/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2137/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2138/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2139/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2140/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2141/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2142/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8:  99%|█████████▉| 2143/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2144/2154 [03:39<00:01,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2145/2154 [03:39<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2146/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2147/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2148/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2149/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2150/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2151/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2152/2154 [03:40<00:00,  9.75it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|█████████▉| 2153/2154 [03:40<00:00,  9.76it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0972, train_loss_epoch=0.120]\n",
      "Epoch 8: 100%|██████████| 2154/2154 [03:40<00:00,  9.76it/s, loss=0.116, v_num=0, train_loss_step=0.130, val_loss=0.0951, train_loss_epoch=0.120]\n",
      "Epoch 9:  94%|█████████▍| 2025/2154 [03:26<00:13,  9.80it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 2026/2154 [03:27<00:13,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2027/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2028/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2029/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2030/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2031/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2032/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2033/2154 [03:27<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2034/2154 [03:28<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  94%|█████████▍| 2035/2154 [03:28<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2036/2154 [03:28<00:12,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2037/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2038/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2039/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2040/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2041/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2042/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2043/2154 [03:28<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2044/2154 [03:29<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2045/2154 [03:29<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▍| 2046/2154 [03:29<00:11,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2047/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2048/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2049/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2050/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2051/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2052/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2053/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2054/2154 [03:29<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2055/2154 [03:30<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2056/2154 [03:30<00:10,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  95%|█████████▌| 2057/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2058/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2059/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2060/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2061/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2062/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2063/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2064/2154 [03:30<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2065/2154 [03:31<00:09,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2066/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2067/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2068/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2069/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2070/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2071/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2072/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▌| 2073/2154 [03:31<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▋| 2074/2154 [03:32<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▋| 2075/2154 [03:32<00:08,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▋| 2076/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▋| 2077/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  96%|█████████▋| 2078/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2079/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2080/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2081/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2082/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2083/2154 [03:32<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2084/2154 [03:33<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2085/2154 [03:33<00:07,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2086/2154 [03:33<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2087/2154 [03:33<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2088/2154 [03:33<00:06,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2089/2154 [03:33<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2090/2154 [03:33<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2091/2154 [03:33<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2092/2154 [03:33<00:06,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2093/2154 [03:33<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2094/2154 [03:33<00:06,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2095/2154 [03:34<00:06,  9.78it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2096/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2097/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2098/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2099/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  97%|█████████▋| 2100/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2101/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2102/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2103/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2104/2154 [03:34<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2105/2154 [03:35<00:05,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2106/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2107/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2108/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2109/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2110/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2111/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2112/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2113/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2114/2154 [03:35<00:04,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2115/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2116/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2117/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2118/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2119/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2120/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  98%|█████████▊| 2121/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▊| 2122/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▊| 2123/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▊| 2124/2154 [03:36<00:03,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▊| 2125/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▊| 2126/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▊| 2127/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2128/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2129/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2130/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2131/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2132/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2133/2154 [03:37<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2134/2154 [03:38<00:02,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2135/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2136/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2137/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2138/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2139/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2140/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2141/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2142/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9:  99%|█████████▉| 2143/2154 [03:38<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2144/2154 [03:39<00:01,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2145/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2146/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2147/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2148/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2149/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2150/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2151/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2152/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|█████████▉| 2153/2154 [03:39<00:00,  9.79it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0951, train_loss_epoch=0.118]\n",
      "Epoch 9: 100%|██████████| 2154/2154 [03:39<00:00,  9.80it/s, loss=0.113, v_num=0, train_loss_step=0.102, val_loss=0.0957, train_loss_epoch=0.118]\n",
      "Epoch 10:  94%|█████████▍| 2025/2154 [03:24<00:13,  9.88it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 2026/2154 [03:25<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2027/2154 [03:25<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2028/2154 [03:25<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2029/2154 [03:25<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2030/2154 [03:25<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2031/2154 [03:25<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2032/2154 [03:26<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2033/2154 [03:26<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2034/2154 [03:26<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  94%|█████████▍| 2035/2154 [03:26<00:12,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2036/2154 [03:26<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2037/2154 [03:26<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2038/2154 [03:26<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2039/2154 [03:26<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2040/2154 [03:26<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2041/2154 [03:27<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2042/2154 [03:27<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2043/2154 [03:27<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2044/2154 [03:27<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2045/2154 [03:27<00:11,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▍| 2046/2154 [03:27<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2047/2154 [03:27<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2048/2154 [03:27<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2049/2154 [03:27<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2050/2154 [03:27<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2051/2154 [03:28<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2052/2154 [03:28<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2053/2154 [03:28<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2054/2154 [03:28<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2055/2154 [03:28<00:10,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2056/2154 [03:28<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  95%|█████████▌| 2057/2154 [03:28<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2058/2154 [03:28<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2059/2154 [03:28<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2060/2154 [03:28<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2061/2154 [03:29<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2062/2154 [03:29<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2063/2154 [03:29<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2064/2154 [03:29<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2065/2154 [03:29<00:09,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2066/2154 [03:29<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2067/2154 [03:29<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2068/2154 [03:29<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2069/2154 [03:29<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2070/2154 [03:30<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2071/2154 [03:30<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2072/2154 [03:30<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▌| 2073/2154 [03:30<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▋| 2074/2154 [03:30<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▋| 2075/2154 [03:30<00:08,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▋| 2076/2154 [03:30<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▋| 2077/2154 [03:30<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  96%|█████████▋| 2078/2154 [03:30<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2079/2154 [03:30<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2080/2154 [03:31<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2081/2154 [03:31<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2082/2154 [03:31<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2083/2154 [03:31<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2084/2154 [03:31<00:07,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2085/2154 [03:31<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2086/2154 [03:31<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2087/2154 [03:31<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2088/2154 [03:31<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2089/2154 [03:31<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2090/2154 [03:31<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2091/2154 [03:32<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2092/2154 [03:32<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2093/2154 [03:32<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2094/2154 [03:32<00:06,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2095/2154 [03:32<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2096/2154 [03:32<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2097/2154 [03:32<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2098/2154 [03:32<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2099/2154 [03:32<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  97%|█████████▋| 2100/2154 [03:33<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2101/2154 [03:33<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2102/2154 [03:33<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2103/2154 [03:33<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2104/2154 [03:33<00:05,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2105/2154 [03:33<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2106/2154 [03:33<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2107/2154 [03:33<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2108/2154 [03:33<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2109/2154 [03:33<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2110/2154 [03:33<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2111/2154 [03:34<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2112/2154 [03:34<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2113/2154 [03:34<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2114/2154 [03:34<00:04,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2115/2154 [03:34<00:03,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2116/2154 [03:34<00:03,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2117/2154 [03:34<00:03,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2118/2154 [03:34<00:03,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2119/2154 [03:34<00:03,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2120/2154 [03:34<00:03,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  98%|█████████▊| 2121/2154 [03:35<00:03,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▊| 2122/2154 [03:35<00:03,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▊| 2123/2154 [03:35<00:03,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▊| 2124/2154 [03:35<00:03,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▊| 2125/2154 [03:35<00:02,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▊| 2126/2154 [03:35<00:02,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▊| 2127/2154 [03:35<00:02,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2128/2154 [03:35<00:02,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2129/2154 [03:35<00:02,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2130/2154 [03:35<00:02,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2131/2154 [03:35<00:02,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2132/2154 [03:36<00:02,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2133/2154 [03:36<00:02,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2134/2154 [03:36<00:02,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2135/2154 [03:36<00:01,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2136/2154 [03:36<00:01,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2137/2154 [03:36<00:01,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2138/2154 [03:36<00:01,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2139/2154 [03:36<00:01,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2140/2154 [03:36<00:01,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2141/2154 [03:36<00:01,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2142/2154 [03:37<00:01,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10:  99%|█████████▉| 2143/2154 [03:37<00:01,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2144/2154 [03:37<00:01,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2145/2154 [03:37<00:00,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2146/2154 [03:37<00:00,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2147/2154 [03:37<00:00,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2148/2154 [03:37<00:00,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2149/2154 [03:37<00:00,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2150/2154 [03:37<00:00,  9.86it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2151/2154 [03:37<00:00,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2152/2154 [03:38<00:00,  9.87it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|█████████▉| 2153/2154 [03:38<00:00,  9.88it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0957, train_loss_epoch=0.115]\n",
      "Epoch 10: 100%|██████████| 2154/2154 [03:38<00:00,  9.88it/s, loss=0.102, v_num=0, train_loss_step=0.105, val_loss=0.0992, train_loss_epoch=0.115]\n",
      "Epoch 11:  94%|█████████▍| 2025/2154 [03:26<00:13,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 2026/2154 [03:27<00:13,  9.78it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2027/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2028/2154 [03:27<00:12,  9.78it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2029/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2030/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2031/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2032/2154 [03:27<00:12,  9.78it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2033/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2034/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  94%|█████████▍| 2035/2154 [03:27<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2036/2154 [03:28<00:12,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2037/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2038/2154 [03:28<00:11,  9.78it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2039/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2040/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2041/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2042/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2043/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2044/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2045/2154 [03:28<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▍| 2046/2154 [03:29<00:11,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2047/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2048/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2049/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2050/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2051/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2052/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2053/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2054/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2055/2154 [03:29<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2056/2154 [03:30<00:10,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  95%|█████████▌| 2057/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2058/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2059/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2060/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2061/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2062/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2063/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2064/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2065/2154 [03:30<00:09,  9.79it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2066/2154 [03:30<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2067/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2068/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2069/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2070/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2071/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2072/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▌| 2073/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▋| 2074/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▋| 2075/2154 [03:31<00:08,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▋| 2076/2154 [03:31<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▋| 2077/2154 [03:31<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  96%|█████████▋| 2078/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2079/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2080/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2081/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2082/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2083/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2084/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2085/2154 [03:32<00:07,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2086/2154 [03:32<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2087/2154 [03:32<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2088/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2089/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2090/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2091/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2092/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2093/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2094/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2095/2154 [03:33<00:06,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2096/2154 [03:33<00:05,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2097/2154 [03:33<00:05,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2098/2154 [03:34<00:05,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2099/2154 [03:34<00:05,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  97%|█████████▋| 2100/2154 [03:34<00:05,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2101/2154 [03:34<00:05,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2102/2154 [03:34<00:05,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2103/2154 [03:34<00:05,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2104/2154 [03:34<00:05,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2105/2154 [03:34<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2106/2154 [03:34<00:04,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2107/2154 [03:34<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2108/2154 [03:35<00:04,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2109/2154 [03:35<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2110/2154 [03:35<00:04,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2111/2154 [03:35<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2112/2154 [03:35<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2113/2154 [03:35<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2114/2154 [03:35<00:04,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2115/2154 [03:35<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2116/2154 [03:35<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2117/2154 [03:35<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2118/2154 [03:35<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2119/2154 [03:36<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2120/2154 [03:36<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  98%|█████████▊| 2121/2154 [03:36<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▊| 2122/2154 [03:36<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▊| 2123/2154 [03:36<00:03,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▊| 2124/2154 [03:36<00:03,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▊| 2125/2154 [03:36<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▊| 2126/2154 [03:36<00:02,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▊| 2127/2154 [03:36<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2128/2154 [03:37<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2129/2154 [03:37<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2130/2154 [03:37<00:02,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2131/2154 [03:37<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2132/2154 [03:37<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2133/2154 [03:37<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2134/2154 [03:37<00:02,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2135/2154 [03:37<00:01,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2136/2154 [03:37<00:01,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2137/2154 [03:37<00:01,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2138/2154 [03:38<00:01,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2139/2154 [03:38<00:01,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2140/2154 [03:38<00:01,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2141/2154 [03:38<00:01,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2142/2154 [03:38<00:01,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11:  99%|█████████▉| 2143/2154 [03:38<00:01,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2144/2154 [03:38<00:01,  9.80it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2145/2154 [03:38<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2146/2154 [03:38<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2147/2154 [03:38<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2148/2154 [03:39<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2149/2154 [03:39<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2150/2154 [03:39<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2151/2154 [03:39<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2152/2154 [03:39<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|█████████▉| 2153/2154 [03:39<00:00,  9.81it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0992, train_loss_epoch=0.114]\n",
      "Epoch 11: 100%|██████████| 2154/2154 [03:39<00:00,  9.82it/s, loss=0.111, v_num=0, train_loss_step=0.115, val_loss=0.0951, train_loss_epoch=0.114]\n",
      "Epoch 12:  94%|█████████▍| 2025/2154 [03:24<00:13,  9.91it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  94%|█████████▍| 2026/2154 [03:24<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2027/2154 [03:24<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2028/2154 [03:24<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2029/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2030/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2031/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2032/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2033/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2034/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  94%|█████████▍| 2035/2154 [03:25<00:12,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2036/2154 [03:25<00:11,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2037/2154 [03:26<00:11,  9.89it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2038/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2039/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2040/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2041/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2042/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2043/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2044/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2045/2154 [03:26<00:11,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▍| 2046/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2047/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2048/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2049/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2050/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2051/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2052/2154 [03:27<00:10,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2053/2154 [03:27<00:10,  9.88it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2054/2154 [03:28<00:10,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2055/2154 [03:28<00:10,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2056/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  95%|█████████▌| 2057/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2058/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2059/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2060/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2061/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2062/2154 [03:28<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2063/2154 [03:29<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2064/2154 [03:29<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2065/2154 [03:29<00:09,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2066/2154 [03:29<00:08,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2067/2154 [03:29<00:08,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2068/2154 [03:29<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2069/2154 [03:29<00:08,  9.87it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2070/2154 [03:29<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2071/2154 [03:29<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2072/2154 [03:30<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▌| 2073/2154 [03:30<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▋| 2074/2154 [03:30<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▋| 2075/2154 [03:30<00:08,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▋| 2076/2154 [03:30<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▋| 2077/2154 [03:30<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  96%|█████████▋| 2078/2154 [03:30<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2079/2154 [03:30<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2080/2154 [03:31<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2081/2154 [03:31<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2082/2154 [03:31<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2083/2154 [03:31<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2084/2154 [03:31<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2085/2154 [03:31<00:07,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2086/2154 [03:31<00:06,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2087/2154 [03:31<00:06,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2088/2154 [03:31<00:06,  9.86it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2089/2154 [03:31<00:06,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2090/2154 [03:32<00:06,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2091/2154 [03:32<00:06,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2092/2154 [03:32<00:06,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2093/2154 [03:32<00:06,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2094/2154 [03:32<00:06,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2095/2154 [03:32<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2096/2154 [03:32<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2097/2154 [03:32<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2098/2154 [03:33<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2099/2154 [03:33<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  97%|█████████▋| 2100/2154 [03:33<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2101/2154 [03:33<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2102/2154 [03:33<00:05,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2103/2154 [03:33<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2104/2154 [03:33<00:05,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2105/2154 [03:33<00:04,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2106/2154 [03:33<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2107/2154 [03:34<00:04,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2108/2154 [03:34<00:04,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2109/2154 [03:34<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2110/2154 [03:34<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2111/2154 [03:34<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2112/2154 [03:34<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2113/2154 [03:34<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2114/2154 [03:34<00:04,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2115/2154 [03:34<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2116/2154 [03:34<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2117/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2118/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2119/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2120/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  98%|█████████▊| 2121/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▊| 2122/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▊| 2123/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▊| 2124/2154 [03:35<00:03,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▊| 2125/2154 [03:35<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▊| 2126/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▊| 2127/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2128/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2129/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2130/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2131/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2132/2154 [03:36<00:02,  9.83it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2133/2154 [03:36<00:02,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2134/2154 [03:36<00:02,  9.83it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2135/2154 [03:37<00:01,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2136/2154 [03:37<00:01,  9.83it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2137/2154 [03:37<00:01,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2138/2154 [03:37<00:01,  9.83it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2139/2154 [03:37<00:01,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2140/2154 [03:37<00:01,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2141/2154 [03:37<00:01,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2142/2154 [03:37<00:01,  9.83it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12:  99%|█████████▉| 2143/2154 [03:37<00:01,  9.83it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2144/2154 [03:37<00:01,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2145/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2146/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2147/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2148/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2149/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2150/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2151/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2152/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|█████████▉| 2153/2154 [03:38<00:00,  9.84it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0951, train_loss_epoch=0.113]\n",
      "Epoch 12: 100%|██████████| 2154/2154 [03:38<00:00,  9.85it/s, loss=0.117, v_num=0, train_loss_step=0.111, val_loss=0.0969, train_loss_epoch=0.113]\n",
      "Epoch 13:  94%|█████████▍| 2025/2154 [03:22<00:12,  9.98it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  94%|█████████▍| 2026/2154 [03:23<00:12,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2027/2154 [03:23<00:12,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2028/2154 [03:23<00:12,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2029/2154 [03:23<00:12,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2030/2154 [03:23<00:12,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2031/2154 [03:23<00:12,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2032/2154 [03:24<00:12,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2033/2154 [03:24<00:12,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2034/2154 [03:24<00:12,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  94%|█████████▍| 2035/2154 [03:24<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2036/2154 [03:24<00:11,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2037/2154 [03:24<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2038/2154 [03:24<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2039/2154 [03:24<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2040/2154 [03:24<00:11,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2041/2154 [03:24<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2042/2154 [03:25<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2043/2154 [03:25<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2044/2154 [03:25<00:11,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2045/2154 [03:25<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▍| 2046/2154 [03:25<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2047/2154 [03:25<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2048/2154 [03:25<00:10,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2049/2154 [03:25<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2050/2154 [03:25<00:10,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2051/2154 [03:25<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2052/2154 [03:26<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2053/2154 [03:26<00:10,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2054/2154 [03:26<00:10,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2055/2154 [03:26<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2056/2154 [03:26<00:09,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  95%|█████████▌| 2057/2154 [03:26<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2058/2154 [03:26<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2059/2154 [03:26<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2060/2154 [03:26<00:09,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2061/2154 [03:27<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2062/2154 [03:27<00:09,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2063/2154 [03:27<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2064/2154 [03:27<00:09,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2065/2154 [03:27<00:08,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2066/2154 [03:27<00:08,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2067/2154 [03:27<00:08,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2068/2154 [03:27<00:08,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2069/2154 [03:27<00:08,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2070/2154 [03:27<00:08,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2071/2154 [03:28<00:08,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2072/2154 [03:28<00:08,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▌| 2073/2154 [03:28<00:08,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▋| 2074/2154 [03:28<00:08,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▋| 2075/2154 [03:28<00:07,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▋| 2076/2154 [03:28<00:07,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▋| 2077/2154 [03:28<00:07,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  96%|█████████▋| 2078/2154 [03:28<00:07,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2079/2154 [03:28<00:07,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2080/2154 [03:29<00:07,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2081/2154 [03:29<00:07,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2082/2154 [03:29<00:07,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2083/2154 [03:29<00:07,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2084/2154 [03:29<00:07,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2085/2154 [03:29<00:06,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2086/2154 [03:29<00:06,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2087/2154 [03:29<00:06,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2088/2154 [03:29<00:06,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2089/2154 [03:29<00:06,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2090/2154 [03:30<00:06,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2091/2154 [03:30<00:06,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2092/2154 [03:30<00:06,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2093/2154 [03:30<00:06,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2094/2154 [03:30<00:06,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2095/2154 [03:30<00:05,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2096/2154 [03:30<00:05,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2097/2154 [03:30<00:05,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2098/2154 [03:30<00:05,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2099/2154 [03:30<00:05,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  97%|█████████▋| 2100/2154 [03:30<00:05,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2101/2154 [03:31<00:05,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2102/2154 [03:31<00:05,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2103/2154 [03:31<00:05,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2104/2154 [03:31<00:05,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2105/2154 [03:31<00:04,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2106/2154 [03:31<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2107/2154 [03:31<00:04,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2108/2154 [03:31<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2109/2154 [03:31<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2110/2154 [03:31<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2111/2154 [03:32<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2112/2154 [03:32<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2113/2154 [03:32<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2114/2154 [03:32<00:04,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2115/2154 [03:32<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2116/2154 [03:32<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2117/2154 [03:32<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2118/2154 [03:32<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2119/2154 [03:32<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2120/2154 [03:33<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  98%|█████████▊| 2121/2154 [03:33<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▊| 2122/2154 [03:33<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▊| 2123/2154 [03:33<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▊| 2124/2154 [03:33<00:03,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▊| 2125/2154 [03:33<00:02,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▊| 2126/2154 [03:33<00:02,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▊| 2127/2154 [03:33<00:02,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2128/2154 [03:33<00:02,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2129/2154 [03:33<00:02,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2130/2154 [03:33<00:02,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2131/2154 [03:34<00:02,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2132/2154 [03:34<00:02,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2133/2154 [03:34<00:02,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2134/2154 [03:34<00:02,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2135/2154 [03:34<00:01,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2136/2154 [03:34<00:01,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2137/2154 [03:34<00:01,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2138/2154 [03:34<00:01,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2139/2154 [03:34<00:01,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2140/2154 [03:34<00:01,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2141/2154 [03:35<00:01,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2142/2154 [03:35<00:01,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13:  99%|█████████▉| 2143/2154 [03:35<00:01,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2144/2154 [03:35<00:01,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2145/2154 [03:35<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2146/2154 [03:35<00:00,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2147/2154 [03:35<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2148/2154 [03:35<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2149/2154 [03:35<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2150/2154 [03:35<00:00,  9.95it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2151/2154 [03:36<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2152/2154 [03:36<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|█████████▉| 2153/2154 [03:36<00:00,  9.96it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0969, train_loss_epoch=0.112]\n",
      "Epoch 13: 100%|██████████| 2154/2154 [03:36<00:00,  9.97it/s, loss=0.108, v_num=0, train_loss_step=0.0918, val_loss=0.0959, train_loss_epoch=0.112]\n",
      "Epoch 14:  94%|█████████▍| 2025/2154 [03:30<00:13,  9.64it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  94%|█████████▍| 2026/2154 [03:30<00:13,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2027/2154 [03:30<00:13,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2028/2154 [03:30<00:13,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2029/2154 [03:30<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2030/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2031/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2032/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2033/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2034/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  94%|█████████▍| 2035/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2036/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2037/2154 [03:31<00:12,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2038/2154 [03:31<00:12,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2039/2154 [03:31<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2040/2154 [03:32<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2041/2154 [03:32<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2042/2154 [03:32<00:11,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2043/2154 [03:32<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2044/2154 [03:32<00:11,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2045/2154 [03:32<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▍| 2046/2154 [03:32<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2047/2154 [03:32<00:11,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2048/2154 [03:33<00:11,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2049/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2050/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2051/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2052/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2053/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2054/2154 [03:33<00:10,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2055/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2056/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  95%|█████████▌| 2057/2154 [03:33<00:10,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2058/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2059/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2060/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2061/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2062/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2063/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2064/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2065/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2066/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2067/2154 [03:34<00:09,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2068/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2069/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2070/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2071/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2072/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▌| 2073/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▋| 2074/2154 [03:35<00:08,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▋| 2075/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▋| 2076/2154 [03:35<00:08,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▋| 2077/2154 [03:35<00:08,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  96%|█████████▋| 2078/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2079/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2080/2154 [03:36<00:07,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2081/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2082/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2083/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2084/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2085/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2086/2154 [03:36<00:07,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2087/2154 [03:36<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2088/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2089/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2090/2154 [03:37<00:06,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2091/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2092/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2093/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2094/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2095/2154 [03:37<00:06,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2096/2154 [03:38<00:06,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2097/2154 [03:38<00:05,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2098/2154 [03:38<00:05,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2099/2154 [03:38<00:05,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  97%|█████████▋| 2100/2154 [03:38<00:05,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2101/2154 [03:38<00:05,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2102/2154 [03:38<00:05,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2103/2154 [03:38<00:05,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2104/2154 [03:38<00:05,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2105/2154 [03:38<00:05,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2106/2154 [03:39<00:04,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2107/2154 [03:39<00:04,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2108/2154 [03:39<00:04,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2109/2154 [03:39<00:04,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2110/2154 [03:39<00:04,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2111/2154 [03:39<00:04,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2112/2154 [03:39<00:04,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2113/2154 [03:39<00:04,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2114/2154 [03:39<00:04,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2115/2154 [03:39<00:04,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2116/2154 [03:40<00:03,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2117/2154 [03:40<00:03,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2118/2154 [03:40<00:03,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2119/2154 [03:40<00:03,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2120/2154 [03:40<00:03,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  98%|█████████▊| 2121/2154 [03:40<00:03,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▊| 2122/2154 [03:40<00:03,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▊| 2123/2154 [03:40<00:03,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▊| 2124/2154 [03:40<00:03,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▊| 2125/2154 [03:40<00:03,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▊| 2126/2154 [03:41<00:02,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▊| 2127/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2128/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2129/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2130/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2131/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2132/2154 [03:41<00:02,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2133/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2134/2154 [03:41<00:02,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2135/2154 [03:41<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2136/2154 [03:42<00:01,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2137/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2138/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2139/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2140/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2141/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2142/2154 [03:42<00:01,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14:  99%|█████████▉| 2143/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2144/2154 [03:42<00:01,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2145/2154 [03:42<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2146/2154 [03:43<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2147/2154 [03:43<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2148/2154 [03:43<00:00,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2149/2154 [03:43<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2150/2154 [03:43<00:00,  9.61it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2151/2154 [03:43<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2152/2154 [03:43<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|█████████▉| 2153/2154 [03:43<00:00,  9.62it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.0959, train_loss_epoch=0.111]\n",
      "Epoch 14: 100%|██████████| 2154/2154 [03:43<00:00,  9.63it/s, loss=0.116, v_num=0, train_loss_step=0.103, val_loss=0.100, train_loss_epoch=0.111] \n",
      "Epoch 15:  94%|█████████▍| 2025/2154 [03:36<00:13,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  94%|█████████▍| 2026/2154 [03:36<00:13,  9.35it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2027/2154 [03:36<00:13,  9.35it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2028/2154 [03:36<00:13,  9.35it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2029/2154 [03:36<00:13,  9.35it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2030/2154 [03:37<00:13,  9.35it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2031/2154 [03:37<00:13,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2032/2154 [03:37<00:13,  9.35it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2033/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2034/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  94%|█████████▍| 2035/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2036/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2037/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2038/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2039/2154 [03:37<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2040/2154 [03:38<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2041/2154 [03:38<00:12,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2042/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2043/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2044/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2045/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▍| 2046/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2047/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2048/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2049/2154 [03:38<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2050/2154 [03:39<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2051/2154 [03:39<00:11,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2052/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2053/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2054/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2055/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2056/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  95%|█████████▌| 2057/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2058/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2059/2154 [03:39<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2060/2154 [03:40<00:10,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2061/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2062/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2063/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2064/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2065/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2066/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2067/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2068/2154 [03:40<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2069/2154 [03:41<00:09,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2070/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2071/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2072/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▌| 2073/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▋| 2074/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▋| 2075/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▋| 2076/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▋| 2077/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  96%|█████████▋| 2078/2154 [03:41<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2079/2154 [03:42<00:08,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2080/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2081/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2082/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2083/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2084/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2085/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2086/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2087/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2088/2154 [03:42<00:07,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2089/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2090/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2091/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2092/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2093/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2094/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2095/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2096/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2097/2154 [03:43<00:06,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2098/2154 [03:44<00:05,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2099/2154 [03:44<00:05,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  97%|█████████▋| 2100/2154 [03:44<00:05,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2101/2154 [03:44<00:05,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2102/2154 [03:44<00:05,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2103/2154 [03:44<00:05,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2104/2154 [03:44<00:05,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2105/2154 [03:44<00:05,  9.36it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2106/2154 [03:44<00:05,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2107/2154 [03:44<00:05,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2108/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2109/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2110/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2111/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2112/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2113/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2114/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2115/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2116/2154 [03:45<00:04,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2117/2154 [03:45<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2118/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2119/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2120/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  98%|█████████▊| 2121/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▊| 2122/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▊| 2123/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▊| 2124/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▊| 2125/2154 [03:46<00:03,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▊| 2126/2154 [03:46<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▊| 2127/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2128/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2129/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2130/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2131/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2132/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2133/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2134/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2135/2154 [03:47<00:02,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2136/2154 [03:47<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2137/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2138/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2139/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2140/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2141/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2142/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15:  99%|█████████▉| 2143/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2144/2154 [03:48<00:01,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2145/2154 [03:48<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2146/2154 [03:48<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2147/2154 [03:49<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2148/2154 [03:49<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2149/2154 [03:49<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2150/2154 [03:49<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2151/2154 [03:49<00:00,  9.37it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2152/2154 [03:49<00:00,  9.38it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|█████████▉| 2153/2154 [03:49<00:00,  9.38it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.100, train_loss_epoch=0.110]\n",
      "Epoch 15: 100%|██████████| 2154/2154 [03:49<00:00,  9.38it/s, loss=0.106, v_num=0, train_loss_step=0.117, val_loss=0.097, train_loss_epoch=0.110]\n",
      "Epoch 16:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.58it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2027/2154 [03:32<00:13,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2028/2154 [03:32<00:13,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2029/2154 [03:32<00:13,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2034/2154 [03:32<00:12,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  94%|█████████▍| 2035/2154 [03:32<00:12,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.56it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2038/2154 [03:33<00:12,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2039/2154 [03:33<00:12,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2047/2154 [03:34<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2048/2154 [03:34<00:11,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2049/2154 [03:34<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2055/2154 [03:35<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2056/2154 [03:35<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  95%|█████████▌| 2057/2154 [03:35<00:10,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.55it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2065/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2066/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2067/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2068/2154 [03:36<00:09,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2071/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2072/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▌| 2073/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▋| 2074/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▋| 2075/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▋| 2076/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▋| 2077/2154 [03:37<00:08,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2080/2154 [03:38<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2081/2154 [03:38<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2082/2154 [03:38<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2084/2154 [03:38<00:07,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2085/2154 [03:38<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2086/2154 [03:38<00:07,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2087/2154 [03:38<00:07,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2089/2154 [03:39<00:06,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2091/2154 [03:39<00:06,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2092/2154 [03:39<00:06,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2093/2154 [03:39<00:06,  9.54it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2094/2154 [03:39<00:06,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2095/2154 [03:39<00:06,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2098/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2099/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2101/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2102/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2103/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2104/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2105/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2107/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2108/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2109/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2110/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2111/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2112/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2113/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2114/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2117/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2119/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2120/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  98%|█████████▊| 2121/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▊| 2122/2154 [03:42<00:03,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▊| 2125/2154 [03:43<00:03,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▊| 2126/2154 [03:43<00:02,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▊| 2127/2154 [03:43<00:02,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2130/2154 [03:43<00:02,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2131/2154 [03:43<00:02,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2132/2154 [03:43<00:02,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2134/2154 [03:44<00:02,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2135/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2136/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2137/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2138/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2139/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2140/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2141/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16:  99%|█████████▉| 2143/2154 [03:45<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2144/2154 [03:45<00:01,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2145/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2146/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2148/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2149/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2150/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2151/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2152/2154 [03:45<00:00,  9.52it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|█████████▉| 2153/2154 [03:45<00:00,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.097, train_loss_epoch=0.108]\n",
      "Epoch 16: 100%|██████████| 2154/2154 [03:45<00:00,  9.53it/s, loss=0.112, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.108]\n",
      "Epoch 17:  94%|█████████▍| 2025/2154 [03:49<00:14,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  94%|█████████▍| 2026/2154 [03:50<00:14,  8.79it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2027/2154 [03:50<00:14,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2028/2154 [03:50<00:14,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2029/2154 [03:50<00:14,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2030/2154 [03:50<00:14,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2031/2154 [03:50<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2032/2154 [03:50<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2033/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2034/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  94%|█████████▍| 2035/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2036/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2037/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2038/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2039/2154 [03:51<00:13,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2040/2154 [03:51<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2041/2154 [03:51<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2042/2154 [03:52<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2043/2154 [03:52<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2044/2154 [03:52<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2045/2154 [03:52<00:12,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▍| 2046/2154 [03:52<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2047/2154 [03:52<00:12,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2048/2154 [03:52<00:12,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2049/2154 [03:52<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2050/2154 [03:52<00:11,  8.80it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2051/2154 [03:52<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2052/2154 [03:53<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2053/2154 [03:53<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2054/2154 [03:53<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2055/2154 [03:53<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2056/2154 [03:53<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  95%|█████████▌| 2057/2154 [03:53<00:11,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2058/2154 [03:53<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2059/2154 [03:53<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2060/2154 [03:53<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2061/2154 [03:53<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2062/2154 [03:54<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2063/2154 [03:54<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2064/2154 [03:54<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2065/2154 [03:54<00:10,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2066/2154 [03:54<00:09,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2067/2154 [03:54<00:09,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2068/2154 [03:54<00:09,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2069/2154 [03:54<00:09,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2070/2154 [03:54<00:09,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2071/2154 [03:54<00:09,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2072/2154 [03:55<00:09,  8.81it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▌| 2073/2154 [03:55<00:09,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▋| 2074/2154 [03:55<00:09,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▋| 2075/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▋| 2076/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▋| 2077/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  96%|█████████▋| 2078/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2079/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2080/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2081/2154 [03:55<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2082/2154 [03:56<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2083/2154 [03:56<00:08,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2084/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2085/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2086/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2087/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2088/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2089/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2090/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2091/2154 [03:56<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2092/2154 [03:57<00:07,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2093/2154 [03:57<00:06,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2094/2154 [03:57<00:06,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2095/2154 [03:57<00:06,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2096/2154 [03:57<00:06,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2097/2154 [03:57<00:06,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2098/2154 [03:57<00:06,  8.82it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2099/2154 [03:57<00:06,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  97%|█████████▋| 2100/2154 [03:57<00:06,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2101/2154 [03:58<00:06,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2102/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2103/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2104/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2105/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2106/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2107/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2108/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2109/2154 [03:58<00:05,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2110/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2111/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2112/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2113/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2114/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2115/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2116/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2117/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2118/2154 [03:59<00:04,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2119/2154 [03:59<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2120/2154 [04:00<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  98%|█████████▊| 2121/2154 [04:00<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▊| 2122/2154 [04:00<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▊| 2123/2154 [04:00<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▊| 2124/2154 [04:00<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▊| 2125/2154 [04:00<00:03,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▊| 2126/2154 [04:00<00:03,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▊| 2127/2154 [04:00<00:03,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2128/2154 [04:00<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2129/2154 [04:00<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2130/2154 [04:01<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2131/2154 [04:01<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2132/2154 [04:01<00:02,  8.83it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2133/2154 [04:01<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2134/2154 [04:01<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2135/2154 [04:01<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2136/2154 [04:01<00:02,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2137/2154 [04:01<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2138/2154 [04:01<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2139/2154 [04:01<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2140/2154 [04:02<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2141/2154 [04:02<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2142/2154 [04:02<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17:  99%|█████████▉| 2143/2154 [04:02<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2144/2154 [04:02<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2145/2154 [04:02<00:01,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2146/2154 [04:02<00:00,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2147/2154 [04:02<00:00,  8.85it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2148/2154 [04:02<00:00,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2149/2154 [04:02<00:00,  8.85it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2150/2154 [04:03<00:00,  8.84it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2151/2154 [04:03<00:00,  8.85it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2152/2154 [04:03<00:00,  8.85it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|█████████▉| 2153/2154 [04:03<00:00,  8.85it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0975, train_loss_epoch=0.109]\n",
      "Epoch 17: 100%|██████████| 2154/2154 [04:03<00:00,  8.86it/s, loss=0.111, v_num=0, train_loss_step=0.120, val_loss=0.0978, train_loss_epoch=0.109]\n",
      "Epoch 18:  94%|█████████▍| 2025/2154 [03:26<00:13,  9.80it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  94%|█████████▍| 2026/2154 [03:27<00:13,  9.78it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2027/2154 [03:27<00:12,  9.78it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2028/2154 [03:27<00:12,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2029/2154 [03:27<00:12,  9.78it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2030/2154 [03:27<00:12,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2031/2154 [03:27<00:12,  9.78it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2032/2154 [03:27<00:12,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2033/2154 [03:27<00:12,  9.78it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2034/2154 [03:28<00:12,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  94%|█████████▍| 2035/2154 [03:28<00:12,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2036/2154 [03:28<00:12,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2037/2154 [03:28<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2038/2154 [03:28<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2039/2154 [03:28<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2040/2154 [03:28<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2041/2154 [03:28<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2042/2154 [03:29<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2043/2154 [03:29<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2044/2154 [03:29<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2045/2154 [03:29<00:11,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▍| 2046/2154 [03:29<00:11,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2047/2154 [03:29<00:10,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2048/2154 [03:29<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2049/2154 [03:29<00:10,  9.77it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2050/2154 [03:29<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2051/2154 [03:30<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2052/2154 [03:30<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2053/2154 [03:30<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2054/2154 [03:30<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2055/2154 [03:30<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2056/2154 [03:30<00:10,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  95%|█████████▌| 2057/2154 [03:30<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2058/2154 [03:30<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2059/2154 [03:30<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2060/2154 [03:31<00:09,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2061/2154 [03:31<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2062/2154 [03:31<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2063/2154 [03:31<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2064/2154 [03:31<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2065/2154 [03:31<00:09,  9.76it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2066/2154 [03:31<00:09,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2067/2154 [03:31<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2068/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2069/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2070/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2071/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2072/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▌| 2073/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▋| 2074/2154 [03:32<00:08,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▋| 2075/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▋| 2076/2154 [03:32<00:08,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▋| 2077/2154 [03:33<00:07,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  96%|█████████▋| 2078/2154 [03:33<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2079/2154 [03:33<00:07,  9.75it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2080/2154 [03:33<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2081/2154 [03:33<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2082/2154 [03:33<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2083/2154 [03:33<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2084/2154 [03:33<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2085/2154 [03:34<00:07,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2086/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2087/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2088/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2089/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2090/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2091/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2092/2154 [03:34<00:06,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2093/2154 [03:34<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2094/2154 [03:35<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2095/2154 [03:35<00:06,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2096/2154 [03:35<00:05,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2097/2154 [03:35<00:05,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2098/2154 [03:35<00:05,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2099/2154 [03:35<00:05,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  97%|█████████▋| 2100/2154 [03:35<00:05,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2101/2154 [03:35<00:05,  9.74it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2102/2154 [03:35<00:05,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2103/2154 [03:36<00:05,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2104/2154 [03:36<00:05,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2105/2154 [03:36<00:05,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2106/2154 [03:36<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2107/2154 [03:36<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2108/2154 [03:36<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2109/2154 [03:36<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2110/2154 [03:36<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2111/2154 [03:36<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2112/2154 [03:37<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2113/2154 [03:37<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2114/2154 [03:37<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2115/2154 [03:37<00:04,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2116/2154 [03:37<00:03,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2117/2154 [03:37<00:03,  9.73it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2118/2154 [03:37<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2119/2154 [03:37<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2120/2154 [03:38<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  98%|█████████▊| 2121/2154 [03:38<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▊| 2122/2154 [03:38<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▊| 2123/2154 [03:38<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▊| 2124/2154 [03:38<00:03,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▊| 2125/2154 [03:38<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▊| 2126/2154 [03:38<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▊| 2127/2154 [03:38<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2128/2154 [03:38<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2129/2154 [03:39<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2130/2154 [03:39<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2131/2154 [03:39<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2132/2154 [03:39<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2133/2154 [03:39<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2134/2154 [03:39<00:02,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2135/2154 [03:39<00:01,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2136/2154 [03:39<00:01,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2137/2154 [03:39<00:01,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2138/2154 [03:40<00:01,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2139/2154 [03:40<00:01,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2140/2154 [03:40<00:01,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2141/2154 [03:40<00:01,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2142/2154 [03:40<00:01,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18:  99%|█████████▉| 2143/2154 [03:40<00:01,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2144/2154 [03:40<00:01,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2145/2154 [03:40<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2146/2154 [03:40<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2147/2154 [03:41<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2148/2154 [03:41<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2149/2154 [03:41<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2150/2154 [03:41<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2151/2154 [03:41<00:00,  9.71it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2152/2154 [03:41<00:00,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|█████████▉| 2153/2154 [03:41<00:00,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.0978, train_loss_epoch=0.107]\n",
      "Epoch 18: 100%|██████████| 2154/2154 [03:41<00:00,  9.72it/s, loss=0.104, v_num=0, train_loss_step=0.128, val_loss=0.098, train_loss_epoch=0.107] \n",
      "Epoch 19:  94%|█████████▍| 2025/2154 [03:28<00:13,  9.69it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  94%|█████████▍| 2026/2154 [03:29<00:13,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2027/2154 [03:29<00:13,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2028/2154 [03:29<00:13,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2029/2154 [03:29<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2030/2154 [03:29<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2031/2154 [03:29<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2032/2154 [03:30<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2033/2154 [03:30<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2034/2154 [03:30<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  94%|█████████▍| 2035/2154 [03:30<00:12,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2036/2154 [03:30<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2037/2154 [03:30<00:12,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2038/2154 [03:30<00:11,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2039/2154 [03:30<00:11,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2040/2154 [03:30<00:11,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2041/2154 [03:30<00:11,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2042/2154 [03:31<00:11,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2043/2154 [03:31<00:11,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2044/2154 [03:31<00:11,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2045/2154 [03:31<00:11,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▍| 2046/2154 [03:31<00:11,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2047/2154 [03:31<00:11,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2048/2154 [03:31<00:10,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2049/2154 [03:31<00:10,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2050/2154 [03:31<00:10,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2051/2154 [03:31<00:10,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2052/2154 [03:32<00:10,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2053/2154 [03:32<00:10,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2054/2154 [03:32<00:10,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2055/2154 [03:32<00:10,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2056/2154 [03:32<00:10,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  95%|█████████▌| 2057/2154 [03:32<00:10,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2058/2154 [03:32<00:09,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2059/2154 [03:32<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2060/2154 [03:32<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2061/2154 [03:32<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2062/2154 [03:33<00:09,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2063/2154 [03:33<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2064/2154 [03:33<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2065/2154 [03:33<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2066/2154 [03:33<00:09,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2067/2154 [03:33<00:08,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2068/2154 [03:33<00:08,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2069/2154 [03:33<00:08,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2070/2154 [03:33<00:08,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2071/2154 [03:33<00:08,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2072/2154 [03:34<00:08,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▌| 2073/2154 [03:34<00:08,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▋| 2074/2154 [03:34<00:08,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▋| 2075/2154 [03:34<00:08,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▋| 2076/2154 [03:34<00:08,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▋| 2077/2154 [03:34<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  96%|█████████▋| 2078/2154 [03:34<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2079/2154 [03:34<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2080/2154 [03:35<00:07,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2081/2154 [03:35<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2082/2154 [03:35<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2083/2154 [03:35<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2084/2154 [03:35<00:07,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2085/2154 [03:35<00:07,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2086/2154 [03:35<00:07,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2087/2154 [03:35<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2088/2154 [03:35<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2089/2154 [03:35<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2090/2154 [03:36<00:06,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2091/2154 [03:36<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2092/2154 [03:36<00:06,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2093/2154 [03:36<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2094/2154 [03:36<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2095/2154 [03:36<00:06,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2096/2154 [03:36<00:05,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2097/2154 [03:36<00:05,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2098/2154 [03:36<00:05,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2099/2154 [03:36<00:05,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  97%|█████████▋| 2100/2154 [03:37<00:05,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2101/2154 [03:37<00:05,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2102/2154 [03:37<00:05,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2103/2154 [03:37<00:05,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2104/2154 [03:37<00:05,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2105/2154 [03:37<00:05,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2106/2154 [03:37<00:04,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2107/2154 [03:37<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2108/2154 [03:37<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2109/2154 [03:37<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2110/2154 [03:38<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2111/2154 [03:38<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2112/2154 [03:38<00:04,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2113/2154 [03:38<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2114/2154 [03:38<00:04,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2115/2154 [03:38<00:04,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2116/2154 [03:38<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2117/2154 [03:38<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2118/2154 [03:38<00:03,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2119/2154 [03:38<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2120/2154 [03:39<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  98%|█████████▊| 2121/2154 [03:39<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▊| 2122/2154 [03:39<00:03,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▊| 2123/2154 [03:39<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▊| 2124/2154 [03:39<00:03,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▊| 2125/2154 [03:39<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▊| 2126/2154 [03:39<00:02,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▊| 2127/2154 [03:39<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2128/2154 [03:39<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2129/2154 [03:39<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2130/2154 [03:40<00:02,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2131/2154 [03:40<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2132/2154 [03:40<00:02,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2133/2154 [03:40<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2134/2154 [03:40<00:02,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2135/2154 [03:40<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2136/2154 [03:40<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2137/2154 [03:40<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2138/2154 [03:41<00:01,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2139/2154 [03:41<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2140/2154 [03:41<00:01,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2141/2154 [03:41<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2142/2154 [03:41<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19:  99%|█████████▉| 2143/2154 [03:41<00:01,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2144/2154 [03:41<00:01,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2145/2154 [03:41<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2146/2154 [03:41<00:00,  9.67it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2147/2154 [03:41<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2148/2154 [03:41<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2149/2154 [03:42<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2150/2154 [03:42<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2151/2154 [03:42<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2152/2154 [03:42<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|█████████▉| 2153/2154 [03:42<00:00,  9.68it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.098, train_loss_epoch=0.107]\n",
      "Epoch 19: 100%|██████████| 2154/2154 [03:42<00:00,  9.69it/s, loss=0.113, v_num=0, train_loss_step=0.103, val_loss=0.101, train_loss_epoch=0.107]\n",
      "Epoch 20:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.58it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  94%|█████████▍| 2026/2154 [03:31<00:13,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2027/2154 [03:31<00:13,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2028/2154 [03:32<00:13,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2029/2154 [03:32<00:13,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2034/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  94%|█████████▍| 2035/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2036/2154 [03:32<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2038/2154 [03:33<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2039/2154 [03:33<00:12,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2044/2154 [03:33<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2045/2154 [03:33<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2047/2154 [03:34<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2048/2154 [03:34<00:11,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2049/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2053/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2054/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2055/2154 [03:34<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2056/2154 [03:35<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  95%|█████████▌| 2057/2154 [03:35<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2062/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2063/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2064/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2065/2154 [03:35<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2066/2154 [03:36<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2067/2154 [03:36<00:09,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2068/2154 [03:36<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2072/2154 [03:36<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▌| 2073/2154 [03:36<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▋| 2074/2154 [03:37<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▋| 2075/2154 [03:37<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▋| 2076/2154 [03:37<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▋| 2077/2154 [03:37<00:08,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2082/2154 [03:37<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2083/2154 [03:37<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2084/2154 [03:38<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2085/2154 [03:38<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2086/2154 [03:38<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2087/2154 [03:38<00:07,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2091/2154 [03:38<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2092/2154 [03:38<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2093/2154 [03:38<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2094/2154 [03:39<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2095/2154 [03:39<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  97%|█████████▋| 2100/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2101/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2102/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2103/2154 [03:39<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2104/2154 [03:40<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2105/2154 [03:40<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2110/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2111/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2112/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2113/2154 [03:40<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2114/2154 [03:41<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2120/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  98%|█████████▊| 2121/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▊| 2122/2154 [03:41<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2129/2154 [03:42<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2130/2154 [03:42<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2131/2154 [03:42<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2132/2154 [03:43<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2134/2154 [03:43<00:02,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2139/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2140/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2141/2154 [03:43<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20:  99%|█████████▉| 2143/2154 [03:44<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2149/2154 [03:44<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2150/2154 [03:44<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2151/2154 [03:45<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2152/2154 [03:45<00:00,  9.56it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|█████████▉| 2153/2154 [03:45<00:00,  9.57it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.101, train_loss_epoch=0.106]\n",
      "Epoch 20: 100%|██████████| 2154/2154 [03:45<00:00,  9.57it/s, loss=0.109, v_num=0, train_loss_step=0.0582, val_loss=0.0944, train_loss_epoch=0.106]\n",
      "Epoch 21:  94%|█████████▍| 2025/2154 [03:32<00:13,  9.54it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2027/2154 [03:33<00:13,  9.52it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2028/2154 [03:33<00:13,  9.52it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2029/2154 [03:33<00:13,  9.52it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2030/2154 [03:33<00:13,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2031/2154 [03:33<00:12,  9.52it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2032/2154 [03:33<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2033/2154 [03:33<00:12,  9.52it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2036/2154 [03:34<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2037/2154 [03:34<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2038/2154 [03:34<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2039/2154 [03:34<00:12,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2040/2154 [03:34<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2041/2154 [03:34<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2042/2154 [03:34<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2043/2154 [03:34<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▍| 2046/2154 [03:35<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2047/2154 [03:35<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2048/2154 [03:35<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2049/2154 [03:35<00:11,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2050/2154 [03:35<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2051/2154 [03:35<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2052/2154 [03:35<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2055/2154 [03:36<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2056/2154 [03:36<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  95%|█████████▌| 2057/2154 [03:36<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2058/2154 [03:36<00:10,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2059/2154 [03:36<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2060/2154 [03:36<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2061/2154 [03:36<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2064/2154 [03:37<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2065/2154 [03:37<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2066/2154 [03:37<00:09,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2067/2154 [03:37<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2068/2154 [03:37<00:09,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2069/2154 [03:37<00:08,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2070/2154 [03:37<00:08,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2071/2154 [03:37<00:08,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2072/2154 [03:38<00:08,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▌| 2073/2154 [03:38<00:08,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▋| 2074/2154 [03:38<00:08,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▋| 2075/2154 [03:38<00:08,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▋| 2076/2154 [03:38<00:08,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▋| 2077/2154 [03:38<00:08,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  96%|█████████▋| 2078/2154 [03:38<00:07,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2079/2154 [03:38<00:07,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2080/2154 [03:38<00:07,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2081/2154 [03:38<00:07,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2082/2154 [03:39<00:07,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2083/2154 [03:39<00:07,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2084/2154 [03:39<00:07,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2085/2154 [03:39<00:07,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2086/2154 [03:39<00:07,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2087/2154 [03:39<00:07,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2088/2154 [03:39<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2089/2154 [03:39<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2091/2154 [03:40<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2092/2154 [03:40<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2093/2154 [03:40<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2094/2154 [03:40<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2095/2154 [03:40<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2096/2154 [03:40<00:06,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2097/2154 [03:40<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2098/2154 [03:40<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2099/2154 [03:40<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2101/2154 [03:41<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2102/2154 [03:41<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2103/2154 [03:41<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2104/2154 [03:41<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2105/2154 [03:41<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2106/2154 [03:41<00:05,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2107/2154 [03:41<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2108/2154 [03:41<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2109/2154 [03:41<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2110/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2111/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2112/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2113/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2114/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2115/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2116/2154 [03:42<00:04,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2117/2154 [03:42<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2119/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2120/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  98%|█████████▊| 2121/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▊| 2122/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▊| 2123/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▊| 2124/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▊| 2125/2154 [03:43<00:03,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▊| 2126/2154 [03:43<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▊| 2127/2154 [03:43<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2129/2154 [03:44<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2130/2154 [03:44<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2131/2154 [03:44<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2132/2154 [03:44<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2133/2154 [03:44<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2134/2154 [03:44<00:02,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2135/2154 [03:44<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2136/2154 [03:44<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2137/2154 [03:44<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2138/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2139/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2140/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2141/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2142/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21:  99%|█████████▉| 2143/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2144/2154 [03:45<00:01,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2145/2154 [03:45<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2146/2154 [03:45<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2148/2154 [03:46<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2149/2154 [03:46<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2150/2154 [03:46<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2151/2154 [03:46<00:00,  9.50it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2152/2154 [03:46<00:00,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|█████████▉| 2153/2154 [03:46<00:00,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.0944, train_loss_epoch=0.105]\n",
      "Epoch 21: 100%|██████████| 2154/2154 [03:46<00:00,  9.51it/s, loss=0.11, v_num=0, train_loss_step=0.0943, val_loss=0.100, train_loss_epoch=0.105] \n",
      "Epoch 22:  94%|█████████▍| 2025/2154 [03:32<00:13,  9.53it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2027/2154 [03:33<00:13,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2028/2154 [03:33<00:13,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2029/2154 [03:33<00:13,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2030/2154 [03:33<00:13,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2031/2154 [03:33<00:12,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2032/2154 [03:33<00:12,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2033/2154 [03:33<00:12,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2037/2154 [03:34<00:12,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2038/2154 [03:34<00:12,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2039/2154 [03:34<00:12,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2040/2154 [03:34<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2041/2154 [03:34<00:11,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2042/2154 [03:34<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2043/2154 [03:34<00:11,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▍| 2046/2154 [03:35<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2047/2154 [03:35<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2048/2154 [03:35<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2049/2154 [03:35<00:11,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2050/2154 [03:35<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2051/2154 [03:35<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2052/2154 [03:35<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2055/2154 [03:36<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2056/2154 [03:36<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  95%|█████████▌| 2057/2154 [03:36<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2058/2154 [03:36<00:10,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2059/2154 [03:36<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2060/2154 [03:36<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2061/2154 [03:36<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2065/2154 [03:37<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2066/2154 [03:37<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2067/2154 [03:37<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2068/2154 [03:37<00:09,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2069/2154 [03:37<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2070/2154 [03:37<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2071/2154 [03:37<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2072/2154 [03:37<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▌| 2073/2154 [03:37<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▋| 2074/2154 [03:38<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▋| 2075/2154 [03:38<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▋| 2076/2154 [03:38<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▋| 2077/2154 [03:38<00:08,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  96%|█████████▋| 2078/2154 [03:38<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2079/2154 [03:38<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2080/2154 [03:38<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2081/2154 [03:38<00:07,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2082/2154 [03:38<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2084/2154 [03:39<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2085/2154 [03:39<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2086/2154 [03:39<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2087/2154 [03:39<00:07,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2088/2154 [03:39<00:06,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2089/2154 [03:39<00:06,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2091/2154 [03:39<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2092/2154 [03:39<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2093/2154 [03:39<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2094/2154 [03:40<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2095/2154 [03:40<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2096/2154 [03:40<00:06,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2097/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2098/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2099/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2101/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2102/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2103/2154 [03:40<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2104/2154 [03:41<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2105/2154 [03:41<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2106/2154 [03:41<00:05,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2107/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2108/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2109/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2110/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2111/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2112/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2113/2154 [03:41<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2114/2154 [03:42<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2115/2154 [03:42<00:04,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2116/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2117/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2119/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2120/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  98%|█████████▊| 2121/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▊| 2122/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▊| 2124/2154 [03:43<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▊| 2125/2154 [03:43<00:03,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▊| 2126/2154 [03:43<00:02,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▊| 2127/2154 [03:43<00:02,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2130/2154 [03:43<00:02,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2131/2154 [03:44<00:02,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2132/2154 [03:44<00:02,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2133/2154 [03:44<00:02,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2134/2154 [03:44<00:02,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2135/2154 [03:44<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2136/2154 [03:44<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2137/2154 [03:44<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2138/2154 [03:44<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2139/2154 [03:44<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2140/2154 [03:44<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2141/2154 [03:45<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2142/2154 [03:45<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22:  99%|█████████▉| 2143/2154 [03:45<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2144/2154 [03:45<00:01,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2145/2154 [03:45<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2146/2154 [03:45<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2148/2154 [03:45<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2149/2154 [03:45<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2150/2154 [03:46<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2151/2154 [03:46<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2152/2154 [03:46<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|█████████▉| 2153/2154 [03:46<00:00,  9.51it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.100, train_loss_epoch=0.105]\n",
      "Epoch 22: 100%|██████████| 2154/2154 [03:46<00:00,  9.52it/s, loss=0.105, v_num=0, train_loss_step=0.115, val_loss=0.0953, train_loss_epoch=0.105]\n",
      "Epoch 23:  94%|█████████▍| 2025/2154 [03:33<00:13,  9.50it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  94%|█████████▍| 2026/2154 [03:33<00:13,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2027/2154 [03:33<00:13,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2028/2154 [03:33<00:13,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2029/2154 [03:34<00:13,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2030/2154 [03:34<00:13,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2031/2154 [03:34<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2032/2154 [03:34<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2033/2154 [03:34<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2034/2154 [03:34<00:12,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  94%|█████████▍| 2035/2154 [03:34<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2036/2154 [03:34<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2037/2154 [03:34<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2038/2154 [03:35<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2039/2154 [03:35<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2040/2154 [03:35<00:12,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2041/2154 [03:35<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2042/2154 [03:35<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2043/2154 [03:35<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2044/2154 [03:35<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2045/2154 [03:35<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▍| 2046/2154 [03:35<00:11,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2047/2154 [03:36<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2048/2154 [03:36<00:11,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2049/2154 [03:36<00:11,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2050/2154 [03:36<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2051/2154 [03:36<00:10,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2052/2154 [03:36<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2053/2154 [03:36<00:10,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2054/2154 [03:36<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2055/2154 [03:36<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2056/2154 [03:37<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  95%|█████████▌| 2057/2154 [03:37<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2058/2154 [03:37<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2059/2154 [03:37<00:10,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2060/2154 [03:37<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2061/2154 [03:37<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2062/2154 [03:37<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2063/2154 [03:37<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2064/2154 [03:37<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2065/2154 [03:38<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2066/2154 [03:38<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2067/2154 [03:38<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2068/2154 [03:38<00:09,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2069/2154 [03:38<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2070/2154 [03:38<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2071/2154 [03:38<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2072/2154 [03:38<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▌| 2073/2154 [03:38<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▋| 2074/2154 [03:38<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▋| 2075/2154 [03:39<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▋| 2076/2154 [03:39<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▋| 2077/2154 [03:39<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  96%|█████████▋| 2078/2154 [03:39<00:08,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2079/2154 [03:39<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2080/2154 [03:39<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2081/2154 [03:39<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2082/2154 [03:39<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2083/2154 [03:39<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2084/2154 [03:40<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2085/2154 [03:40<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2086/2154 [03:40<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2087/2154 [03:40<00:07,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2088/2154 [03:40<00:06,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2089/2154 [03:40<00:06,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2090/2154 [03:40<00:06,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2091/2154 [03:40<00:06,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2092/2154 [03:40<00:06,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2093/2154 [03:40<00:06,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2094/2154 [03:41<00:06,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2095/2154 [03:41<00:06,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2096/2154 [03:41<00:06,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2097/2154 [03:41<00:06,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2098/2154 [03:41<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2099/2154 [03:41<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  97%|█████████▋| 2100/2154 [03:41<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2101/2154 [03:41<00:05,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2102/2154 [03:41<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2103/2154 [03:41<00:05,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2104/2154 [03:42<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2105/2154 [03:42<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2106/2154 [03:42<00:05,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2107/2154 [03:42<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2108/2154 [03:42<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2109/2154 [03:42<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2110/2154 [03:42<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2111/2154 [03:42<00:04,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2112/2154 [03:42<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2113/2154 [03:43<00:04,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2114/2154 [03:43<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2115/2154 [03:43<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2116/2154 [03:43<00:04,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2117/2154 [03:43<00:03,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2118/2154 [03:43<00:03,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2119/2154 [03:43<00:03,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2120/2154 [03:43<00:03,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  98%|█████████▊| 2121/2154 [03:43<00:03,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▊| 2122/2154 [03:43<00:03,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▊| 2123/2154 [03:44<00:03,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▊| 2124/2154 [03:44<00:03,  9.47it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▊| 2125/2154 [03:44<00:03,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▊| 2126/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▊| 2127/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2128/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2129/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2130/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2131/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2132/2154 [03:44<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2133/2154 [03:45<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2134/2154 [03:45<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2135/2154 [03:45<00:02,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2136/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2137/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2138/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2139/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2140/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2141/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2142/2154 [03:45<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23:  99%|█████████▉| 2143/2154 [03:46<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2144/2154 [03:46<00:01,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2145/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2146/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2147/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2148/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2149/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2150/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2151/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2152/2154 [03:46<00:00,  9.48it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|█████████▉| 2153/2154 [03:46<00:00,  9.49it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0953, train_loss_epoch=0.104]\n",
      "Epoch 23: 100%|██████████| 2154/2154 [03:46<00:00,  9.49it/s, loss=0.101, v_num=0, train_loss_step=0.075, val_loss=0.0971, train_loss_epoch=0.104]\n",
      "Epoch 24:  94%|█████████▍| 2025/2154 [03:30<00:13,  9.63it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  94%|█████████▍| 2026/2154 [03:30<00:13,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2027/2154 [03:30<00:13,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2028/2154 [03:31<00:13,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2029/2154 [03:31<00:13,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2030/2154 [03:31<00:12,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2031/2154 [03:31<00:12,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2032/2154 [03:31<00:12,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2033/2154 [03:31<00:12,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2034/2154 [03:31<00:12,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  94%|█████████▍| 2035/2154 [03:31<00:12,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2036/2154 [03:31<00:12,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2037/2154 [03:31<00:12,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2038/2154 [03:31<00:12,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2039/2154 [03:32<00:11,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2040/2154 [03:32<00:11,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2041/2154 [03:32<00:11,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2042/2154 [03:32<00:11,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2043/2154 [03:32<00:11,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2044/2154 [03:32<00:11,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2045/2154 [03:32<00:11,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▍| 2046/2154 [03:32<00:11,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2047/2154 [03:32<00:11,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2048/2154 [03:33<00:11,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2049/2154 [03:33<00:10,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2050/2154 [03:33<00:10,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2051/2154 [03:33<00:10,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2052/2154 [03:33<00:10,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2053/2154 [03:33<00:10,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2054/2154 [03:33<00:10,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2055/2154 [03:33<00:10,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2056/2154 [03:33<00:10,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  95%|█████████▌| 2057/2154 [03:33<00:10,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2058/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2059/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2060/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2061/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2062/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2063/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2064/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2065/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2066/2154 [03:34<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2067/2154 [03:35<00:09,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2068/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2069/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2070/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2071/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2072/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▌| 2073/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▋| 2074/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▋| 2075/2154 [03:35<00:08,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▋| 2076/2154 [03:35<00:08,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▋| 2077/2154 [03:35<00:08,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  96%|█████████▋| 2078/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2079/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2080/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2081/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2082/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2083/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2084/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2085/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2086/2154 [03:36<00:07,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2087/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2088/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2089/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2090/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2091/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2092/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2093/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2094/2154 [03:37<00:06,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2095/2154 [03:37<00:06,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2096/2154 [03:37<00:06,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2097/2154 [03:38<00:05,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2098/2154 [03:38<00:05,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2099/2154 [03:38<00:05,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  97%|█████████▋| 2100/2154 [03:38<00:05,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2101/2154 [03:38<00:05,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2102/2154 [03:38<00:05,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2103/2154 [03:38<00:05,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2104/2154 [03:38<00:05,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2105/2154 [03:38<00:05,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2106/2154 [03:39<00:04,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2107/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2108/2154 [03:39<00:04,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2109/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2110/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2111/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2112/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2113/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2114/2154 [03:39<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2115/2154 [03:40<00:04,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2116/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2117/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2118/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2119/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2120/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  98%|█████████▊| 2121/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▊| 2122/2154 [03:40<00:03,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▊| 2123/2154 [03:40<00:03,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▊| 2124/2154 [03:40<00:03,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▊| 2125/2154 [03:41<00:03,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▊| 2126/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▊| 2127/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2128/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2129/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2130/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2131/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2132/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2133/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2134/2154 [03:41<00:02,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2135/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2136/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2137/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2138/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2139/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2140/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2141/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2142/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24:  99%|█████████▉| 2143/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2144/2154 [03:42<00:01,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2145/2154 [03:43<00:00,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2146/2154 [03:43<00:00,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2147/2154 [03:43<00:00,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2148/2154 [03:43<00:00,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2149/2154 [03:43<00:00,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2150/2154 [03:43<00:00,  9.61it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2151/2154 [03:43<00:00,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2152/2154 [03:43<00:00,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|█████████▉| 2153/2154 [03:43<00:00,  9.62it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0971, train_loss_epoch=0.103]\n",
      "Epoch 24: 100%|██████████| 2154/2154 [03:43<00:00,  9.63it/s, loss=0.105, v_num=0, train_loss_step=0.111, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.57it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2027/2154 [03:32<00:13,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2028/2154 [03:32<00:13,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2029/2154 [03:32<00:13,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2038/2154 [03:33<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2039/2154 [03:33<00:12,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2047/2154 [03:34<00:11,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2048/2154 [03:34<00:11,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2049/2154 [03:34<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2055/2154 [03:35<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2056/2154 [03:35<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  95%|█████████▌| 2057/2154 [03:35<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2065/2154 [03:36<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2066/2154 [03:36<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2067/2154 [03:36<00:09,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2068/2154 [03:36<00:09,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2072/2154 [03:37<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▌| 2073/2154 [03:37<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▋| 2074/2154 [03:37<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▋| 2075/2154 [03:37<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▋| 2076/2154 [03:37<00:08,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▋| 2077/2154 [03:37<00:08,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2082/2154 [03:38<00:07,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2084/2154 [03:38<00:07,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2085/2154 [03:38<00:07,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2086/2154 [03:38<00:07,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2087/2154 [03:38<00:07,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2091/2154 [03:39<00:06,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2092/2154 [03:39<00:06,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2093/2154 [03:39<00:06,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2094/2154 [03:39<00:06,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2095/2154 [03:39<00:06,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2101/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2102/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2103/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2104/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2105/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2110/2154 [03:41<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2111/2154 [03:41<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2112/2154 [03:41<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2113/2154 [03:41<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2114/2154 [03:41<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2119/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2120/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  98%|█████████▊| 2121/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▊| 2122/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2130/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2131/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2132/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2134/2154 [03:43<00:02,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2138/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2139/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2140/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2141/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25:  99%|█████████▉| 2143/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2148/2154 [03:45<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2149/2154 [03:45<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2150/2154 [03:45<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2151/2154 [03:45<00:00,  9.54it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2152/2154 [03:45<00:00,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|█████████▉| 2153/2154 [03:45<00:00,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0986, train_loss_epoch=0.103]\n",
      "Epoch 25: 100%|██████████| 2154/2154 [03:45<00:00,  9.55it/s, loss=0.106, v_num=0, train_loss_step=0.113, val_loss=0.0985, train_loss_epoch=0.103]\n",
      "Epoch 26:  94%|█████████▍| 2025/2154 [03:32<00:13,  9.54it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.51it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2027/2154 [03:32<00:13,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2028/2154 [03:33<00:13,  9.51it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2029/2154 [03:33<00:13,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2030/2154 [03:33<00:13,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2031/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2032/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2033/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2038/2154 [03:34<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2039/2154 [03:34<00:12,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2040/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2041/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2042/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2043/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2047/2154 [03:35<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2048/2154 [03:35<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2049/2154 [03:35<00:11,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2050/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2051/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2052/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2055/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2056/2154 [03:35<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  95%|█████████▌| 2057/2154 [03:36<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2058/2154 [03:36<00:10,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2059/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2060/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2061/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2065/2154 [03:36<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2066/2154 [03:37<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2067/2154 [03:37<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2068/2154 [03:37<00:09,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2069/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2070/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2071/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2072/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▌| 2073/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▋| 2074/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▋| 2075/2154 [03:37<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▋| 2076/2154 [03:38<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▋| 2077/2154 [03:38<00:08,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  96%|█████████▋| 2078/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2079/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2080/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2081/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2082/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2084/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2085/2154 [03:38<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2086/2154 [03:39<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2087/2154 [03:39<00:07,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2088/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2089/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2091/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2092/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2093/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2094/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2095/2154 [03:39<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2096/2154 [03:40<00:06,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2097/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2098/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2099/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2101/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2102/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2103/2154 [03:40<00:05,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2104/2154 [03:40<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2105/2154 [03:40<00:05,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2106/2154 [03:41<00:05,  9.52it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2107/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2108/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2109/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2110/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2111/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2112/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2113/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2114/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2116/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2117/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2119/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2120/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  98%|█████████▊| 2121/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▊| 2122/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▊| 2125/2154 [03:43<00:03,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▊| 2126/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▊| 2127/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2130/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2131/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2132/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2134/2154 [03:43<00:02,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2135/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2136/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2137/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2138/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2139/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2140/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2141/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26:  99%|█████████▉| 2143/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2145/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2146/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2148/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2149/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2150/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2151/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2152/2154 [03:45<00:00,  9.53it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|█████████▉| 2153/2154 [03:45<00:00,  9.54it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0985, train_loss_epoch=0.102]\n",
      "Epoch 26: 100%|██████████| 2154/2154 [03:45<00:00,  9.54it/s, loss=0.103, v_num=0, train_loss_step=0.0773, val_loss=0.0998, train_loss_epoch=0.102]\n",
      "Epoch 27:  94%|█████████▍| 2025/2154 [03:32<00:13,  9.54it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2027/2154 [03:32<00:13,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2028/2154 [03:33<00:13,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2029/2154 [03:33<00:13,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2030/2154 [03:33<00:13,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2031/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2032/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2033/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2038/2154 [03:34<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2039/2154 [03:34<00:12,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2040/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2041/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2042/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2043/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2047/2154 [03:35<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2048/2154 [03:35<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2049/2154 [03:35<00:11,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2050/2154 [03:35<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2051/2154 [03:35<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2052/2154 [03:35<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2055/2154 [03:35<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2056/2154 [03:36<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  95%|█████████▌| 2057/2154 [03:36<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2058/2154 [03:36<00:10,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2059/2154 [03:36<00:09,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2060/2154 [03:36<00:09,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2061/2154 [03:36<00:09,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2063/2154 [03:36<00:09,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2065/2154 [03:36<00:09,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2066/2154 [03:37<00:09,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2067/2154 [03:37<00:09,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2068/2154 [03:37<00:09,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2069/2154 [03:37<00:08,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2070/2154 [03:37<00:08,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2071/2154 [03:37<00:08,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2072/2154 [03:37<00:08,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▌| 2073/2154 [03:37<00:08,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▋| 2074/2154 [03:38<00:08,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▋| 2075/2154 [03:38<00:08,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▋| 2076/2154 [03:38<00:08,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▋| 2077/2154 [03:38<00:08,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  96%|█████████▋| 2078/2154 [03:38<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2079/2154 [03:38<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2080/2154 [03:38<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2081/2154 [03:38<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2082/2154 [03:38<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2084/2154 [03:39<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2085/2154 [03:39<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2086/2154 [03:39<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2087/2154 [03:39<00:07,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2088/2154 [03:39<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2089/2154 [03:39<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2091/2154 [03:39<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2092/2154 [03:39<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2093/2154 [03:40<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2094/2154 [03:40<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2095/2154 [03:40<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2096/2154 [03:40<00:06,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2097/2154 [03:40<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2098/2154 [03:40<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2099/2154 [03:40<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  97%|█████████▋| 2100/2154 [03:40<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2101/2154 [03:40<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2102/2154 [03:41<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2103/2154 [03:41<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2104/2154 [03:41<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2105/2154 [03:41<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2106/2154 [03:41<00:05,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2107/2154 [03:41<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2108/2154 [03:41<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2109/2154 [03:41<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2110/2154 [03:41<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2111/2154 [03:41<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2112/2154 [03:42<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2113/2154 [03:42<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2114/2154 [03:42<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2115/2154 [03:42<00:04,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2116/2154 [03:42<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2117/2154 [03:42<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2119/2154 [03:42<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2120/2154 [03:42<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  98%|█████████▊| 2121/2154 [03:43<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▊| 2122/2154 [03:43<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▊| 2123/2154 [03:43<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▊| 2124/2154 [03:43<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▊| 2125/2154 [03:43<00:03,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▊| 2126/2154 [03:43<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▊| 2127/2154 [03:43<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2130/2154 [03:44<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2131/2154 [03:44<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2132/2154 [03:44<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2133/2154 [03:44<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2134/2154 [03:44<00:02,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2135/2154 [03:44<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2136/2154 [03:44<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2137/2154 [03:44<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2138/2154 [03:44<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2139/2154 [03:44<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2140/2154 [03:45<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2141/2154 [03:45<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2142/2154 [03:45<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27:  99%|█████████▉| 2143/2154 [03:45<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2144/2154 [03:45<00:01,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2145/2154 [03:45<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2146/2154 [03:45<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2148/2154 [03:45<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2149/2154 [03:45<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2150/2154 [03:46<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2151/2154 [03:46<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2152/2154 [03:46<00:00,  9.51it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|█████████▉| 2153/2154 [03:46<00:00,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0998, train_loss_epoch=0.101]\n",
      "Epoch 27: 100%|██████████| 2154/2154 [03:46<00:00,  9.52it/s, loss=0.102, v_num=0, train_loss_step=0.0596, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.59it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  94%|█████████▍| 2026/2154 [03:31<00:13,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2027/2154 [03:31<00:13,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2028/2154 [03:31<00:13,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2029/2154 [03:31<00:13,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2034/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  94%|█████████▍| 2035/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2036/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2037/2154 [03:32<00:12,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2038/2154 [03:32<00:12,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2039/2154 [03:32<00:12,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2044/2154 [03:33<00:11,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2045/2154 [03:33<00:11,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▍| 2046/2154 [03:33<00:11,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2047/2154 [03:33<00:11,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2048/2154 [03:33<00:11,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2049/2154 [03:33<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2053/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2054/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2055/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2056/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  95%|█████████▌| 2057/2154 [03:34<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2062/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2063/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2064/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2065/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2066/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2067/2154 [03:35<00:09,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2068/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2072/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▌| 2073/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▋| 2074/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▋| 2075/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▋| 2076/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▋| 2077/2154 [03:36<00:08,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2082/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2083/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2084/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2085/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2086/2154 [03:37<00:07,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2087/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2091/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2092/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2093/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2094/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2095/2154 [03:38<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  97%|█████████▋| 2100/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2101/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2102/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2103/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2104/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2105/2154 [03:39<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2110/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2111/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2112/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2113/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2114/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2115/2154 [03:40<00:04,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2120/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  98%|█████████▊| 2121/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▊| 2122/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▊| 2123/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▊| 2124/2154 [03:41<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2129/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2130/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2131/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2132/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2133/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2134/2154 [03:42<00:02,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2139/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2140/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2141/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2142/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28:  99%|█████████▉| 2143/2154 [03:43<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2149/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2150/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2151/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2152/2154 [03:44<00:00,  9.57it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|█████████▉| 2153/2154 [03:44<00:00,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0985, train_loss_epoch=0.101]\n",
      "Epoch 28: 100%|██████████| 2154/2154 [03:44<00:00,  9.58it/s, loss=0.0934, v_num=0, train_loss_step=0.0957, val_loss=0.0934, train_loss_epoch=0.101]\n",
      "Epoch 29:  94%|█████████▍| 2025/2154 [03:32<00:13,  9.54it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  94%|█████████▍| 2026/2154 [03:33<00:13,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2027/2154 [03:33<00:13,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2028/2154 [03:33<00:13,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2029/2154 [03:33<00:13,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2030/2154 [03:33<00:13,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2031/2154 [03:33<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2032/2154 [03:33<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2033/2154 [03:33<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2034/2154 [03:33<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2036/2154 [03:34<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2037/2154 [03:34<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2038/2154 [03:34<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2039/2154 [03:34<00:12,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2040/2154 [03:34<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2041/2154 [03:34<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2042/2154 [03:34<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2043/2154 [03:34<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2045/2154 [03:35<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▍| 2046/2154 [03:35<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2047/2154 [03:35<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2048/2154 [03:35<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2049/2154 [03:35<00:11,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2050/2154 [03:35<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2051/2154 [03:35<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2052/2154 [03:35<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2053/2154 [03:35<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2054/2154 [03:36<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2055/2154 [03:36<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2056/2154 [03:36<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  95%|█████████▌| 2057/2154 [03:36<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2058/2154 [03:36<00:10,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2059/2154 [03:36<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2060/2154 [03:36<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2061/2154 [03:36<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2062/2154 [03:36<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2063/2154 [03:37<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2064/2154 [03:37<00:09,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2065/2154 [03:37<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2066/2154 [03:37<00:09,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2067/2154 [03:37<00:09,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2068/2154 [03:37<00:09,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2069/2154 [03:37<00:08,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2070/2154 [03:37<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2071/2154 [03:37<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2072/2154 [03:38<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▌| 2073/2154 [03:38<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▋| 2074/2154 [03:38<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▋| 2075/2154 [03:38<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▋| 2076/2154 [03:38<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▋| 2077/2154 [03:38<00:08,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  96%|█████████▋| 2078/2154 [03:38<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2079/2154 [03:38<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2080/2154 [03:38<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2081/2154 [03:38<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2082/2154 [03:39<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2083/2154 [03:39<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2084/2154 [03:39<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2085/2154 [03:39<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2086/2154 [03:39<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2087/2154 [03:39<00:07,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2088/2154 [03:39<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2089/2154 [03:39<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2090/2154 [03:39<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2091/2154 [03:40<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2092/2154 [03:40<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2093/2154 [03:40<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2094/2154 [03:40<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2095/2154 [03:40<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2096/2154 [03:40<00:06,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2097/2154 [03:40<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2098/2154 [03:40<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2099/2154 [03:40<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  97%|█████████▋| 2100/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2101/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2102/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2103/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2104/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2105/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2106/2154 [03:41<00:05,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2107/2154 [03:41<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2108/2154 [03:41<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2109/2154 [03:41<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2110/2154 [03:42<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2111/2154 [03:42<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2112/2154 [03:42<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2113/2154 [03:42<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2114/2154 [03:42<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2115/2154 [03:42<00:04,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2116/2154 [03:42<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2117/2154 [03:42<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2118/2154 [03:42<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2119/2154 [03:42<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2120/2154 [03:43<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  98%|█████████▊| 2121/2154 [03:43<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▊| 2122/2154 [03:43<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▊| 2123/2154 [03:43<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▊| 2124/2154 [03:43<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▊| 2125/2154 [03:43<00:03,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▊| 2126/2154 [03:43<00:02,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▊| 2127/2154 [03:43<00:02,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2128/2154 [03:43<00:02,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2129/2154 [03:43<00:02,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2130/2154 [03:44<00:02,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2131/2154 [03:44<00:02,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2132/2154 [03:44<00:02,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2133/2154 [03:44<00:02,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2134/2154 [03:44<00:02,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2135/2154 [03:44<00:01,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2136/2154 [03:44<00:01,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2137/2154 [03:44<00:01,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2138/2154 [03:44<00:01,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2139/2154 [03:45<00:01,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2140/2154 [03:45<00:01,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2141/2154 [03:45<00:01,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2142/2154 [03:45<00:01,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29:  99%|█████████▉| 2143/2154 [03:45<00:01,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2144/2154 [03:45<00:01,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2145/2154 [03:45<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2146/2154 [03:45<00:00,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2147/2154 [03:45<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2148/2154 [03:46<00:00,  9.50it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2149/2154 [03:46<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2150/2154 [03:46<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2151/2154 [03:46<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2152/2154 [03:46<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|█████████▉| 2153/2154 [03:46<00:00,  9.51it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0934, train_loss_epoch=0.0999]\n",
      "Epoch 29: 100%|██████████| 2154/2154 [03:46<00:00,  9.52it/s, loss=0.0934, v_num=0, train_loss_step=0.112, val_loss=0.0942, train_loss_epoch=0.0999]\n",
      "Epoch 30:  94%|█████████▍| 2025/2154 [03:26<00:13,  9.82it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  94%|█████████▍| 2026/2154 [03:26<00:13,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2027/2154 [03:26<00:12,  9.80it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2028/2154 [03:27<00:12,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2029/2154 [03:27<00:12,  9.80it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2030/2154 [03:27<00:12,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2031/2154 [03:27<00:12,  9.80it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2032/2154 [03:27<00:12,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2033/2154 [03:27<00:12,  9.80it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2034/2154 [03:27<00:12,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  94%|█████████▍| 2035/2154 [03:27<00:12,  9.80it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2036/2154 [03:27<00:12,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2037/2154 [03:27<00:11,  9.80it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2038/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2039/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2040/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2041/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2042/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2043/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2044/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2045/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▍| 2046/2154 [03:28<00:11,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2047/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2048/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2049/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2050/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2051/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2052/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2053/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2054/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2055/2154 [03:29<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2056/2154 [03:30<00:10,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  95%|█████████▌| 2057/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2058/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2059/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2060/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2061/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2062/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2063/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2064/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2065/2154 [03:30<00:09,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2066/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2067/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2068/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2069/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2070/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2071/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2072/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▌| 2073/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▋| 2074/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▋| 2075/2154 [03:31<00:08,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▋| 2076/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▋| 2077/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  96%|█████████▋| 2078/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2079/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2080/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2081/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2082/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2083/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2084/2154 [03:32<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2085/2154 [03:33<00:07,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2086/2154 [03:33<00:06,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2087/2154 [03:33<00:06,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2088/2154 [03:33<00:06,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2089/2154 [03:33<00:06,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2090/2154 [03:33<00:06,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2091/2154 [03:33<00:06,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2092/2154 [03:33<00:06,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2093/2154 [03:33<00:06,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2094/2154 [03:34<00:06,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2095/2154 [03:34<00:06,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2096/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2097/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2098/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2099/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  97%|█████████▋| 2100/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2101/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2102/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2103/2154 [03:34<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2104/2154 [03:35<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2105/2154 [03:35<00:05,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2106/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2107/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2108/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2109/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2110/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2111/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2112/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2113/2154 [03:35<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2114/2154 [03:36<00:04,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2115/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2116/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2117/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2118/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2119/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2120/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  98%|█████████▊| 2121/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▊| 2122/2154 [03:36<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▊| 2123/2154 [03:37<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▊| 2124/2154 [03:37<00:03,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▊| 2125/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▊| 2126/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▊| 2127/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2128/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2129/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2130/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2131/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2132/2154 [03:37<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2133/2154 [03:38<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2134/2154 [03:38<00:02,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2135/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2136/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2137/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2138/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2139/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2140/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2141/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2142/2154 [03:38<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30:  99%|█████████▉| 2143/2154 [03:39<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2144/2154 [03:39<00:01,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2145/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2146/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2147/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2148/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2149/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2150/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2151/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2152/2154 [03:39<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|█████████▉| 2153/2154 [03:40<00:00,  9.78it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0942, train_loss_epoch=0.100]\n",
      "Epoch 30: 100%|██████████| 2154/2154 [03:40<00:00,  9.79it/s, loss=0.0991, v_num=0, train_loss_step=0.111, val_loss=0.0973, train_loss_epoch=0.100]\n",
      "Epoch 31:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.57it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  94%|█████████▍| 2026/2154 [03:32<00:13,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2027/2154 [03:32<00:13,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2028/2154 [03:32<00:13,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2029/2154 [03:32<00:13,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2034/2154 [03:32<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  94%|█████████▍| 2035/2154 [03:33<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2036/2154 [03:33<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2037/2154 [03:33<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2038/2154 [03:33<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2039/2154 [03:33<00:12,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2044/2154 [03:34<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2045/2154 [03:34<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▍| 2046/2154 [03:34<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2047/2154 [03:34<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2048/2154 [03:34<00:11,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2049/2154 [03:34<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2053/2154 [03:34<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2054/2154 [03:35<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2055/2154 [03:35<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2056/2154 [03:35<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  95%|█████████▌| 2057/2154 [03:35<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2062/2154 [03:35<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2063/2154 [03:35<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2064/2154 [03:36<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2065/2154 [03:36<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2066/2154 [03:36<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2067/2154 [03:36<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2068/2154 [03:36<00:09,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2072/2154 [03:36<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▌| 2073/2154 [03:36<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▋| 2074/2154 [03:37<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▋| 2075/2154 [03:37<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▋| 2076/2154 [03:37<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▋| 2077/2154 [03:37<00:08,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2082/2154 [03:37<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2083/2154 [03:38<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2084/2154 [03:38<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2085/2154 [03:38<00:07,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2086/2154 [03:38<00:07,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2087/2154 [03:38<00:07,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2091/2154 [03:38<00:06,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2092/2154 [03:38<00:06,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2093/2154 [03:39<00:06,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2094/2154 [03:39<00:06,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2095/2154 [03:39<00:06,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.55it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  97%|█████████▋| 2100/2154 [03:39<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2101/2154 [03:39<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2102/2154 [03:39<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2103/2154 [03:40<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2104/2154 [03:40<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2105/2154 [03:40<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2110/2154 [03:40<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2111/2154 [03:40<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2112/2154 [03:40<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2113/2154 [03:41<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2114/2154 [03:41<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2120/2154 [03:41<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  98%|█████████▊| 2121/2154 [03:41<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▊| 2122/2154 [03:42<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▊| 2123/2154 [03:42<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2129/2154 [03:42<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2130/2154 [03:42<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2131/2154 [03:42<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2132/2154 [03:43<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2134/2154 [03:43<00:02,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2139/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2140/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2141/2154 [03:43<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31:  99%|█████████▉| 2143/2154 [03:44<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2149/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2150/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2151/2154 [03:44<00:00,  9.56it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2152/2154 [03:44<00:00,  9.57it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|█████████▉| 2153/2154 [03:44<00:00,  9.57it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0973, train_loss_epoch=0.0992]\n",
      "Epoch 31: 100%|██████████| 2154/2154 [03:44<00:00,  9.57it/s, loss=0.0984, v_num=0, train_loss_step=0.0701, val_loss=0.0959, train_loss_epoch=0.0992]\n",
      "Epoch 32:  94%|█████████▍| 2025/2154 [03:31<00:13,  9.58it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  94%|█████████▍| 2026/2154 [03:31<00:13,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2027/2154 [03:31<00:13,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2028/2154 [03:32<00:13,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2029/2154 [03:32<00:13,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2030/2154 [03:32<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2031/2154 [03:32<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2032/2154 [03:32<00:12,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2033/2154 [03:32<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2034/2154 [03:32<00:12,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  94%|█████████▍| 2035/2154 [03:32<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2036/2154 [03:32<00:12,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2037/2154 [03:32<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2038/2154 [03:33<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2039/2154 [03:33<00:12,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2040/2154 [03:33<00:11,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2041/2154 [03:33<00:11,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2042/2154 [03:33<00:11,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2044/2154 [03:33<00:11,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2045/2154 [03:33<00:11,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▍| 2046/2154 [03:33<00:11,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2047/2154 [03:33<00:11,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2048/2154 [03:34<00:11,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2049/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2050/2154 [03:34<00:10,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2051/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2053/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2054/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2055/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2056/2154 [03:34<00:10,  9.56it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  95%|█████████▌| 2057/2154 [03:34<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2058/2154 [03:35<00:10,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2059/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2060/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2062/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2063/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2064/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2065/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2066/2154 [03:35<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2067/2154 [03:36<00:09,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2068/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2069/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2072/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▌| 2073/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▋| 2074/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▋| 2075/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▋| 2076/2154 [03:36<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▋| 2077/2154 [03:37<00:08,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2082/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2083/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2084/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2085/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2086/2154 [03:37<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2087/2154 [03:38<00:07,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2091/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2092/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2093/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2094/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2095/2154 [03:38<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  97%|█████████▋| 2100/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2101/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2102/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2103/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2104/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2105/2154 [03:39<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2110/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2111/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2112/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2113/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2114/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2115/2154 [03:40<00:04,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2120/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  98%|█████████▊| 2121/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▊| 2122/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▊| 2123/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▊| 2124/2154 [03:41<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2129/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2130/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2131/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2132/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2133/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2134/2154 [03:42<00:02,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2139/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2140/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2141/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2142/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32:  99%|█████████▉| 2143/2154 [03:43<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2149/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2150/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2151/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2152/2154 [03:44<00:00,  9.57it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|█████████▉| 2153/2154 [03:44<00:00,  9.58it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0959, train_loss_epoch=0.0981]\n",
      "Epoch 32: 100%|██████████| 2154/2154 [03:44<00:00,  9.58it/s, loss=0.0927, v_num=0, train_loss_step=0.0839, val_loss=0.0944, train_loss_epoch=0.0981]\n",
      "Epoch 33:  94%|█████████▍| 2025/2154 [03:26<00:13,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  94%|█████████▍| 2026/2154 [03:27<00:13,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2027/2154 [03:27<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2028/2154 [03:27<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2029/2154 [03:27<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2030/2154 [03:27<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2031/2154 [03:27<00:12,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2032/2154 [03:27<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2033/2154 [03:27<00:12,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2034/2154 [03:27<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  94%|█████████▍| 2035/2154 [03:27<00:12,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2036/2154 [03:28<00:12,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2037/2154 [03:28<00:11,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2038/2154 [03:28<00:11,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2039/2154 [03:28<00:11,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2040/2154 [03:28<00:11,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2041/2154 [03:28<00:11,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2042/2154 [03:28<00:11,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2043/2154 [03:28<00:11,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2044/2154 [03:28<00:11,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2045/2154 [03:28<00:11,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▍| 2046/2154 [03:29<00:11,  9.78it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2047/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2048/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2049/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2050/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2051/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2052/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2053/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2054/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2055/2154 [03:29<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2056/2154 [03:30<00:10,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  95%|█████████▌| 2057/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2058/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2059/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2060/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2061/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2062/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2063/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2064/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2065/2154 [03:30<00:09,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2066/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2067/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2068/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2069/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2070/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2071/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2072/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▌| 2073/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▋| 2074/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▋| 2075/2154 [03:31<00:08,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▋| 2076/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▋| 2077/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  96%|█████████▋| 2078/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2079/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2080/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2081/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2082/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2083/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2084/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2085/2154 [03:32<00:07,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2086/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2087/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2088/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2089/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2090/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2091/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2092/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2093/2154 [03:33<00:06,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2094/2154 [03:33<00:06,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2095/2154 [03:33<00:06,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2096/2154 [03:34<00:05,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2097/2154 [03:34<00:05,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2098/2154 [03:34<00:05,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2099/2154 [03:34<00:05,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  97%|█████████▋| 2100/2154 [03:34<00:05,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2101/2154 [03:34<00:05,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2102/2154 [03:34<00:05,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2103/2154 [03:34<00:05,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2104/2154 [03:34<00:05,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2105/2154 [03:34<00:05,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2106/2154 [03:35<00:04,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2107/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2108/2154 [03:35<00:04,  9.79it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2109/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2110/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2111/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2112/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2113/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2114/2154 [03:35<00:04,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2115/2154 [03:35<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2116/2154 [03:35<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2117/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2118/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2119/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2120/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  98%|█████████▊| 2121/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▊| 2122/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▊| 2123/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▊| 2124/2154 [03:36<00:03,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▊| 2125/2154 [03:36<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▊| 2126/2154 [03:36<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▊| 2127/2154 [03:36<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2128/2154 [03:37<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2129/2154 [03:37<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2130/2154 [03:37<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2131/2154 [03:37<00:02,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2132/2154 [03:37<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2133/2154 [03:37<00:02,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2134/2154 [03:37<00:02,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2135/2154 [03:37<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2136/2154 [03:37<00:01,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2137/2154 [03:37<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2138/2154 [03:38<00:01,  9.80it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2139/2154 [03:38<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2140/2154 [03:38<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2141/2154 [03:38<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2142/2154 [03:38<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33:  99%|█████████▉| 2143/2154 [03:38<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2144/2154 [03:38<00:01,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2145/2154 [03:38<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2146/2154 [03:38<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2147/2154 [03:38<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2148/2154 [03:39<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2149/2154 [03:39<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2150/2154 [03:39<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2151/2154 [03:39<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2152/2154 [03:39<00:00,  9.81it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|█████████▉| 2153/2154 [03:39<00:00,  9.82it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0944, train_loss_epoch=0.0984]\n",
      "Epoch 33: 100%|██████████| 2154/2154 [03:39<00:00,  9.82it/s, loss=0.0918, v_num=0, train_loss_step=0.0852, val_loss=0.0965, train_loss_epoch=0.0984]\n",
      "Epoch 34:  94%|█████████▍| 2025/2154 [03:23<00:12,  9.96it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  94%|█████████▍| 2026/2154 [03:23<00:12,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2027/2154 [03:23<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2028/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2029/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2030/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2031/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2032/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2033/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2034/2154 [03:24<00:12,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  94%|█████████▍| 2035/2154 [03:24<00:11,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2036/2154 [03:24<00:11,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2037/2154 [03:25<00:11,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2038/2154 [03:25<00:11,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2039/2154 [03:25<00:11,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2040/2154 [03:25<00:11,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2041/2154 [03:25<00:11,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2042/2154 [03:25<00:11,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2043/2154 [03:25<00:11,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2044/2154 [03:25<00:11,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2045/2154 [03:25<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▍| 2046/2154 [03:25<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2047/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2048/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2049/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2050/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2051/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2052/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2053/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2054/2154 [03:26<00:10,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2055/2154 [03:26<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2056/2154 [03:26<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  95%|█████████▌| 2057/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2058/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2059/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2060/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2061/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2062/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2063/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2064/2154 [03:27<00:09,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2065/2154 [03:27<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2066/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2067/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2068/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2069/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2070/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2071/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2072/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▌| 2073/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▋| 2074/2154 [03:28<00:08,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▋| 2075/2154 [03:28<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▋| 2076/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▋| 2077/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  96%|█████████▋| 2078/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2079/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2080/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2081/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2082/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2083/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2084/2154 [03:29<00:07,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2085/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2086/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2087/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2088/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2089/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2090/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2091/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2092/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2093/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2094/2154 [03:30<00:06,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2095/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2096/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2097/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2098/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2099/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  97%|█████████▋| 2100/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2101/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2102/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2103/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2104/2154 [03:31<00:05,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2105/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2106/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2107/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2108/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2109/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2110/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2111/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2112/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2113/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2114/2154 [03:32<00:04,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2115/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2116/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2117/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2118/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2119/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2120/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  98%|█████████▊| 2121/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▊| 2122/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▊| 2123/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▊| 2124/2154 [03:33<00:03,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▊| 2125/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▊| 2126/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▊| 2127/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2128/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2129/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2130/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2131/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2132/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2133/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2134/2154 [03:34<00:02,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2135/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2136/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2137/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2138/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2139/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2140/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2141/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2142/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34:  99%|█████████▉| 2143/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2144/2154 [03:35<00:01,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2145/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2146/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2147/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2148/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2149/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2150/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2151/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2152/2154 [03:36<00:00,  9.93it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|█████████▉| 2153/2154 [03:36<00:00,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0965, train_loss_epoch=0.0973]\n",
      "Epoch 34: 100%|██████████| 2154/2154 [03:36<00:00,  9.94it/s, loss=0.0907, v_num=0, train_loss_step=0.0795, val_loss=0.0972, train_loss_epoch=0.0973]\n",
      "Epoch 35:  94%|█████████▍| 2025/2154 [03:27<00:13,  9.75it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  94%|█████████▍| 2026/2154 [03:28<00:13,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2027/2154 [03:28<00:13,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2028/2154 [03:28<00:12,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2029/2154 [03:28<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2030/2154 [03:28<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2031/2154 [03:28<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2032/2154 [03:28<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2033/2154 [03:28<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2034/2154 [03:29<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  94%|█████████▍| 2035/2154 [03:29<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2036/2154 [03:29<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2037/2154 [03:29<00:12,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2038/2154 [03:29<00:11,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2039/2154 [03:29<00:11,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2040/2154 [03:29<00:11,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2041/2154 [03:29<00:11,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2042/2154 [03:29<00:11,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2043/2154 [03:30<00:11,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2044/2154 [03:30<00:11,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2045/2154 [03:30<00:11,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▍| 2046/2154 [03:30<00:11,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2047/2154 [03:30<00:11,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2048/2154 [03:30<00:10,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2049/2154 [03:30<00:10,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2050/2154 [03:30<00:10,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2051/2154 [03:30<00:10,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2052/2154 [03:31<00:10,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2053/2154 [03:31<00:10,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2054/2154 [03:31<00:10,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2055/2154 [03:31<00:10,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2056/2154 [03:31<00:10,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  95%|█████████▌| 2057/2154 [03:31<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2058/2154 [03:31<00:09,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2059/2154 [03:31<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2060/2154 [03:31<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2061/2154 [03:31<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2062/2154 [03:32<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2063/2154 [03:32<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2064/2154 [03:32<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2065/2154 [03:32<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2066/2154 [03:32<00:09,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2067/2154 [03:32<00:08,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2068/2154 [03:32<00:08,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2069/2154 [03:32<00:08,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2070/2154 [03:32<00:08,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2071/2154 [03:32<00:08,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2072/2154 [03:33<00:08,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▌| 2073/2154 [03:33<00:08,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▋| 2074/2154 [03:33<00:08,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▋| 2075/2154 [03:33<00:08,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▋| 2076/2154 [03:33<00:08,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▋| 2077/2154 [03:33<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  96%|█████████▋| 2078/2154 [03:33<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2079/2154 [03:33<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2080/2154 [03:33<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2081/2154 [03:34<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2082/2154 [03:34<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2083/2154 [03:34<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2084/2154 [03:34<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2085/2154 [03:34<00:07,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2086/2154 [03:34<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2087/2154 [03:34<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2088/2154 [03:34<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2089/2154 [03:34<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2090/2154 [03:34<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2091/2154 [03:35<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2092/2154 [03:35<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2093/2154 [03:35<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2094/2154 [03:35<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2095/2154 [03:35<00:06,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2096/2154 [03:35<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2097/2154 [03:35<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2098/2154 [03:35<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2099/2154 [03:35<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  97%|█████████▋| 2100/2154 [03:35<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2101/2154 [03:36<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2102/2154 [03:36<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2103/2154 [03:36<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2104/2154 [03:36<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2105/2154 [03:36<00:05,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2106/2154 [03:36<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2107/2154 [03:36<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2108/2154 [03:36<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2109/2154 [03:36<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2110/2154 [03:36<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2111/2154 [03:37<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2112/2154 [03:37<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2113/2154 [03:37<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2114/2154 [03:37<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2115/2154 [03:37<00:04,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2116/2154 [03:37<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2117/2154 [03:37<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2118/2154 [03:37<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2119/2154 [03:37<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2120/2154 [03:38<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  98%|█████████▊| 2121/2154 [03:38<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▊| 2122/2154 [03:38<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▊| 2123/2154 [03:38<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▊| 2124/2154 [03:38<00:03,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▊| 2125/2154 [03:38<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▊| 2126/2154 [03:38<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▊| 2127/2154 [03:38<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2128/2154 [03:38<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2129/2154 [03:39<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2130/2154 [03:39<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2131/2154 [03:39<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2132/2154 [03:39<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2133/2154 [03:39<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2134/2154 [03:39<00:02,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2135/2154 [03:39<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2136/2154 [03:39<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2137/2154 [03:39<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2138/2154 [03:39<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2139/2154 [03:40<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2140/2154 [03:40<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2141/2154 [03:40<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2142/2154 [03:40<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35:  99%|█████████▉| 2143/2154 [03:40<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2144/2154 [03:40<00:01,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2145/2154 [03:40<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2146/2154 [03:40<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2147/2154 [03:40<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2148/2154 [03:40<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2149/2154 [03:41<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2150/2154 [03:41<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2151/2154 [03:41<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2152/2154 [03:41<00:00,  9.72it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|█████████▉| 2153/2154 [03:41<00:00,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.0972, train_loss_epoch=0.0967]\n",
      "Epoch 35: 100%|██████████| 2154/2154 [03:41<00:00,  9.73it/s, loss=0.0971, v_num=0, train_loss_step=0.147, val_loss=0.100, train_loss_epoch=0.0967] \n",
      "Epoch 36:  94%|█████████▍| 2025/2154 [03:30<00:13,  9.62it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  94%|█████████▍| 2026/2154 [03:31<00:13,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2027/2154 [03:31<00:13,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2028/2154 [03:31<00:13,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2029/2154 [03:31<00:13,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2030/2154 [03:31<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2031/2154 [03:31<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2032/2154 [03:31<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2033/2154 [03:31<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2034/2154 [03:31<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  94%|█████████▍| 2035/2154 [03:32<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2036/2154 [03:32<00:12,  9.60it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2037/2154 [03:32<00:12,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2038/2154 [03:32<00:12,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2039/2154 [03:32<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2040/2154 [03:32<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2041/2154 [03:32<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2042/2154 [03:32<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2043/2154 [03:33<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2044/2154 [03:33<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2045/2154 [03:33<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▍| 2046/2154 [03:33<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2047/2154 [03:33<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2048/2154 [03:33<00:11,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2049/2154 [03:33<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2050/2154 [03:33<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2051/2154 [03:33<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2052/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2053/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2054/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2055/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2056/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  95%|█████████▌| 2057/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2058/2154 [03:34<00:10,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2059/2154 [03:34<00:09,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2060/2154 [03:34<00:09,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2061/2154 [03:35<00:09,  9.59it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2062/2154 [03:35<00:09,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2063/2154 [03:35<00:09,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2064/2154 [03:35<00:09,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2065/2154 [03:35<00:09,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2066/2154 [03:35<00:09,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2067/2154 [03:35<00:09,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2068/2154 [03:35<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2069/2154 [03:35<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2070/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2071/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2072/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▌| 2073/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▋| 2074/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▋| 2075/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▋| 2076/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▋| 2077/2154 [03:36<00:08,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  96%|█████████▋| 2078/2154 [03:37<00:07,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2079/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2080/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2081/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2082/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2083/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2084/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2085/2154 [03:37<00:07,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2086/2154 [03:37<00:07,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2087/2154 [03:37<00:06,  9.58it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2088/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2089/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2090/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2091/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2092/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2093/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2094/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2095/2154 [03:38<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2096/2154 [03:39<00:06,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2097/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2098/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2099/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  97%|█████████▋| 2100/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2101/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2102/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2103/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2104/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2105/2154 [03:39<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2106/2154 [03:40<00:05,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2107/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2108/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2109/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2110/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2111/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2112/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2113/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2114/2154 [03:40<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2115/2154 [03:41<00:04,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2116/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2117/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2118/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2119/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2120/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  98%|█████████▊| 2121/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▊| 2122/2154 [03:41<00:03,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▊| 2123/2154 [03:41<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▊| 2124/2154 [03:42<00:03,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▊| 2125/2154 [03:42<00:03,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▊| 2126/2154 [03:42<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▊| 2127/2154 [03:42<00:02,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2128/2154 [03:42<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2129/2154 [03:42<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2130/2154 [03:42<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2131/2154 [03:42<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2132/2154 [03:42<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2133/2154 [03:43<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2134/2154 [03:43<00:02,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2135/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2136/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2137/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2138/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2139/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2140/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2141/2154 [03:43<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2142/2154 [03:44<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36:  99%|█████████▉| 2143/2154 [03:44<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2144/2154 [03:44<00:01,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2145/2154 [03:44<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2146/2154 [03:44<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2147/2154 [03:44<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2148/2154 [03:44<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2149/2154 [03:44<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2150/2154 [03:44<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2151/2154 [03:45<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2152/2154 [03:45<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|█████████▉| 2153/2154 [03:45<00:00,  9.56it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.100, train_loss_epoch=0.0963]\n",
      "Epoch 36: 100%|██████████| 2154/2154 [03:45<00:00,  9.57it/s, loss=0.0949, v_num=0, train_loss_step=0.0692, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2025/2154 [03:27<00:13,  9.74it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  94%|█████████▍| 2026/2154 [03:28<00:13,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2027/2154 [03:28<00:13,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2028/2154 [03:28<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2029/2154 [03:28<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2030/2154 [03:28<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2031/2154 [03:28<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2032/2154 [03:29<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2033/2154 [03:29<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2034/2154 [03:29<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  94%|█████████▍| 2035/2154 [03:29<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2036/2154 [03:29<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2037/2154 [03:29<00:12,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2038/2154 [03:29<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2039/2154 [03:29<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2040/2154 [03:29<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2041/2154 [03:29<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2042/2154 [03:30<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2043/2154 [03:30<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2044/2154 [03:30<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2045/2154 [03:30<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▍| 2046/2154 [03:30<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2047/2154 [03:30<00:11,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2048/2154 [03:30<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2049/2154 [03:30<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2050/2154 [03:30<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2051/2154 [03:30<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2052/2154 [03:31<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2053/2154 [03:31<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2054/2154 [03:31<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2055/2154 [03:31<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2056/2154 [03:31<00:10,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  95%|█████████▌| 2057/2154 [03:31<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2058/2154 [03:31<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2059/2154 [03:31<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2060/2154 [03:31<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2061/2154 [03:31<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2062/2154 [03:32<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2063/2154 [03:32<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2064/2154 [03:32<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2065/2154 [03:32<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2066/2154 [03:32<00:09,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2067/2154 [03:32<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2068/2154 [03:32<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2069/2154 [03:32<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2070/2154 [03:32<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2071/2154 [03:32<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2072/2154 [03:33<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▌| 2073/2154 [03:33<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▋| 2074/2154 [03:33<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▋| 2075/2154 [03:33<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▋| 2076/2154 [03:33<00:08,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▋| 2077/2154 [03:33<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  96%|█████████▋| 2078/2154 [03:33<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2079/2154 [03:33<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2080/2154 [03:34<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2081/2154 [03:34<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2082/2154 [03:34<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2083/2154 [03:34<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2084/2154 [03:34<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2085/2154 [03:34<00:07,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2086/2154 [03:34<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2087/2154 [03:34<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2088/2154 [03:34<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2089/2154 [03:34<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2090/2154 [03:34<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2091/2154 [03:35<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2092/2154 [03:35<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2093/2154 [03:35<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2094/2154 [03:35<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2095/2154 [03:35<00:06,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2096/2154 [03:35<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2097/2154 [03:35<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2098/2154 [03:35<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2099/2154 [03:35<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  97%|█████████▋| 2100/2154 [03:36<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2101/2154 [03:36<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2102/2154 [03:36<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2103/2154 [03:36<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2104/2154 [03:36<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2105/2154 [03:36<00:05,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2106/2154 [03:36<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2107/2154 [03:36<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2108/2154 [03:36<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2109/2154 [03:36<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2110/2154 [03:37<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2111/2154 [03:37<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2112/2154 [03:37<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2113/2154 [03:37<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2114/2154 [03:37<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2115/2154 [03:37<00:04,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2116/2154 [03:37<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2117/2154 [03:37<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2118/2154 [03:37<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2119/2154 [03:37<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2120/2154 [03:38<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  98%|█████████▊| 2121/2154 [03:38<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▊| 2122/2154 [03:38<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▊| 2123/2154 [03:38<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▊| 2124/2154 [03:38<00:03,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▊| 2125/2154 [03:38<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▊| 2126/2154 [03:38<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▊| 2127/2154 [03:38<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2128/2154 [03:38<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2129/2154 [03:39<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2130/2154 [03:39<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2131/2154 [03:39<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2132/2154 [03:39<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2133/2154 [03:39<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2134/2154 [03:39<00:02,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2135/2154 [03:39<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2136/2154 [03:39<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2137/2154 [03:39<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2138/2154 [03:39<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2139/2154 [03:40<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2140/2154 [03:40<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2141/2154 [03:40<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2142/2154 [03:40<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37:  99%|█████████▉| 2143/2154 [03:40<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2144/2154 [03:40<00:01,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2145/2154 [03:40<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2146/2154 [03:40<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2147/2154 [03:40<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2148/2154 [03:41<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2149/2154 [03:41<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2150/2154 [03:41<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2151/2154 [03:41<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2152/2154 [03:41<00:00,  9.72it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|█████████▉| 2153/2154 [03:41<00:00,  9.73it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.096, train_loss_epoch=0.0963]\n",
      "Epoch 37: 100%|██████████| 2154/2154 [03:41<00:00,  9.73it/s, loss=0.0897, v_num=0, train_loss_step=0.107, val_loss=0.101, train_loss_epoch=0.0963]\n",
      "Epoch 54:  94%|█████████▍| 2025/2154 [03:20<00:12, 10.12it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  94%|█████████▍| 2026/2154 [03:20<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2027/2154 [03:20<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2030/2154 [03:21<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2031/2154 [03:21<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2032/2154 [03:21<00:12, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2033/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2034/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  94%|█████████▍| 2035/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2036/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2037/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2040/2154 [03:22<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2041/2154 [03:22<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2042/2154 [03:22<00:11, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2043/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2044/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2045/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▍| 2046/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2047/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2050/2154 [03:23<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2051/2154 [03:23<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2052/2154 [03:23<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2053/2154 [03:23<00:10, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2054/2154 [03:23<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2055/2154 [03:23<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2056/2154 [03:23<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  95%|█████████▌| 2057/2154 [03:23<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2060/2154 [03:24<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2061/2154 [03:24<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2062/2154 [03:24<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2063/2154 [03:24<00:09, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2064/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2065/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2066/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2072/2154 [03:25<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▌| 2073/2154 [03:25<00:08, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▋| 2074/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▋| 2075/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▋| 2076/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▋| 2077/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2082/2154 [03:26<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2083/2154 [03:26<00:07, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2084/2154 [03:26<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2085/2154 [03:26<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2086/2154 [03:26<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2087/2154 [03:26<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2092/2154 [03:27<00:06, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2093/2154 [03:27<00:06, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2094/2154 [03:27<00:05, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2095/2154 [03:27<00:05, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2096/2154 [03:27<00:05, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2097/2154 [03:27<00:05, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2102/2154 [03:28<00:05, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2103/2154 [03:28<00:05, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2104/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2105/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2106/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2107/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2108/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2112/2154 [03:29<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2113/2154 [03:29<00:04, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2114/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2115/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2116/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2117/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2118/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▊| 2122/2154 [03:30<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▊| 2123/2154 [03:30<00:03, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▊| 2124/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▊| 2125/2154 [03:30<00:02, 10.10it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▊| 2126/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▊| 2127/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2128/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2129/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2134/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2135/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2136/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2137/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2138/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2139/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2144/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2145/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2146/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2147/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2148/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.11it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.12it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.12it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.12it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0965, train_loss_epoch=0.0895]\n",
      "Epoch 54: 100%|██████████| 2154/2154 [03:32<00:00, 10.12it/s, loss=0.0897, v_num=0, train_loss_step=0.129, val_loss=0.0974, train_loss_epoch=0.0895]\n",
      "Epoch 55:  94%|█████████▍| 2025/2154 [03:19<00:12, 10.15it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  94%|█████████▍| 2026/2154 [03:20<00:12, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2027/2154 [03:20<00:12, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2030/2154 [03:20<00:12, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2031/2154 [03:20<00:12, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2032/2154 [03:20<00:12, 10.12it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2033/2154 [03:20<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2036/2154 [03:21<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2037/2154 [03:21<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.12it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2040/2154 [03:21<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2041/2154 [03:21<00:11, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2042/2154 [03:21<00:11, 10.12it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2043/2154 [03:21<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2044/2154 [03:21<00:10, 10.12it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▍| 2046/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2047/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2050/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2051/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2052/2154 [03:22<00:10, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2053/2154 [03:22<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2054/2154 [03:22<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2055/2154 [03:22<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2056/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  95%|█████████▌| 2057/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2060/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2061/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2062/2154 [03:23<00:09, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2063/2154 [03:23<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2064/2154 [03:23<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2065/2154 [03:23<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2066/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2072/2154 [03:24<00:08, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▌| 2073/2154 [03:24<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▋| 2074/2154 [03:24<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▋| 2075/2154 [03:24<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▋| 2076/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▋| 2077/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2082/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2083/2154 [03:25<00:07, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2084/2154 [03:25<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2085/2154 [03:25<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2087/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2092/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2093/2154 [03:26<00:06, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2095/2154 [03:26<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2096/2154 [03:26<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2097/2154 [03:26<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2102/2154 [03:27<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2103/2154 [03:27<00:05, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2104/2154 [03:27<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2105/2154 [03:27<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2106/2154 [03:27<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2107/2154 [03:27<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2108/2154 [03:28<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2114/2154 [03:28<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2115/2154 [03:28<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2116/2154 [03:28<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2117/2154 [03:28<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2118/2154 [03:29<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▊| 2124/2154 [03:29<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▊| 2125/2154 [03:29<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▊| 2126/2154 [03:29<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▊| 2127/2154 [03:29<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2128/2154 [03:30<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2129/2154 [03:30<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2134/2154 [03:30<00:01, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2135/2154 [03:30<00:01, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2136/2154 [03:30<00:01, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2137/2154 [03:30<00:01, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2138/2154 [03:30<00:01, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2139/2154 [03:31<00:01, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2144/2154 [03:31<00:00, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2145/2154 [03:31<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2146/2154 [03:31<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2147/2154 [03:31<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2148/2154 [03:31<00:00, 10.13it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.14it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.0974, train_loss_epoch=0.089]\n",
      "Epoch 55: 100%|██████████| 2154/2154 [03:32<00:00, 10.15it/s, loss=0.0793, v_num=0, train_loss_step=0.0912, val_loss=0.100, train_loss_epoch=0.089] \n",
      "Epoch 56:   8%|▊         | 169/2154 [00:17<03:20,  9.90it/s, loss=0.0875, v_num=0, train_loss_step=0.107, val_loss=0.100, train_loss_epoch=0.0901]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57:  94%|█████████▍| 2025/2154 [03:18<00:12, 10.22it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  94%|█████████▍| 2026/2154 [03:18<00:12, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2027/2154 [03:18<00:12, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2028/2154 [03:18<00:12, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2029/2154 [03:18<00:12, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2030/2154 [03:19<00:12, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2032/2154 [03:19<00:11, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2034/2154 [03:19<00:11, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  94%|█████████▍| 2035/2154 [03:19<00:11, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2036/2154 [03:19<00:11, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2037/2154 [03:19<00:11, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2038/2154 [03:19<00:11, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2039/2154 [03:19<00:11, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2042/2154 [03:20<00:10, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2044/2154 [03:20<00:10, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2045/2154 [03:20<00:10, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▍| 2046/2154 [03:20<00:10, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2047/2154 [03:20<00:10, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2048/2154 [03:20<00:10, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2049/2154 [03:20<00:10, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2052/2154 [03:21<00:10, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2054/2154 [03:21<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2055/2154 [03:21<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2056/2154 [03:21<00:09, 10.19it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  95%|█████████▌| 2057/2154 [03:21<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2058/2154 [03:21<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2059/2154 [03:21<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2062/2154 [03:22<00:09, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2064/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2065/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2066/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2067/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2068/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2069/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2070/2154 [03:22<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2071/2154 [03:23<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▋| 2074/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▋| 2075/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▋| 2076/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▋| 2077/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  96%|█████████▋| 2078/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2079/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2080/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2081/2154 [03:23<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2084/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2085/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2086/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2087/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2088/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2089/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2090/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2091/2154 [03:24<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2093/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2094/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2095/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2096/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2097/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2098/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2099/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  97%|█████████▋| 2100/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2101/2154 [03:25<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2103/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2104/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2105/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2106/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2107/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2108/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2109/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2110/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2111/2154 [03:26<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2112/2154 [03:27<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2113/2154 [03:27<00:04, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2114/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2115/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2116/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2117/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2118/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2119/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2120/2154 [03:27<00:03, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  98%|█████████▊| 2121/2154 [03:27<00:03, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▊| 2122/2154 [03:27<00:03, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▊| 2123/2154 [03:28<00:03, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▊| 2124/2154 [03:28<00:02, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▊| 2125/2154 [03:28<00:02, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▊| 2126/2154 [03:28<00:02, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▊| 2127/2154 [03:28<00:02, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2128/2154 [03:28<00:02, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2129/2154 [03:28<00:02, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2130/2154 [03:28<00:02, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2131/2154 [03:28<00:02, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2132/2154 [03:28<00:02, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2133/2154 [03:28<00:02, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2134/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2135/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2136/2154 [03:29<00:01, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2137/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2138/2154 [03:29<00:01, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2139/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2140/2154 [03:29<00:01, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2141/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2142/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57:  99%|█████████▉| 2143/2154 [03:29<00:01, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2144/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2145/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2146/2154 [03:30<00:00, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2147/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2148/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2149/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2150/2154 [03:30<00:00, 10.20it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2151/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2152/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|█████████▉| 2153/2154 [03:30<00:00, 10.21it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.0966, train_loss_epoch=0.0888]\n",
      "Epoch 57: 100%|██████████| 2154/2154 [03:30<00:00, 10.22it/s, loss=0.0862, v_num=0, train_loss_step=0.0984, val_loss=0.102, train_loss_epoch=0.0888] \n",
      "Epoch 58:  15%|█▌        | 330/2154 [00:33<03:04,  9.88it/s, loss=0.089, v_num=0, train_loss_step=0.112, val_loss=0.102, train_loss_epoch=0.0876]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59:  94%|█████████▍| 2025/2154 [03:22<00:12,  9.99it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  94%|█████████▍| 2026/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2027/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2028/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2029/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2030/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2031/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2032/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2033/2154 [03:23<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2034/2154 [03:24<00:12,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  94%|█████████▍| 2035/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2036/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2037/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2038/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2039/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2040/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2041/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2042/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2043/2154 [03:24<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2044/2154 [03:25<00:11,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2045/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▍| 2046/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2047/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2048/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2049/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2050/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2051/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2052/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2053/2154 [03:25<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2054/2154 [03:26<00:10,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2055/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2056/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  95%|█████████▌| 2057/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2058/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2059/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2060/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2061/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2062/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2063/2154 [03:26<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2064/2154 [03:27<00:09,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2065/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2066/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2067/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2068/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2069/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2070/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2071/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2072/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▌| 2073/2154 [03:27<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▋| 2074/2154 [03:28<00:08,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▋| 2075/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▋| 2076/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▋| 2077/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  96%|█████████▋| 2078/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2079/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2080/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2081/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2082/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2083/2154 [03:28<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2084/2154 [03:29<00:07,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2085/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2086/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2087/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2088/2154 [03:29<00:06,  9.96it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2089/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2090/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2091/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2092/2154 [03:29<00:06,  9.96it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2093/2154 [03:29<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2094/2154 [03:30<00:06,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2095/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2096/2154 [03:30<00:05,  9.96it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2097/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2098/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2099/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  97%|█████████▋| 2100/2154 [03:30<00:05,  9.96it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2101/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2102/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2103/2154 [03:30<00:05,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2104/2154 [03:31<00:05,  9.96it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2105/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2106/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2107/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2108/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2109/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2110/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2111/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2112/2154 [03:31<00:04,  9.96it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2113/2154 [03:31<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2114/2154 [03:32<00:04,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2115/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2116/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2117/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2118/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2119/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2120/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  98%|█████████▊| 2121/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▊| 2122/2154 [03:32<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▊| 2123/2154 [03:33<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▊| 2124/2154 [03:33<00:03,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▊| 2125/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▊| 2126/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▊| 2127/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2128/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2129/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2130/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2131/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2132/2154 [03:33<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2133/2154 [03:34<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2134/2154 [03:34<00:02,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2135/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2136/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2137/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2138/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2139/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2140/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2141/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2142/2154 [03:34<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59:  99%|█████████▉| 2143/2154 [03:35<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2144/2154 [03:35<00:01,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2145/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2146/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2147/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2148/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2149/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2150/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2151/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2152/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|█████████▉| 2153/2154 [03:35<00:00,  9.97it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0981, train_loss_epoch=0.0888]\n",
      "Epoch 59: 100%|██████████| 2154/2154 [03:35<00:00,  9.98it/s, loss=0.0821, v_num=0, train_loss_step=0.101, val_loss=0.0991, train_loss_epoch=0.0888]\n",
      "Epoch 60:  20%|█▉        | 426/2154 [00:42<02:53,  9.94it/s, loss=0.094, v_num=0, train_loss_step=0.0954, val_loss=0.0991, train_loss_epoch=0.088]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:  94%|█████████▍| 2025/2154 [03:18<00:12, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  94%|█████████▍| 2026/2154 [03:19<00:12, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2027/2154 [03:19<00:12, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2028/2154 [03:19<00:12, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2029/2154 [03:19<00:12, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2030/2154 [03:19<00:12, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2032/2154 [03:19<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2036/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2037/2154 [03:20<00:11, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2038/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2039/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2042/2154 [03:20<00:11, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2044/2154 [03:20<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▍| 2046/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2047/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2048/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2049/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2052/2154 [03:21<00:10, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2054/2154 [03:21<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2055/2154 [03:21<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2056/2154 [03:22<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  95%|█████████▌| 2057/2154 [03:22<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2058/2154 [03:22<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2059/2154 [03:22<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2062/2154 [03:22<00:09, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2064/2154 [03:22<00:08, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2065/2154 [03:22<00:08, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2066/2154 [03:23<00:08, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2067/2154 [03:23<00:08, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2068/2154 [03:23<00:08, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2069/2154 [03:23<00:08, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2070/2154 [03:23<00:08, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2071/2154 [03:23<00:08, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▋| 2074/2154 [03:23<00:07, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▋| 2075/2154 [03:23<00:07, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▋| 2076/2154 [03:24<00:07, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▋| 2077/2154 [03:24<00:07, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  96%|█████████▋| 2078/2154 [03:24<00:07, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2079/2154 [03:24<00:07, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2080/2154 [03:24<00:07, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2081/2154 [03:24<00:07, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2084/2154 [03:24<00:06, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2085/2154 [03:24<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.17it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2087/2154 [03:25<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2088/2154 [03:25<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2089/2154 [03:25<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2090/2154 [03:25<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2091/2154 [03:25<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2093/2154 [03:25<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2094/2154 [03:25<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2095/2154 [03:25<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2096/2154 [03:25<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2097/2154 [03:25<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2098/2154 [03:26<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2099/2154 [03:26<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  97%|█████████▋| 2100/2154 [03:26<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2101/2154 [03:26<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2103/2154 [03:26<00:05, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2104/2154 [03:26<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2105/2154 [03:26<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2106/2154 [03:26<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2107/2154 [03:26<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2108/2154 [03:27<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2109/2154 [03:27<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2110/2154 [03:27<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2111/2154 [03:27<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2112/2154 [03:27<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2113/2154 [03:27<00:04, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2114/2154 [03:27<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2115/2154 [03:27<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2116/2154 [03:27<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2117/2154 [03:27<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2118/2154 [03:28<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2119/2154 [03:28<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2120/2154 [03:28<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  98%|█████████▊| 2121/2154 [03:28<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▊| 2122/2154 [03:28<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▊| 2123/2154 [03:28<00:03, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▊| 2124/2154 [03:28<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▊| 2125/2154 [03:28<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▊| 2126/2154 [03:28<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▊| 2127/2154 [03:28<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2128/2154 [03:29<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2129/2154 [03:29<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2130/2154 [03:29<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2131/2154 [03:29<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2132/2154 [03:29<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2133/2154 [03:29<00:02, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2134/2154 [03:29<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2135/2154 [03:29<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2136/2154 [03:29<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2137/2154 [03:29<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2138/2154 [03:29<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2139/2154 [03:30<00:01, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2140/2154 [03:30<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2141/2154 [03:30<00:01, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2142/2154 [03:30<00:01, 10.18it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61:  99%|█████████▉| 2143/2154 [03:30<00:01, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2144/2154 [03:30<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2145/2154 [03:30<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2146/2154 [03:30<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2147/2154 [03:30<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2148/2154 [03:30<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2149/2154 [03:30<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2150/2154 [03:31<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2151/2154 [03:31<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2152/2154 [03:31<00:00, 10.19it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|█████████▉| 2153/2154 [03:31<00:00, 10.20it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.0985, train_loss_epoch=0.089]\n",
      "Epoch 61: 100%|██████████| 2154/2154 [03:31<00:00, 10.20it/s, loss=0.0841, v_num=0, train_loss_step=0.0778, val_loss=0.097, train_loss_epoch=0.089] \n",
      "Epoch 62:  94%|█████████▍| 2025/2154 [03:20<00:12, 10.08it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  94%|█████████▍| 2026/2154 [03:21<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2027/2154 [03:21<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2028/2154 [03:21<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2029/2154 [03:21<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2030/2154 [03:21<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2031/2154 [03:21<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2032/2154 [03:22<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2033/2154 [03:22<00:12, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2034/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  94%|█████████▍| 2035/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2036/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2037/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2038/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2039/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2040/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2041/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2042/2154 [03:22<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2043/2154 [03:23<00:11, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2044/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2045/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▍| 2046/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2047/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2048/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2049/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2050/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2051/2154 [03:23<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2052/2154 [03:24<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2053/2154 [03:24<00:10, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2054/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2055/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2056/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  95%|█████████▌| 2057/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2058/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2059/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2060/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2061/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2062/2154 [03:24<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2063/2154 [03:25<00:09, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2064/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2065/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2066/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2067/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2068/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2069/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2070/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2071/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2072/2154 [03:25<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▌| 2073/2154 [03:26<00:08, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▋| 2074/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▋| 2075/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▋| 2076/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▋| 2077/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  96%|█████████▋| 2078/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2079/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2080/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2081/2154 [03:26<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2082/2154 [03:27<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2083/2154 [03:27<00:07, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2084/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2085/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2086/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2087/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2088/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2089/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2090/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2091/2154 [03:27<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2092/2154 [03:28<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2093/2154 [03:28<00:06, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2094/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2095/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2096/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2097/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2098/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2099/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  97%|█████████▋| 2100/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2101/2154 [03:28<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2102/2154 [03:29<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2103/2154 [03:29<00:05, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2104/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2105/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2106/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2107/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2108/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2109/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2110/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2111/2154 [03:29<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2112/2154 [03:30<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2113/2154 [03:30<00:04, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2114/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2115/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2116/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2117/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2118/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2119/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2120/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  98%|█████████▊| 2121/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▊| 2122/2154 [03:30<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▊| 2123/2154 [03:31<00:03, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▊| 2124/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▊| 2125/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▊| 2126/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▊| 2127/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2128/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2129/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2130/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2131/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2132/2154 [03:31<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2133/2154 [03:32<00:02, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2134/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2135/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2136/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2137/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2138/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2139/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2140/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2141/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2142/2154 [03:32<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62:  99%|█████████▉| 2143/2154 [03:33<00:01, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2144/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2145/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2146/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2147/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2148/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2149/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2150/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2151/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2152/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|█████████▉| 2153/2154 [03:33<00:00, 10.06it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.097, train_loss_epoch=0.0874]\n",
      "Epoch 62: 100%|██████████| 2154/2154 [03:33<00:00, 10.07it/s, loss=0.088, v_num=0, train_loss_step=0.0963, val_loss=0.101, train_loss_epoch=0.0874]\n",
      "Epoch 63:  94%|█████████▍| 2025/2154 [03:17<00:12, 10.28it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  94%|█████████▍| 2026/2154 [03:17<00:12, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2027/2154 [03:17<00:12, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2028/2154 [03:17<00:12, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2029/2154 [03:17<00:12, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2030/2154 [03:17<00:12, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2031/2154 [03:17<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2032/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2033/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2034/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  94%|█████████▍| 2035/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2036/2154 [03:18<00:11, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2037/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2038/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2039/2154 [03:18<00:11, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2040/2154 [03:18<00:11, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2041/2154 [03:19<00:11, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2042/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2043/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2044/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2045/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▍| 2046/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2047/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2048/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2049/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2050/2154 [03:19<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2051/2154 [03:20<00:10, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2052/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2053/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2054/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2055/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2056/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  95%|█████████▌| 2057/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2058/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2059/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2060/2154 [03:20<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2061/2154 [03:21<00:09, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2062/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2063/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2064/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2065/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2066/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2067/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2068/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2069/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2070/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2071/2154 [03:21<00:08, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2072/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▌| 2073/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▋| 2074/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▋| 2075/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▋| 2076/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▋| 2077/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  96%|█████████▋| 2078/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2079/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2080/2154 [03:22<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2081/2154 [03:23<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2082/2154 [03:23<00:07, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2083/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2084/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2085/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2086/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2087/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2088/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2089/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2090/2154 [03:23<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2091/2154 [03:24<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2092/2154 [03:24<00:06, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2093/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2094/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2095/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2096/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2097/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2098/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2099/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  97%|█████████▋| 2100/2154 [03:24<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2101/2154 [03:25<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2102/2154 [03:25<00:05, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2103/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2104/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2105/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2106/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2107/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2108/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2109/2154 [03:25<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2110/2154 [03:25<00:04, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2111/2154 [03:26<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2112/2154 [03:26<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2113/2154 [03:26<00:04, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2114/2154 [03:26<00:03, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2115/2154 [03:26<00:03, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2116/2154 [03:26<00:03, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2117/2154 [03:26<00:03, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2118/2154 [03:26<00:03, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2119/2154 [03:26<00:03, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2120/2154 [03:26<00:03, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  98%|█████████▊| 2121/2154 [03:27<00:03, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▊| 2122/2154 [03:27<00:03, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▊| 2123/2154 [03:27<00:03, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▊| 2124/2154 [03:27<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▊| 2125/2154 [03:27<00:02, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▊| 2126/2154 [03:27<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▊| 2127/2154 [03:27<00:02, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2128/2154 [03:27<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2129/2154 [03:27<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2130/2154 [03:27<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2131/2154 [03:28<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2132/2154 [03:28<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2133/2154 [03:28<00:02, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2134/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2135/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2136/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2137/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2138/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2139/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2140/2154 [03:28<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2141/2154 [03:28<00:01, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2142/2154 [03:29<00:01, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63:  99%|█████████▉| 2143/2154 [03:29<00:01, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2144/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2145/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2146/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2147/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2148/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2149/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2150/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2151/2154 [03:29<00:00, 10.24it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2152/2154 [03:30<00:00, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|█████████▉| 2153/2154 [03:30<00:00, 10.25it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.101, train_loss_epoch=0.0878]\n",
      "Epoch 63: 100%|██████████| 2154/2154 [03:30<00:00, 10.26it/s, loss=0.0818, v_num=0, train_loss_step=0.084, val_loss=0.0976, train_loss_epoch=0.0878]\n",
      "Epoch 64:  94%|█████████▍| 2025/2154 [03:17<00:12, 10.24it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  94%|█████████▍| 2026/2154 [03:18<00:12, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2027/2154 [03:18<00:12, 10.22it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2028/2154 [03:18<00:12, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2029/2154 [03:18<00:12, 10.22it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2030/2154 [03:18<00:12, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2031/2154 [03:18<00:12, 10.22it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2032/2154 [03:18<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.22it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2034/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  94%|█████████▍| 2035/2154 [03:19<00:11, 10.22it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2036/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2037/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2038/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2039/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2040/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2041/2154 [03:19<00:11, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2042/2154 [03:19<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2044/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2045/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▍| 2046/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2047/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2048/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2049/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2050/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2051/2154 [03:20<00:10, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2052/2154 [03:20<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2054/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2055/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2056/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  95%|█████████▌| 2057/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2058/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2059/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2060/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2061/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2062/2154 [03:21<00:09, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2064/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2065/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2066/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2067/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2068/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2069/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2070/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2071/2154 [03:22<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▋| 2074/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▋| 2075/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▋| 2076/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▋| 2077/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  96%|█████████▋| 2078/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2079/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2080/2154 [03:23<00:07, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2081/2154 [03:23<00:07, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2084/2154 [03:24<00:06, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2085/2154 [03:24<00:06, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2086/2154 [03:24<00:06, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2087/2154 [03:24<00:06, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2088/2154 [03:24<00:06, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2089/2154 [03:24<00:06, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2090/2154 [03:24<00:06, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2091/2154 [03:24<00:06, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2093/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2094/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2095/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2096/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2097/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2098/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2099/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  97%|█████████▋| 2100/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2101/2154 [03:25<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2103/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2104/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2105/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2106/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2107/2154 [03:26<00:04, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2108/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2109/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2110/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2111/2154 [03:26<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2112/2154 [03:27<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2113/2154 [03:27<00:04, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2114/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2115/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2116/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2117/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2118/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2119/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2120/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  98%|█████████▊| 2121/2154 [03:27<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▊| 2122/2154 [03:28<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▊| 2123/2154 [03:28<00:03, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▊| 2124/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▊| 2125/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▊| 2126/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▊| 2127/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2128/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2129/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2130/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2131/2154 [03:28<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2132/2154 [03:29<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2133/2154 [03:29<00:02, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2134/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2135/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2136/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2137/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2138/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2139/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2140/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2141/2154 [03:29<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2142/2154 [03:30<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64:  99%|█████████▉| 2143/2154 [03:30<00:01, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2144/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2145/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2146/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2147/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2148/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2149/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2150/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2151/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2152/2154 [03:30<00:00, 10.20it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|█████████▉| 2153/2154 [03:30<00:00, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0976, train_loss_epoch=0.0877]\n",
      "Epoch 64: 100%|██████████| 2154/2154 [03:30<00:00, 10.21it/s, loss=0.0888, v_num=0, train_loss_step=0.086, val_loss=0.0958, train_loss_epoch=0.0877]\n",
      "Epoch 65:  94%|█████████▍| 2025/2154 [03:19<00:12, 10.15it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  94%|█████████▍| 2026/2154 [03:20<00:12, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2027/2154 [03:20<00:12, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2030/2154 [03:20<00:12, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2031/2154 [03:20<00:12, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2032/2154 [03:20<00:12, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2033/2154 [03:20<00:11, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2036/2154 [03:21<00:11, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2037/2154 [03:21<00:11, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2040/2154 [03:21<00:11, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2041/2154 [03:21<00:11, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2042/2154 [03:21<00:11, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2043/2154 [03:21<00:10, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2044/2154 [03:21<00:10, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▍| 2046/2154 [03:22<00:10, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2047/2154 [03:22<00:10, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2050/2154 [03:22<00:10, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2051/2154 [03:22<00:10, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2052/2154 [03:22<00:10, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2053/2154 [03:22<00:09, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2054/2154 [03:22<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2055/2154 [03:22<00:09, 10.13it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2056/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  95%|█████████▌| 2057/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2060/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2061/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2062/2154 [03:23<00:09, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2063/2154 [03:23<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2064/2154 [03:23<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2065/2154 [03:23<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2066/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2072/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▌| 2073/2154 [03:24<00:08, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▋| 2074/2154 [03:24<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▋| 2075/2154 [03:24<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▋| 2076/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▋| 2077/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2082/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2083/2154 [03:25<00:07, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2084/2154 [03:25<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2085/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2086/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2087/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2092/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2093/2154 [03:26<00:06, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2095/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2096/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2097/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2102/2154 [03:27<00:05, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2103/2154 [03:27<00:05, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2104/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2105/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2106/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2107/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2108/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2114/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2115/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2116/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2117/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2118/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▊| 2124/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▊| 2125/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▊| 2126/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▊| 2127/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2128/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2129/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2133/2154 [03:31<00:02, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2134/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2135/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2136/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2137/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2138/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2139/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65:  99%|█████████▉| 2143/2154 [03:32<00:01, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2144/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2145/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2146/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2147/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2148/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.10it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.11it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0958, train_loss_epoch=0.0859]\n",
      "Epoch 65: 100%|██████████| 2154/2154 [03:32<00:00, 10.12it/s, loss=0.0857, v_num=0, train_loss_step=0.0944, val_loss=0.0962, train_loss_epoch=0.0859]\n",
      "Epoch 66:  94%|█████████▍| 2025/2154 [03:16<00:12, 10.29it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  94%|█████████▍| 2026/2154 [03:17<00:12, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2027/2154 [03:17<00:12, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2028/2154 [03:17<00:12, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2029/2154 [03:17<00:12, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2030/2154 [03:17<00:12, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2031/2154 [03:17<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2032/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2033/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2034/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  94%|█████████▍| 2035/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2036/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2037/2154 [03:18<00:11, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2038/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2039/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2040/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2041/2154 [03:18<00:11, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2042/2154 [03:18<00:10, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2043/2154 [03:19<00:10, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2044/2154 [03:19<00:10, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2045/2154 [03:19<00:10, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▍| 2046/2154 [03:19<00:10, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2047/2154 [03:19<00:10, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2048/2154 [03:19<00:10, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2049/2154 [03:19<00:10, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2050/2154 [03:19<00:10, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2051/2154 [03:19<00:10, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2052/2154 [03:19<00:09, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2053/2154 [03:19<00:09, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2054/2154 [03:20<00:09, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2055/2154 [03:20<00:09, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2056/2154 [03:20<00:09, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  95%|█████████▌| 2057/2154 [03:20<00:09, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2058/2154 [03:20<00:09, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2059/2154 [03:20<00:09, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2060/2154 [03:20<00:09, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2061/2154 [03:20<00:09, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2062/2154 [03:20<00:08, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2063/2154 [03:20<00:08, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2064/2154 [03:21<00:08, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2065/2154 [03:21<00:08, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2066/2154 [03:21<00:08, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2067/2154 [03:21<00:08, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2068/2154 [03:21<00:08, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2069/2154 [03:21<00:08, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2070/2154 [03:21<00:08, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2071/2154 [03:21<00:08, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2072/2154 [03:21<00:07, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▌| 2073/2154 [03:21<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▋| 2074/2154 [03:22<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▋| 2075/2154 [03:22<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▋| 2076/2154 [03:22<00:07, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▋| 2077/2154 [03:22<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  96%|█████████▋| 2078/2154 [03:22<00:07, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2079/2154 [03:22<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2080/2154 [03:22<00:07, 10.26it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2081/2154 [03:22<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2082/2154 [03:22<00:07, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2083/2154 [03:22<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2084/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2085/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2086/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2087/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2088/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2089/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2090/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2091/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2092/2154 [03:23<00:06, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2093/2154 [03:23<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2094/2154 [03:23<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2095/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2096/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2097/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2098/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2099/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  97%|█████████▋| 2100/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2101/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2102/2154 [03:24<00:05, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2103/2154 [03:24<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2104/2154 [03:24<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2105/2154 [03:24<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2106/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2107/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2108/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2109/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2110/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2111/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2112/2154 [03:25<00:04, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2113/2154 [03:25<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2114/2154 [03:25<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2115/2154 [03:25<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2116/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2117/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2118/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2119/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2120/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  98%|█████████▊| 2121/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▊| 2122/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▊| 2123/2154 [03:26<00:03, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▊| 2124/2154 [03:26<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▊| 2125/2154 [03:26<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▊| 2126/2154 [03:26<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▊| 2127/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2128/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2129/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2130/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2131/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2132/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2133/2154 [03:27<00:02, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2134/2154 [03:27<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2135/2154 [03:27<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2136/2154 [03:27<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2137/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2138/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2139/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2140/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2141/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2142/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66:  99%|█████████▉| 2143/2154 [03:28<00:01, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2144/2154 [03:28<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2145/2154 [03:28<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2146/2154 [03:28<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2147/2154 [03:29<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2148/2154 [03:29<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2149/2154 [03:29<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2150/2154 [03:29<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2151/2154 [03:29<00:00, 10.27it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2152/2154 [03:29<00:00, 10.28it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|█████████▉| 2153/2154 [03:29<00:00, 10.28it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.0962, train_loss_epoch=0.0864]\n",
      "Epoch 66: 100%|██████████| 2154/2154 [03:29<00:00, 10.28it/s, loss=0.0895, v_num=0, train_loss_step=0.0807, val_loss=0.100, train_loss_epoch=0.0864] \n",
      "Epoch 67:  94%|█████████▍| 2025/2154 [03:20<00:12, 10.12it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  94%|█████████▍| 2026/2154 [03:20<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2027/2154 [03:20<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2030/2154 [03:21<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2031/2154 [03:21<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2032/2154 [03:21<00:12, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2033/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2034/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  94%|█████████▍| 2035/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2036/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2037/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2040/2154 [03:22<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2041/2154 [03:22<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2042/2154 [03:22<00:11, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2043/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2044/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2045/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▍| 2046/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2047/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2050/2154 [03:22<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2051/2154 [03:23<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2052/2154 [03:23<00:10, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2053/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2054/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2055/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2056/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  95%|█████████▌| 2057/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2060/2154 [03:23<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2061/2154 [03:24<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2062/2154 [03:24<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2063/2154 [03:24<00:09, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2064/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2065/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2066/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2072/2154 [03:25<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▌| 2073/2154 [03:25<00:08, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▋| 2074/2154 [03:25<00:07, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▋| 2075/2154 [03:25<00:07, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▋| 2076/2154 [03:25<00:07, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▋| 2077/2154 [03:25<00:07, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2082/2154 [03:26<00:07, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2083/2154 [03:26<00:07, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2084/2154 [03:26<00:06, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2085/2154 [03:26<00:06, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2086/2154 [03:26<00:06, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2087/2154 [03:26<00:06, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2092/2154 [03:27<00:06, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2093/2154 [03:27<00:06, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2094/2154 [03:27<00:05, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2095/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2096/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2097/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2102/2154 [03:28<00:05, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2103/2154 [03:28<00:05, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2104/2154 [03:28<00:04, 10.10it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2105/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2106/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2107/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2108/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2114/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2115/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2116/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2117/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2118/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▊| 2124/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▊| 2125/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▊| 2126/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▊| 2127/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2128/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2129/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2134/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2135/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2136/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2137/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2138/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2139/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2144/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2145/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2146/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2147/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2148/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.11it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.12it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.12it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.100, train_loss_epoch=0.0866]\n",
      "Epoch 67: 100%|██████████| 2154/2154 [03:32<00:00, 10.13it/s, loss=0.0811, v_num=0, train_loss_step=0.077, val_loss=0.099, train_loss_epoch=0.0866]\n",
      "Epoch 68:  94%|█████████▍| 2025/2154 [03:18<00:12, 10.22it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  94%|█████████▍| 2026/2154 [03:18<00:12, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2027/2154 [03:18<00:12, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2028/2154 [03:18<00:12, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2029/2154 [03:18<00:12, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2030/2154 [03:19<00:12, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2032/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2034/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  94%|█████████▍| 2035/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2036/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2037/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2038/2154 [03:19<00:11, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2039/2154 [03:19<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2042/2154 [03:20<00:10, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2044/2154 [03:20<00:10, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2045/2154 [03:20<00:10, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▍| 2046/2154 [03:20<00:10, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2047/2154 [03:20<00:10, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2048/2154 [03:20<00:10, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2049/2154 [03:20<00:10, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2052/2154 [03:21<00:10, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2054/2154 [03:21<00:09, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2055/2154 [03:21<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2056/2154 [03:21<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  95%|█████████▌| 2057/2154 [03:21<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2058/2154 [03:21<00:09, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2059/2154 [03:21<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2062/2154 [03:22<00:09, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2064/2154 [03:22<00:08, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2065/2154 [03:22<00:08, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2066/2154 [03:22<00:08, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2067/2154 [03:22<00:08, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2068/2154 [03:22<00:08, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2069/2154 [03:22<00:08, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2070/2154 [03:23<00:08, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2071/2154 [03:23<00:08, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▋| 2074/2154 [03:23<00:07, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▋| 2075/2154 [03:23<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▋| 2076/2154 [03:23<00:07, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▋| 2077/2154 [03:23<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  96%|█████████▋| 2078/2154 [03:23<00:07, 10.19it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2079/2154 [03:23<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2080/2154 [03:24<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2081/2154 [03:24<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2084/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2085/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2086/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2087/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2088/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2089/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2090/2154 [03:24<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2091/2154 [03:25<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2093/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2094/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2095/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2096/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2097/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2098/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2099/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  97%|█████████▋| 2100/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2101/2154 [03:25<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2103/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2104/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2105/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2106/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2107/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2108/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2109/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2110/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2111/2154 [03:26<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2112/2154 [03:27<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2113/2154 [03:27<00:04, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2114/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2115/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2116/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2117/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2118/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2119/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2120/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  98%|█████████▊| 2121/2154 [03:27<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▊| 2122/2154 [03:28<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▊| 2123/2154 [03:28<00:03, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▊| 2124/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▊| 2125/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▊| 2126/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▊| 2127/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2128/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2129/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2130/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2131/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2132/2154 [03:28<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2133/2154 [03:29<00:02, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2134/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2135/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2136/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2137/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2138/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2139/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2140/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2141/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2142/2154 [03:29<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68:  99%|█████████▉| 2143/2154 [03:30<00:01, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2144/2154 [03:30<00:00, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2145/2154 [03:30<00:00, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2146/2154 [03:30<00:00, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2147/2154 [03:30<00:00, 10.21it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2148/2154 [03:30<00:00, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2149/2154 [03:30<00:00, 10.21it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2150/2154 [03:30<00:00, 10.20it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2151/2154 [03:30<00:00, 10.21it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2152/2154 [03:30<00:00, 10.21it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|█████████▉| 2153/2154 [03:30<00:00, 10.21it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.099, train_loss_epoch=0.0851]\n",
      "Epoch 68: 100%|██████████| 2154/2154 [03:30<00:00, 10.22it/s, loss=0.0864, v_num=0, train_loss_step=0.0821, val_loss=0.0956, train_loss_epoch=0.0851]\n",
      "Epoch 69:  94%|█████████▍| 2025/2154 [03:19<00:12, 10.16it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69:  94%|█████████▍| 2026/2154 [03:19<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2027/2154 [03:19<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2030/2154 [03:20<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2031/2154 [03:20<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2032/2154 [03:20<00:12, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2033/2154 [03:20<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2036/2154 [03:20<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2037/2154 [03:20<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2040/2154 [03:21<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2041/2154 [03:21<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2042/2154 [03:21<00:11, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2043/2154 [03:21<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2044/2154 [03:21<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▍| 2046/2154 [03:21<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2047/2154 [03:21<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2050/2154 [03:22<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2051/2154 [03:22<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2052/2154 [03:22<00:10, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2053/2154 [03:22<00:09, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2054/2154 [03:22<00:09, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2055/2154 [03:22<00:09, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2056/2154 [03:22<00:09, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  95%|█████████▌| 2057/2154 [03:22<00:09, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.14it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2060/2154 [03:23<00:09, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2061/2154 [03:23<00:09, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2062/2154 [03:23<00:09, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2063/2154 [03:23<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2064/2154 [03:23<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2065/2154 [03:23<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2066/2154 [03:23<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2072/2154 [03:24<00:08, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▌| 2073/2154 [03:24<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▋| 2074/2154 [03:24<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▋| 2075/2154 [03:24<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▋| 2076/2154 [03:24<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▋| 2077/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2082/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2083/2154 [03:25<00:07, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2084/2154 [03:25<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2085/2154 [03:25<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2087/2154 [03:26<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.13it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2092/2154 [03:26<00:06, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2093/2154 [03:26<00:06, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2095/2154 [03:26<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2096/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2097/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2102/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2103/2154 [03:27<00:05, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2104/2154 [03:27<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2105/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2106/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2107/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2108/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2114/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2115/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2116/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2117/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2118/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▊| 2124/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▊| 2125/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▊| 2126/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▊| 2127/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2128/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2129/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2134/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2135/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2136/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2137/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2138/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2139/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2144/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2145/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2146/2154 [03:32<00:00, 10.10it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2147/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2148/2154 [03:32<00:00, 10.10it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.10it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.11it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0956, train_loss_epoch=0.0847]\n",
      "Epoch 69: 100%|██████████| 2154/2154 [03:32<00:00, 10.12it/s, loss=0.0878, v_num=0, train_loss_step=0.085, val_loss=0.0944, train_loss_epoch=0.0847]\n",
      "Epoch 70:  94%|█████████▍| 2025/2154 [03:20<00:12, 10.09it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  94%|█████████▍| 2026/2154 [03:21<00:12, 10.06it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2027/2154 [03:21<00:12, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2028/2154 [03:21<00:12, 10.06it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2029/2154 [03:21<00:12, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2030/2154 [03:21<00:12, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2031/2154 [03:21<00:12, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2032/2154 [03:21<00:12, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2033/2154 [03:21<00:12, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2034/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  94%|█████████▍| 2035/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2036/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2037/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2038/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2039/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2040/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2041/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2042/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2043/2154 [03:22<00:11, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2044/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2045/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▍| 2046/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2047/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2048/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2049/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2050/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2051/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2052/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2053/2154 [03:23<00:10, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2054/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2055/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2056/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  95%|█████████▌| 2057/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2058/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2059/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2060/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2061/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2062/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2063/2154 [03:24<00:09, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2064/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2065/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2066/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2067/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2068/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2069/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2070/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2071/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2072/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▌| 2073/2154 [03:25<00:08, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▋| 2074/2154 [03:25<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▋| 2075/2154 [03:25<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▋| 2076/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▋| 2077/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  96%|█████████▋| 2078/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2079/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2080/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2081/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2082/2154 [03:26<00:07, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2083/2154 [03:26<00:07, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2084/2154 [03:26<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2085/2154 [03:26<00:06, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2086/2154 [03:27<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2087/2154 [03:27<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2088/2154 [03:27<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2089/2154 [03:27<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2090/2154 [03:27<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2091/2154 [03:27<00:06, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2092/2154 [03:27<00:06, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2093/2154 [03:27<00:06, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2094/2154 [03:27<00:05, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2095/2154 [03:27<00:05, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2096/2154 [03:28<00:05, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2097/2154 [03:28<00:05, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2098/2154 [03:28<00:05, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2099/2154 [03:28<00:05, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  97%|█████████▋| 2100/2154 [03:28<00:05, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2101/2154 [03:28<00:05, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2102/2154 [03:28<00:05, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2103/2154 [03:28<00:05, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2104/2154 [03:28<00:04, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2105/2154 [03:28<00:04, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2106/2154 [03:29<00:04, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2107/2154 [03:29<00:04, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2108/2154 [03:29<00:04, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2109/2154 [03:29<00:04, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2110/2154 [03:29<00:04, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2111/2154 [03:29<00:04, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2112/2154 [03:29<00:04, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2113/2154 [03:29<00:04, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2114/2154 [03:29<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2115/2154 [03:29<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2116/2154 [03:30<00:03, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2117/2154 [03:30<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2118/2154 [03:30<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2119/2154 [03:30<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2120/2154 [03:30<00:03, 10.07it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  98%|█████████▊| 2121/2154 [03:30<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▊| 2122/2154 [03:30<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▊| 2123/2154 [03:30<00:03, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▊| 2124/2154 [03:30<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▊| 2125/2154 [03:30<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▊| 2126/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▊| 2127/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2128/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2129/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2130/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2131/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2132/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2133/2154 [03:31<00:02, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2134/2154 [03:31<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2135/2154 [03:31<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2136/2154 [03:31<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2137/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2138/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2139/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2140/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2141/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2142/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70:  99%|█████████▉| 2143/2154 [03:32<00:01, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2144/2154 [03:32<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2145/2154 [03:32<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2146/2154 [03:32<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2147/2154 [03:32<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2148/2154 [03:33<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2149/2154 [03:33<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2150/2154 [03:33<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2151/2154 [03:33<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2152/2154 [03:33<00:00, 10.08it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|█████████▉| 2153/2154 [03:33<00:00, 10.09it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0944, train_loss_epoch=0.0851]\n",
      "Epoch 70: 100%|██████████| 2154/2154 [03:33<00:00, 10.09it/s, loss=0.0932, v_num=0, train_loss_step=0.0791, val_loss=0.0983, train_loss_epoch=0.0851]\n",
      "Epoch 71:  94%|█████████▍| 2025/2154 [03:18<00:12, 10.18it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  94%|█████████▍| 2026/2154 [03:19<00:12, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2027/2154 [03:19<00:12, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2028/2154 [03:19<00:12, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2029/2154 [03:19<00:12, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2030/2154 [03:19<00:12, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2032/2154 [03:20<00:12, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2033/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2036/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2037/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2038/2154 [03:20<00:11, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2039/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2042/2154 [03:21<00:11, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2043/2154 [03:21<00:10, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2044/2154 [03:21<00:10, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▍| 2046/2154 [03:21<00:10, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2047/2154 [03:21<00:10, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2048/2154 [03:21<00:10, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2049/2154 [03:21<00:10, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2052/2154 [03:22<00:10, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2053/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2054/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2055/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2056/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  95%|█████████▌| 2057/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2058/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2059/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2062/2154 [03:23<00:09, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2063/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2064/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2065/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2066/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2067/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2068/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2069/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2070/2154 [03:23<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2072/2154 [03:24<00:08, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▌| 2073/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▋| 2074/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▋| 2075/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▋| 2076/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▋| 2077/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  96%|█████████▋| 2078/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2079/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2080/2154 [03:24<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2082/2154 [03:25<00:07, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2083/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2084/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2085/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2087/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2088/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2089/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2090/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2091/2154 [03:25<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2092/2154 [03:26<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2093/2154 [03:26<00:06, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2095/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2096/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2097/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2098/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2099/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  97%|█████████▋| 2100/2154 [03:26<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2102/2154 [03:27<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2103/2154 [03:27<00:05, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2104/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2105/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2106/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2107/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2108/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2109/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2110/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2111/2154 [03:27<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2114/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2115/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2116/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2117/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2118/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2119/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2120/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  98%|█████████▊| 2121/2154 [03:28<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▊| 2124/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▊| 2125/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▊| 2126/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▊| 2127/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2128/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2129/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2130/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2131/2154 [03:29<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2134/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2135/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2136/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2137/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2138/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2139/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2140/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2141/2154 [03:30<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2144/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2145/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2146/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2147/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2148/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2149/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2150/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2151/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2152/2154 [03:31<00:00, 10.15it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.0983, train_loss_epoch=0.0858]\n",
      "Epoch 71: 100%|██████████| 2154/2154 [03:32<00:00, 10.16it/s, loss=0.0832, v_num=0, train_loss_step=0.0916, val_loss=0.100, train_loss_epoch=0.0858] \n",
      "Epoch 72:  94%|█████████▍| 2025/2154 [03:21<00:12, 10.07it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  94%|█████████▍| 2026/2154 [03:21<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2027/2154 [03:21<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2028/2154 [03:21<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2029/2154 [03:21<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2030/2154 [03:21<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2031/2154 [03:22<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2032/2154 [03:22<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2033/2154 [03:22<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2034/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  94%|█████████▍| 2035/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2036/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2037/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2038/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2039/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2040/2154 [03:22<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2041/2154 [03:23<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2042/2154 [03:23<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2043/2154 [03:23<00:11, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2044/2154 [03:23<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2045/2154 [03:23<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▍| 2046/2154 [03:23<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2047/2154 [03:23<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2048/2154 [03:23<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2049/2154 [03:23<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2050/2154 [03:24<00:10, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2051/2154 [03:24<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2052/2154 [03:24<00:10, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2053/2154 [03:24<00:10, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2054/2154 [03:24<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2055/2154 [03:24<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2056/2154 [03:24<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  95%|█████████▌| 2057/2154 [03:24<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2058/2154 [03:24<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2059/2154 [03:24<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2060/2154 [03:25<00:09, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2061/2154 [03:25<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2062/2154 [03:25<00:09, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2063/2154 [03:25<00:09, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2064/2154 [03:25<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2065/2154 [03:25<00:08, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2066/2154 [03:25<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2067/2154 [03:25<00:08, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2068/2154 [03:25<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2069/2154 [03:25<00:08, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2070/2154 [03:26<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2071/2154 [03:26<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2072/2154 [03:26<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▌| 2073/2154 [03:26<00:08, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▋| 2074/2154 [03:26<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▋| 2075/2154 [03:26<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▋| 2076/2154 [03:26<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▋| 2077/2154 [03:26<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  96%|█████████▋| 2078/2154 [03:26<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2079/2154 [03:26<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2080/2154 [03:27<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2081/2154 [03:27<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2082/2154 [03:27<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2083/2154 [03:27<00:07, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2084/2154 [03:27<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2085/2154 [03:27<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2086/2154 [03:27<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2087/2154 [03:27<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2088/2154 [03:27<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2089/2154 [03:28<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2090/2154 [03:28<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2091/2154 [03:28<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2092/2154 [03:28<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2093/2154 [03:28<00:06, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2094/2154 [03:28<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2095/2154 [03:28<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2096/2154 [03:28<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2097/2154 [03:28<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2098/2154 [03:28<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2099/2154 [03:29<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  97%|█████████▋| 2100/2154 [03:29<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2101/2154 [03:29<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2102/2154 [03:29<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2103/2154 [03:29<00:05, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2104/2154 [03:29<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2105/2154 [03:29<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2106/2154 [03:29<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2107/2154 [03:29<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2108/2154 [03:29<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2109/2154 [03:30<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2110/2154 [03:30<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2111/2154 [03:30<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2112/2154 [03:30<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2113/2154 [03:30<00:04, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2114/2154 [03:30<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2115/2154 [03:30<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2116/2154 [03:30<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2117/2154 [03:30<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2118/2154 [03:30<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2119/2154 [03:31<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2120/2154 [03:31<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  98%|█████████▊| 2121/2154 [03:31<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▊| 2122/2154 [03:31<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▊| 2123/2154 [03:31<00:03, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▊| 2124/2154 [03:31<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▊| 2125/2154 [03:31<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▊| 2126/2154 [03:31<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▊| 2127/2154 [03:31<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2128/2154 [03:31<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2129/2154 [03:32<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2130/2154 [03:32<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2131/2154 [03:32<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2132/2154 [03:32<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2133/2154 [03:32<00:02, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2134/2154 [03:32<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2135/2154 [03:32<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2136/2154 [03:32<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2137/2154 [03:32<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2138/2154 [03:33<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2139/2154 [03:33<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2140/2154 [03:33<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2141/2154 [03:33<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2142/2154 [03:33<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72:  99%|█████████▉| 2143/2154 [03:33<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2144/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2145/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2146/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2147/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2148/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2149/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2150/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2151/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2152/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|█████████▉| 2153/2154 [03:34<00:00, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.100, train_loss_epoch=0.0847]\n",
      "Epoch 72: 100%|██████████| 2154/2154 [03:34<00:00, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.120, val_loss=0.0945, train_loss_epoch=0.0847]\n",
      "Epoch 73:  94%|█████████▍| 2025/2154 [03:21<00:12, 10.03it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  94%|█████████▍| 2026/2154 [03:22<00:12, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2027/2154 [03:22<00:12, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2028/2154 [03:22<00:12, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2029/2154 [03:22<00:12, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2030/2154 [03:22<00:12, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2031/2154 [03:22<00:12, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2032/2154 [03:23<00:12, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2033/2154 [03:23<00:12, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2034/2154 [03:23<00:11, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  94%|█████████▍| 2035/2154 [03:23<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2036/2154 [03:23<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2037/2154 [03:23<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2038/2154 [03:23<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2039/2154 [03:23<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2040/2154 [03:23<00:11, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2041/2154 [03:23<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2042/2154 [03:24<00:11, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2043/2154 [03:24<00:11, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2044/2154 [03:24<00:10, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2045/2154 [03:24<00:10, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▍| 2046/2154 [03:24<00:10, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2047/2154 [03:24<00:10, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2048/2154 [03:24<00:10, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2049/2154 [03:24<00:10, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2050/2154 [03:24<00:10, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2051/2154 [03:24<00:10, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2052/2154 [03:25<00:10, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2053/2154 [03:25<00:10, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2054/2154 [03:25<00:09, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2055/2154 [03:25<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2056/2154 [03:25<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  95%|█████████▌| 2057/2154 [03:25<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2058/2154 [03:25<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2059/2154 [03:25<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2060/2154 [03:25<00:09, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2061/2154 [03:25<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2062/2154 [03:26<00:09, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2063/2154 [03:26<00:09, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2064/2154 [03:26<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2065/2154 [03:26<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2066/2154 [03:26<00:08, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2067/2154 [03:26<00:08, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2068/2154 [03:26<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2069/2154 [03:26<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2070/2154 [03:26<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2071/2154 [03:27<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2072/2154 [03:27<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▌| 2073/2154 [03:27<00:08, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▋| 2074/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▋| 2075/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▋| 2076/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▋| 2077/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  96%|█████████▋| 2078/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2079/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2080/2154 [03:27<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2081/2154 [03:28<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2082/2154 [03:28<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2083/2154 [03:28<00:07, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2084/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2085/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2086/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2087/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2088/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2089/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2090/2154 [03:28<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2091/2154 [03:29<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2092/2154 [03:29<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2093/2154 [03:29<00:06, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2094/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2095/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2096/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2097/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2098/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2099/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  97%|█████████▋| 2100/2154 [03:29<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2101/2154 [03:30<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2102/2154 [03:30<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2103/2154 [03:30<00:05, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2104/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2105/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2106/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2107/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2108/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2109/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2110/2154 [03:30<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2111/2154 [03:31<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2112/2154 [03:31<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2113/2154 [03:31<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2114/2154 [03:31<00:04, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2115/2154 [03:31<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2116/2154 [03:31<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2117/2154 [03:31<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2118/2154 [03:31<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2119/2154 [03:31<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2120/2154 [03:31<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  98%|█████████▊| 2121/2154 [03:32<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▊| 2122/2154 [03:32<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▊| 2123/2154 [03:32<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▊| 2124/2154 [03:32<00:03, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▊| 2125/2154 [03:32<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▊| 2126/2154 [03:32<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▊| 2127/2154 [03:32<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2128/2154 [03:32<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2129/2154 [03:32<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2130/2154 [03:33<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2131/2154 [03:33<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2132/2154 [03:33<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2133/2154 [03:33<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2134/2154 [03:33<00:02, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2135/2154 [03:33<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2136/2154 [03:33<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2137/2154 [03:33<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2138/2154 [03:33<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2139/2154 [03:33<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2140/2154 [03:33<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2141/2154 [03:34<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2142/2154 [03:34<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73:  99%|█████████▉| 2143/2154 [03:34<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2144/2154 [03:34<00:01, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2145/2154 [03:34<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2146/2154 [03:34<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2147/2154 [03:34<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2148/2154 [03:34<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2149/2154 [03:34<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2150/2154 [03:35<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2151/2154 [03:35<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2152/2154 [03:35<00:00, 10.00it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|█████████▉| 2153/2154 [03:35<00:00, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0945, train_loss_epoch=0.0851]\n",
      "Epoch 73: 100%|██████████| 2154/2154 [03:35<00:00, 10.01it/s, loss=0.0869, v_num=0, train_loss_step=0.0738, val_loss=0.0994, train_loss_epoch=0.0851]\n",
      "Epoch 74:  94%|█████████▍| 2025/2154 [03:16<00:12, 10.29it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  94%|█████████▍| 2026/2154 [03:17<00:12, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2027/2154 [03:17<00:12, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2028/2154 [03:17<00:12, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2029/2154 [03:17<00:12, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2030/2154 [03:17<00:12, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2031/2154 [03:17<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2032/2154 [03:17<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2033/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2034/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  94%|█████████▍| 2035/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2036/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2037/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2038/2154 [03:18<00:11, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2039/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2040/2154 [03:18<00:11, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2041/2154 [03:18<00:11, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2042/2154 [03:18<00:10, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2043/2154 [03:18<00:10, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2044/2154 [03:19<00:10, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2045/2154 [03:19<00:10, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▍| 2046/2154 [03:19<00:10, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2047/2154 [03:19<00:10, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2048/2154 [03:19<00:10, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2049/2154 [03:19<00:10, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2050/2154 [03:19<00:10, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2051/2154 [03:19<00:10, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2052/2154 [03:19<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2053/2154 [03:19<00:09, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2054/2154 [03:20<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2055/2154 [03:20<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2056/2154 [03:20<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  95%|█████████▌| 2057/2154 [03:20<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2058/2154 [03:20<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2059/2154 [03:20<00:09, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2060/2154 [03:20<00:09, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2061/2154 [03:20<00:09, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2062/2154 [03:20<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2063/2154 [03:20<00:08, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2064/2154 [03:21<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2065/2154 [03:21<00:08, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2066/2154 [03:21<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2067/2154 [03:21<00:08, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2068/2154 [03:21<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2069/2154 [03:21<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2070/2154 [03:21<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2071/2154 [03:21<00:08, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2072/2154 [03:21<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▌| 2073/2154 [03:21<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▋| 2074/2154 [03:22<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▋| 2075/2154 [03:22<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▋| 2076/2154 [03:22<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▋| 2077/2154 [03:22<00:07, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  96%|█████████▋| 2078/2154 [03:22<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2079/2154 [03:22<00:07, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2080/2154 [03:22<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2081/2154 [03:22<00:07, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2082/2154 [03:22<00:07, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2083/2154 [03:22<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2084/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2085/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2086/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2087/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2088/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2089/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2090/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2091/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2092/2154 [03:23<00:06, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2093/2154 [03:23<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2094/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2095/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2096/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2097/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2098/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2099/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  97%|█████████▋| 2100/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2101/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2102/2154 [03:24<00:05, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2103/2154 [03:24<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2104/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2105/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2106/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2107/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2108/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2109/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2110/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2111/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2112/2154 [03:25<00:04, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2113/2154 [03:25<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2114/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2115/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2116/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2117/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2118/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2119/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2120/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  98%|█████████▊| 2121/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▊| 2122/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▊| 2123/2154 [03:26<00:03, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▊| 2124/2154 [03:26<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▊| 2125/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▊| 2126/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▊| 2127/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2128/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2129/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2130/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2131/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2132/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2133/2154 [03:27<00:02, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2134/2154 [03:27<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2135/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2136/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2137/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2138/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2139/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2140/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2141/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2142/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74:  99%|█████████▉| 2143/2154 [03:28<00:01, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2144/2154 [03:28<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2145/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2146/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2147/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2148/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2149/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2150/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2151/2154 [03:29<00:00, 10.26it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2152/2154 [03:29<00:00, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|█████████▉| 2153/2154 [03:29<00:00, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0994, train_loss_epoch=0.0836]\n",
      "Epoch 74: 100%|██████████| 2154/2154 [03:29<00:00, 10.27it/s, loss=0.0913, v_num=0, train_loss_step=0.113, val_loss=0.0957, train_loss_epoch=0.0836]\n",
      "Epoch 75:  94%|█████████▍| 2025/2154 [03:19<00:12, 10.14it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  94%|█████████▍| 2026/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2027/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2030/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2031/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2032/2154 [03:20<00:12, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2033/2154 [03:20<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2034/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  94%|█████████▍| 2035/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2036/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2037/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2040/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2041/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2042/2154 [03:21<00:11, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2043/2154 [03:21<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2044/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2045/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▍| 2046/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2047/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2050/2154 [03:22<00:10, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2051/2154 [03:22<00:10, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2052/2154 [03:22<00:10, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2053/2154 [03:22<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2054/2154 [03:23<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2055/2154 [03:23<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2056/2154 [03:23<00:09, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  95%|█████████▌| 2057/2154 [03:23<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2060/2154 [03:23<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2061/2154 [03:23<00:09, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2062/2154 [03:23<00:09, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2063/2154 [03:23<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2064/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2065/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2066/2154 [03:24<00:08, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2072/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▌| 2073/2154 [03:24<00:08, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▋| 2074/2154 [03:25<00:07, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▋| 2075/2154 [03:25<00:07, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▋| 2076/2154 [03:25<00:07, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▋| 2077/2154 [03:25<00:07, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2082/2154 [03:25<00:07, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2083/2154 [03:25<00:07, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2084/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2085/2154 [03:26<00:06, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2086/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2087/2154 [03:26<00:06, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2092/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2093/2154 [03:26<00:06, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2094/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2095/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2096/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2097/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2102/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2103/2154 [03:27<00:05, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2104/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2105/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2106/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2107/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2108/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2114/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2115/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2116/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2117/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2118/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▊| 2124/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▊| 2125/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▊| 2126/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▊| 2127/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2128/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2129/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2134/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2135/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2136/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2137/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2138/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2139/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2144/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2145/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2146/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2147/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2148/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2149/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.11it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.0957, train_loss_epoch=0.0848]\n",
      "Epoch 75: 100%|██████████| 2154/2154 [03:32<00:00, 10.12it/s, loss=0.0888, v_num=0, train_loss_step=0.0871, val_loss=0.104, train_loss_epoch=0.0848] \n",
      "Epoch 76:  94%|█████████▍| 2025/2154 [03:19<00:12, 10.15it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  94%|█████████▍| 2026/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2027/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2028/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2029/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2030/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2031/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2032/2154 [03:20<00:12, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2033/2154 [03:20<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2036/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2037/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2038/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2039/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2040/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2041/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2042/2154 [03:21<00:11, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2043/2154 [03:21<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2044/2154 [03:21<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▍| 2046/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2047/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2048/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2049/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2050/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2051/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2052/2154 [03:22<00:10, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2053/2154 [03:22<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2054/2154 [03:22<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2055/2154 [03:22<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2056/2154 [03:22<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  95%|█████████▌| 2057/2154 [03:23<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2058/2154 [03:23<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2059/2154 [03:23<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2060/2154 [03:23<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2061/2154 [03:23<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2062/2154 [03:23<00:09, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2063/2154 [03:23<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2064/2154 [03:23<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2065/2154 [03:23<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2066/2154 [03:23<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2067/2154 [03:24<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2068/2154 [03:24<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2069/2154 [03:24<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2070/2154 [03:24<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2071/2154 [03:24<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2072/2154 [03:24<00:08, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▌| 2073/2154 [03:24<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▋| 2074/2154 [03:24<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▋| 2075/2154 [03:24<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▋| 2076/2154 [03:24<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▋| 2077/2154 [03:24<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  96%|█████████▋| 2078/2154 [03:25<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2079/2154 [03:25<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2080/2154 [03:25<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2081/2154 [03:25<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2082/2154 [03:25<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2083/2154 [03:25<00:07, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2084/2154 [03:25<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2085/2154 [03:25<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2087/2154 [03:25<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2088/2154 [03:26<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2089/2154 [03:26<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2090/2154 [03:26<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2091/2154 [03:26<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2092/2154 [03:26<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2093/2154 [03:26<00:06, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2095/2154 [03:26<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2096/2154 [03:26<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2097/2154 [03:26<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2098/2154 [03:27<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2099/2154 [03:27<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  97%|█████████▋| 2100/2154 [03:27<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2101/2154 [03:27<00:05, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2102/2154 [03:27<00:05, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2103/2154 [03:27<00:05, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2104/2154 [03:27<00:04, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2105/2154 [03:27<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2106/2154 [03:27<00:04, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2107/2154 [03:27<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2108/2154 [03:27<00:04, 10.13it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2109/2154 [03:28<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2110/2154 [03:28<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2111/2154 [03:28<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2112/2154 [03:28<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2113/2154 [03:28<00:04, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2114/2154 [03:28<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2115/2154 [03:28<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2116/2154 [03:28<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2117/2154 [03:28<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2118/2154 [03:28<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2119/2154 [03:29<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2120/2154 [03:29<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  98%|█████████▊| 2121/2154 [03:29<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▊| 2122/2154 [03:29<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▊| 2123/2154 [03:29<00:03, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▊| 2124/2154 [03:29<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▊| 2125/2154 [03:29<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▊| 2126/2154 [03:29<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▊| 2127/2154 [03:29<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2128/2154 [03:29<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2129/2154 [03:29<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2130/2154 [03:30<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2131/2154 [03:30<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2132/2154 [03:30<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2133/2154 [03:30<00:02, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2134/2154 [03:30<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2135/2154 [03:30<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2136/2154 [03:30<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2137/2154 [03:30<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2138/2154 [03:30<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2139/2154 [03:30<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2140/2154 [03:31<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2141/2154 [03:31<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2142/2154 [03:31<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76:  99%|█████████▉| 2143/2154 [03:31<00:01, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2144/2154 [03:31<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2145/2154 [03:31<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2146/2154 [03:31<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2147/2154 [03:31<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2148/2154 [03:31<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2149/2154 [03:31<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2150/2154 [03:32<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2151/2154 [03:32<00:00, 10.14it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2152/2154 [03:32<00:00, 10.15it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|█████████▉| 2153/2154 [03:32<00:00, 10.15it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.104, train_loss_epoch=0.0837]\n",
      "Epoch 76: 100%|██████████| 2154/2154 [03:32<00:00, 10.15it/s, loss=0.0802, v_num=0, train_loss_step=0.0877, val_loss=0.0984, train_loss_epoch=0.0837]\n",
      "Epoch 77:  94%|█████████▍| 2025/2154 [03:18<00:12, 10.19it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  94%|█████████▍| 2026/2154 [03:19<00:12, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2027/2154 [03:19<00:12, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2028/2154 [03:19<00:12, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2029/2154 [03:19<00:12, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2030/2154 [03:19<00:12, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2031/2154 [03:19<00:12, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2032/2154 [03:19<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2033/2154 [03:19<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2034/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  94%|█████████▍| 2035/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2036/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2037/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2038/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2039/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2040/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2041/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2042/2154 [03:20<00:11, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2043/2154 [03:20<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2044/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2045/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▍| 2046/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2047/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2048/2154 [03:21<00:10, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2049/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2050/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2051/2154 [03:21<00:10, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2052/2154 [03:21<00:10, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2053/2154 [03:21<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2054/2154 [03:22<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2055/2154 [03:22<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2056/2154 [03:22<00:09, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  95%|█████████▌| 2057/2154 [03:22<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2058/2154 [03:22<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2059/2154 [03:22<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2060/2154 [03:22<00:09, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2061/2154 [03:22<00:09, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2062/2154 [03:22<00:09, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2063/2154 [03:22<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2064/2154 [03:23<00:08, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2065/2154 [03:23<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2066/2154 [03:23<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2067/2154 [03:23<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2068/2154 [03:23<00:08, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2069/2154 [03:23<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2070/2154 [03:23<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2071/2154 [03:23<00:08, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2072/2154 [03:23<00:08, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▌| 2073/2154 [03:23<00:07, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▋| 2074/2154 [03:24<00:07, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▋| 2075/2154 [03:24<00:07, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▋| 2076/2154 [03:24<00:07, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▋| 2077/2154 [03:24<00:07, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  96%|█████████▋| 2078/2154 [03:24<00:07, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2079/2154 [03:24<00:07, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2080/2154 [03:24<00:07, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2081/2154 [03:24<00:07, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2082/2154 [03:24<00:07, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2083/2154 [03:24<00:06, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2084/2154 [03:25<00:06, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2085/2154 [03:25<00:06, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2086/2154 [03:25<00:06, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2087/2154 [03:25<00:06, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2088/2154 [03:25<00:06, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2089/2154 [03:25<00:06, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2090/2154 [03:25<00:06, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2091/2154 [03:25<00:06, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2092/2154 [03:25<00:06, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2093/2154 [03:25<00:06, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2094/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2095/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2096/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2097/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2098/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2099/2154 [03:26<00:05, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  97%|█████████▋| 2100/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2101/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2102/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2103/2154 [03:26<00:05, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2104/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2105/2154 [03:27<00:04, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2106/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2107/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2108/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2109/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2110/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2111/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2112/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2113/2154 [03:27<00:04, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2114/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2115/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2116/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2117/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2118/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2119/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2120/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  98%|█████████▊| 2121/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▊| 2122/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▊| 2123/2154 [03:28<00:03, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▊| 2124/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▊| 2125/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▊| 2126/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▊| 2127/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2128/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2129/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2130/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2131/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2132/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2133/2154 [03:29<00:02, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2134/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2135/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2136/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2137/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2138/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2139/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2140/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2141/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2142/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77:  99%|█████████▉| 2143/2154 [03:30<00:01, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2144/2154 [03:30<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2145/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2146/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2147/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2148/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2149/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2150/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2151/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2152/2154 [03:31<00:00, 10.16it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|█████████▉| 2153/2154 [03:31<00:00, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.0984, train_loss_epoch=0.0833]\n",
      "Epoch 77: 100%|██████████| 2154/2154 [03:31<00:00, 10.17it/s, loss=0.0733, v_num=0, train_loss_step=0.0834, val_loss=0.099, train_loss_epoch=0.0833] \n",
      "Epoch 78:  94%|█████████▍| 2025/2154 [03:17<00:12, 10.25it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  94%|█████████▍| 2026/2154 [03:18<00:12, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2027/2154 [03:18<00:12, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2028/2154 [03:18<00:12, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2029/2154 [03:18<00:12, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2030/2154 [03:18<00:12, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2031/2154 [03:18<00:12, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2032/2154 [03:18<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2033/2154 [03:18<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2034/2154 [03:18<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  94%|█████████▍| 2035/2154 [03:18<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2036/2154 [03:19<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2037/2154 [03:19<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2038/2154 [03:19<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2039/2154 [03:19<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2040/2154 [03:19<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2041/2154 [03:19<00:11, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2042/2154 [03:19<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2043/2154 [03:19<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2044/2154 [03:19<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2045/2154 [03:19<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▍| 2046/2154 [03:20<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2047/2154 [03:20<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2048/2154 [03:20<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2049/2154 [03:20<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2050/2154 [03:20<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2051/2154 [03:20<00:10, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2052/2154 [03:20<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2053/2154 [03:20<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2054/2154 [03:20<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2055/2154 [03:20<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2056/2154 [03:20<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  95%|█████████▌| 2057/2154 [03:21<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2058/2154 [03:21<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2059/2154 [03:21<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2060/2154 [03:21<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2061/2154 [03:21<00:09, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2062/2154 [03:21<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2063/2154 [03:21<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2064/2154 [03:21<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2065/2154 [03:21<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2066/2154 [03:21<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2067/2154 [03:21<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2068/2154 [03:22<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2069/2154 [03:22<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2070/2154 [03:22<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2071/2154 [03:22<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2072/2154 [03:22<00:08, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▌| 2073/2154 [03:22<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▋| 2074/2154 [03:22<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▋| 2075/2154 [03:22<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▋| 2076/2154 [03:22<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▋| 2077/2154 [03:22<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  96%|█████████▋| 2078/2154 [03:23<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2079/2154 [03:23<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2080/2154 [03:23<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2081/2154 [03:23<00:07, 10.24it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2082/2154 [03:23<00:07, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2083/2154 [03:23<00:06, 10.24it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2084/2154 [03:23<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2085/2154 [03:23<00:06, 10.24it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2086/2154 [03:23<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2087/2154 [03:23<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2088/2154 [03:24<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2089/2154 [03:24<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2090/2154 [03:24<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2091/2154 [03:24<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2092/2154 [03:24<00:06, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2093/2154 [03:24<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2094/2154 [03:24<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2095/2154 [03:24<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2096/2154 [03:24<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2097/2154 [03:24<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2098/2154 [03:25<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2099/2154 [03:25<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  97%|█████████▋| 2100/2154 [03:25<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2101/2154 [03:25<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2102/2154 [03:25<00:05, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2103/2154 [03:25<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2104/2154 [03:25<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2105/2154 [03:25<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2106/2154 [03:25<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2107/2154 [03:25<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2108/2154 [03:26<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2109/2154 [03:26<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2110/2154 [03:26<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2111/2154 [03:26<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2112/2154 [03:26<00:04, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2113/2154 [03:26<00:04, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2114/2154 [03:26<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2115/2154 [03:26<00:03, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2116/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2117/2154 [03:27<00:03, 10.23it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2118/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2119/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2120/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  98%|█████████▊| 2121/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▊| 2122/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▊| 2123/2154 [03:27<00:03, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▊| 2124/2154 [03:27<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▊| 2125/2154 [03:27<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▊| 2126/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▊| 2127/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2128/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2129/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2130/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2131/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2132/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2133/2154 [03:28<00:02, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2134/2154 [03:28<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2135/2154 [03:28<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2136/2154 [03:29<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2137/2154 [03:29<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2138/2154 [03:29<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2139/2154 [03:29<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2140/2154 [03:29<00:01, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2141/2154 [03:29<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2142/2154 [03:29<00:01, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78:  99%|█████████▉| 2143/2154 [03:29<00:01, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2144/2154 [03:29<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2145/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2146/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2147/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2148/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2149/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2150/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2151/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2152/2154 [03:30<00:00, 10.21it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|█████████▉| 2153/2154 [03:30<00:00, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.099, train_loss_epoch=0.0844]\n",
      "Epoch 78: 100%|██████████| 2154/2154 [03:30<00:00, 10.22it/s, loss=0.0817, v_num=0, train_loss_step=0.120, val_loss=0.105, train_loss_epoch=0.0844]\n",
      "Epoch 79:  94%|█████████▍| 2025/2154 [03:23<00:12,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  94%|█████████▍| 2026/2154 [03:24<00:12,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2027/2154 [03:24<00:12,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2028/2154 [03:24<00:12,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2029/2154 [03:24<00:12,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2030/2154 [03:24<00:12,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2031/2154 [03:24<00:12,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2032/2154 [03:24<00:12,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2033/2154 [03:24<00:12,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2034/2154 [03:24<00:12,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  94%|█████████▍| 2035/2154 [03:24<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2036/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2037/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2038/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2039/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2040/2154 [03:25<00:11,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2041/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2042/2154 [03:25<00:11,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2043/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2044/2154 [03:25<00:11,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2045/2154 [03:25<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▍| 2046/2154 [03:26<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2047/2154 [03:26<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2048/2154 [03:26<00:10,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2049/2154 [03:26<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2050/2154 [03:26<00:10,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2051/2154 [03:26<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2052/2154 [03:26<00:10,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2053/2154 [03:26<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2054/2154 [03:26<00:10,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2055/2154 [03:26<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2056/2154 [03:27<00:09,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  95%|█████████▌| 2057/2154 [03:27<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2058/2154 [03:27<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2059/2154 [03:27<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2060/2154 [03:27<00:09,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2061/2154 [03:27<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2062/2154 [03:27<00:09,  9.92it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2063/2154 [03:27<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2064/2154 [03:27<00:09,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2065/2154 [03:27<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2066/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2067/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2068/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2069/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2070/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2071/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2072/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▌| 2073/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▋| 2074/2154 [03:28<00:08,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▋| 2075/2154 [03:28<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▋| 2076/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▋| 2077/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  96%|█████████▋| 2078/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2079/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2080/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2081/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2082/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2083/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2084/2154 [03:29<00:07,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2085/2154 [03:29<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2086/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2087/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2088/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2089/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2090/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2091/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2092/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2093/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2094/2154 [03:30<00:06,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2095/2154 [03:30<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2096/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2097/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2098/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2099/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  97%|█████████▋| 2100/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2101/2154 [03:31<00:05,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2102/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2103/2154 [03:31<00:05,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2104/2154 [03:31<00:05,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2105/2154 [03:31<00:04,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2106/2154 [03:32<00:04,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2107/2154 [03:32<00:04,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2108/2154 [03:32<00:04,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2109/2154 [03:32<00:04,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2110/2154 [03:32<00:04,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2111/2154 [03:32<00:04,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2112/2154 [03:32<00:04,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2113/2154 [03:32<00:04,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2114/2154 [03:32<00:04,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2115/2154 [03:32<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2116/2154 [03:32<00:03,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2117/2154 [03:33<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2118/2154 [03:33<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2119/2154 [03:33<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2120/2154 [03:33<00:03,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  98%|█████████▊| 2121/2154 [03:33<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▊| 2122/2154 [03:33<00:03,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▊| 2123/2154 [03:33<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▊| 2124/2154 [03:33<00:03,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▊| 2125/2154 [03:33<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▊| 2126/2154 [03:33<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▊| 2127/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2128/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2129/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2130/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2131/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2132/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2133/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2134/2154 [03:34<00:02,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2135/2154 [03:34<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2136/2154 [03:34<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2137/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2138/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2139/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2140/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2141/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2142/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79:  99%|█████████▉| 2143/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2144/2154 [03:35<00:01,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2145/2154 [03:35<00:00,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2146/2154 [03:36<00:00,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2147/2154 [03:36<00:00,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2148/2154 [03:36<00:00,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2149/2154 [03:36<00:00,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2150/2154 [03:36<00:00,  9.93it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2151/2154 [03:36<00:00,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2152/2154 [03:36<00:00,  9.94it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|█████████▉| 2153/2154 [03:36<00:00,  9.95it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.105, train_loss_epoch=0.0817]\n",
      "Epoch 79: 100%|██████████| 2154/2154 [03:36<00:00,  9.95it/s, loss=0.0848, v_num=0, train_loss_step=0.133, val_loss=0.0987, train_loss_epoch=0.0817]\n",
      "Epoch 80:  94%|█████████▍| 2025/2154 [03:21<00:12, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/129 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  94%|█████████▍| 2026/2154 [03:22<00:12, 10.02it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2027/2154 [03:22<00:12, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2028/2154 [03:22<00:12, 10.02it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2029/2154 [03:22<00:12, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2030/2154 [03:22<00:12, 10.02it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2031/2154 [03:22<00:12, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2032/2154 [03:22<00:12, 10.02it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2033/2154 [03:22<00:12, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2034/2154 [03:22<00:11, 10.02it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  94%|█████████▍| 2035/2154 [03:22<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2036/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2037/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2038/2154 [03:23<00:11, 10.02it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2039/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2040/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2041/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2042/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2043/2154 [03:23<00:11, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2044/2154 [03:23<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2045/2154 [03:23<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▍| 2046/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2047/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2048/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2049/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2050/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2051/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2052/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2053/2154 [03:24<00:10, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2054/2154 [03:24<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2055/2154 [03:24<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2056/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  95%|█████████▌| 2057/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2058/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2059/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2060/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2061/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2062/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2063/2154 [03:25<00:09, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2064/2154 [03:25<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2065/2154 [03:25<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2066/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2067/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2068/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2069/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2070/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2071/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2072/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▌| 2073/2154 [03:26<00:08, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▋| 2074/2154 [03:26<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▋| 2075/2154 [03:26<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▋| 2076/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▋| 2077/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  96%|█████████▋| 2078/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2079/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2080/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2081/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2082/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2083/2154 [03:27<00:07, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2084/2154 [03:27<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2085/2154 [03:27<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2086/2154 [03:27<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2087/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2088/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2089/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2090/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2091/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2092/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2093/2154 [03:28<00:06, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2094/2154 [03:28<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2095/2154 [03:28<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2096/2154 [03:28<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2097/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2098/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2099/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  97%|█████████▋| 2100/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2101/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2102/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2103/2154 [03:29<00:05, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2104/2154 [03:29<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2105/2154 [03:29<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2106/2154 [03:29<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2107/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2108/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2109/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2110/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2111/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2112/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2113/2154 [03:30<00:04, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2114/2154 [03:30<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2115/2154 [03:30<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2116/2154 [03:30<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2117/2154 [03:30<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2118/2154 [03:31<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2119/2154 [03:31<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2120/2154 [03:31<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  98%|█████████▊| 2121/2154 [03:31<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▊| 2122/2154 [03:31<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▊| 2123/2154 [03:31<00:03, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▊| 2124/2154 [03:31<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▊| 2125/2154 [03:31<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▊| 2126/2154 [03:31<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▊| 2127/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2128/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2129/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2130/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2131/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2132/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2133/2154 [03:32<00:02, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2134/2154 [03:32<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2135/2154 [03:32<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2136/2154 [03:32<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2137/2154 [03:32<00:01, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2138/2154 [03:33<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2139/2154 [03:33<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2140/2154 [03:33<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2141/2154 [03:33<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2142/2154 [03:33<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80:  99%|█████████▉| 2143/2154 [03:33<00:01, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2144/2154 [03:33<00:00, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2145/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2146/2154 [03:33<00:00, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2147/2154 [03:33<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2148/2154 [03:34<00:00, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2149/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2150/2154 [03:34<00:00, 10.03it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2151/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2152/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|█████████▉| 2153/2154 [03:34<00:00, 10.04it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0987, train_loss_epoch=0.083]\n",
      "Epoch 80: 100%|██████████| 2154/2154 [03:34<00:00, 10.05it/s, loss=0.0805, v_num=0, train_loss_step=0.0772, val_loss=0.0974, train_loss_epoch=0.083]\n",
      "Epoch 81:  45%|████▍     | 967/2154 [01:34<01:56, 10.20it/s, loss=0.0829, v_num=0, train_loss_step=0.097, val_loss=0.0974, train_loss_epoch=0.0823]  "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "logger = TensorBoardLogger('/tf_logs', name=f\"FCNN: batch_size={batch_size}, encoder_length={encoder_length}, \\\n",
    "                            group={group}, \\\n",
    "                            known_reals={known_reals}, \\\n",
    "                            hidden_size={hidden_size}, n_hidden_layers={n_hidden_layers}\")\n",
    "\n",
    "# trainer = Trainer(gpus=1, max_epochs=100, limit_train_batches=2606, logger=logger)\n",
    "trainer = Trainer(accelerator='gpu', devices=1, logger=logger, max_epochs=100)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "# trainer.validate(model=model, dataloaders=valid_dataloaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "# best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "# best_tft = FullyConnectedModelWithCovariates.load_from_checkpoint(best_model_path)\n",
    "trainer.save_checkpoint(\"fc_best_model.ckpt\")\n",
    "best_tft = FullyConnectedModelWithCovariates.load_from_checkpoint(\"fc_best_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(valid_dataloader)])\n",
    "predictions = best_tft.predict(valid_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(actuals), actuals.shape, type(predictions), predictions.shape)\n",
    "print(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = [X for X in range(0, actuals.shape[0])]\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(20,5))\n",
    "\n",
    "ax1.plot(X, actuals, color='b', label=\"Actual\")\n",
    "ax1.plot(X, predictions, color='r', label=\"Predicted\")\n",
    "\n",
    "files = os.path.join(home_dir, f'FCNN.png')\n",
    "plt.savefig(files, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm65lJFvnnLs",
    "outputId": "ffd88daa-bbd8-4b3a-c1f8-e693f3ffece0"
   },
   "outputs": [],
   "source": [
    "max_prediction_length = 3\n",
    "max_encoder_length = 8\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "# print(training_cutoff)\n",
    "# x = data[lambda x: x.time_idx <= training_cutoff]\n",
    "# print()\n",
    "\n",
    "bins_name = list([\"yield\"])\n",
    "for bin in range(0, 512):\n",
    "  bins_name.append(f'bin{bin}')\n",
    "\n",
    "print(bins_name)\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx = \"time_idx\",\n",
    "    target = \"yield\",\n",
    "    group_ids = [\"county\", \"bands\", \"time\"],\n",
    "    min_encoder_length = max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length = max_encoder_length,\n",
    "    min_prediction_length = 1,\n",
    "    max_prediction_length = max_prediction_length,\n",
    "    # static_categoricals = [\"county\"],\n",
    "    # static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    # time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    # variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    # time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    # time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals = bins_name,\n",
    "    allow_missing_timesteps = True,\n",
    "    # target_normalizer=GroupNormalizer(\n",
    "    #     groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    # ),  # use softplus and normalize by group\n",
    "    # add_relative_time_idx = True,\n",
    "    # add_target_scales = True,\n",
    "    # add_encoder_length = True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 1  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train =  True, batch_size = batch_size, num_workers = 0)\n",
    "val_dataloader = validation.to_dataloader(train = False, batch_size = batch_size, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gThPXEaensCI",
    "outputId": "45c75a22-e2c8-4538-f11e-eaf1aea74050"
   },
   "outputs": [],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(valid_dataloader)])\n",
    "baseline_predictions = Baseline().predict(valid_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BR2PH1m8opGv"
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "# pl.seed_everything(42)\n",
    "# trainer = pl.Trainer(\n",
    "#     gpus=0,\n",
    "#     # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "#     # of the gradient for recurrent neural networks\n",
    "#     gradient_clip_val=0.1,\n",
    "#     auto_lr_find = True,\n",
    "# )\n",
    "\n",
    "\n",
    "# tft = TemporalFusionTransformer.from_dataset(\n",
    "#     training,\n",
    "#     # not meaningful for finding the learning rate but otherwise very important\n",
    "#     learning_rate=0.03,\n",
    "#     hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "#     # number of attention heads. Set to up to 4 for large datasets\n",
    "#     attention_head_size=1,\n",
    "#     dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "#     hidden_continuous_size=8,  # set to <= hidden_size\n",
    "#     output_size=1,  # 7 quantiles by default\n",
    "#     loss=QuantileLoss(),\n",
    "#     # reduce learning rate if no improvement in validation loss after x epochs\n",
    "#     reduce_on_plateau_patience=4,\n",
    "# )\n",
    "# print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQexRoPJopqa"
   },
   "outputs": [],
   "source": [
    "# # find optimal learning rate\n",
    "# res = trainer.tuner.lr_find(\n",
    "#     tft,\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "#     max_lr=10.0,\n",
    "#     min_lr=1e-6,\n",
    "# )\n",
    "\n",
    "# # res = trainer.tuner.lr_find(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader,)\n",
    "\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8ohrZoqosSX",
    "outputId": "4f54da2d-924c-4403-93ee-6ce56f78cc4c"
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    gpus=0,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=1,  # 7 quantiles by default\n",
    "    loss=MAPE(),  #QuantileLoss(), #MAPE(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zcFzxHVrVQ-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorboard as tb \n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939,
     "referenced_widgets": [
      "14d07476dd484e5e8a7bca7bf59ceae5",
      "c56fd12d72db4e4caf6d5ef0ade8b9f8",
      "fa10f2402f224290815d92ee89213162",
      "daf65e7e84e34266929b680250bc7a46",
      "ba34c1e6d0cb4b03870cb4aef1b6c32c",
      "cdd9d4ddccdc4e06a76aafddce2701f0",
      "ae9c80f166694da09e56af90999a7c6b",
      "5eeae71bc8384c98921f6ead0351b047",
      "74f31ab6b038471ca73833d340ba5606",
      "88d278124f704f90a67d37da11072342",
      "325556a59ba44f10bea30d875b032bcd"
     ]
    },
    "id": "L3O1F_Joo0YG",
    "outputId": "a2851582-3695-4376-9460-bdf095cbcd12"
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyhBzIoi5cqP"
   },
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtZA-Mom5gaW"
   },
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXtVdTBs5jZP"
   },
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoYevMoT5wGA"
   },
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQT6Kxwl53gu"
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cufHwzV8pLiR"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08YeXDvqo3ZE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14d07476dd484e5e8a7bca7bf59ceae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c56fd12d72db4e4caf6d5ef0ade8b9f8",
       "IPY_MODEL_fa10f2402f224290815d92ee89213162",
       "IPY_MODEL_daf65e7e84e34266929b680250bc7a46"
      ],
      "layout": "IPY_MODEL_ba34c1e6d0cb4b03870cb4aef1b6c32c"
     }
    },
    "325556a59ba44f10bea30d875b032bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eeae71bc8384c98921f6ead0351b047": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74f31ab6b038471ca73833d340ba5606": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88d278124f704f90a67d37da11072342": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae9c80f166694da09e56af90999a7c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba34c1e6d0cb4b03870cb4aef1b6c32c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "c56fd12d72db4e4caf6d5ef0ade8b9f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdd9d4ddccdc4e06a76aafddce2701f0",
      "placeholder": "​",
      "style": "IPY_MODEL_ae9c80f166694da09e56af90999a7c6b",
      "value": "Sanity Checking DataLoader 0:   0%"
     }
    },
    "cdd9d4ddccdc4e06a76aafddce2701f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daf65e7e84e34266929b680250bc7a46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88d278124f704f90a67d37da11072342",
      "placeholder": "​",
      "style": "IPY_MODEL_325556a59ba44f10bea30d875b032bcd",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "fa10f2402f224290815d92ee89213162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eeae71bc8384c98921f6ead0351b047",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74f31ab6b038471ca73833d340ba5606",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
