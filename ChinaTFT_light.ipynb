{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvpNHOs_nTQK",
    "outputId": "58e5e73c-d790-40a6-a1dc-1f6638a75f55"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')\n",
    "\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDXvdYFuLYSI",
    "outputId": "db9c1dcc-d2d2-450c-bab9-29f775f571d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hy-tmp\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "home_dir = '/content/gdrive/My Drive/AChina' \n",
    "home_dir = '/hy-tmp'\n",
    "os.chdir(home_dir)\n",
    "!pwd\n",
    "\n",
    "!pip install tqdm \n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WPwRIbsMnaq8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "# os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYbhRWaxneDl",
    "outputId": "c79dccdb-c661-4f1c-ca13-a14d7bd2c1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.22.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.0+cu113)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (1.8.6)\n",
      "Requirement already satisfied: pytorch_forecasting in /usr/local/lib/python3.8/dist-packages (0.10.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.4.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2.5.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.22.3)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.24 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (1.1.1)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (0.13.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (3.5.2)\n",
      "Requirement already satisfied: optuna<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (2.10.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (1.4.3)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.8/dist-packages (from pytorch_forecasting) (1.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.9.0)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.1.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.4.45)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (6.7.0)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.8/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=0.24->pytorch_forecasting) (3.1.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (4.34.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pytorch_forecasting) (0.11.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pytorch_forecasting) (0.5.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.2->statsmodels->pytorch_forecasting) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.12.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.2.4)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (5.8.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (4.1.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.4.2)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (3.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (3.8.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (5.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch_forecasting) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision\n",
    "# !pip install pytorch_lightning\n",
    "# !pip install pytorch_forecasting\n",
    "\n",
    "# !pip install torch -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install pytorch-forecasting\n",
    "\n",
    "!pip install scipy\n",
    "!pip install torch pytorch-lightning pytorch_forecasting\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAPE, SMAPE, PoissonLoss, QuantileLoss\n",
    "# from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "65_fJ6MIbncZ",
    "outputId": "06e9c0ab-8d58-480b-86d1-4ca275159e4a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('corn_china_pandas_onebands.csv')  # encoding= 'unicode_escape')\n",
    "\n",
    "data[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOncsJYonfF_"
   },
   "outputs": [],
   "source": [
    "# years = [x for x in range(2003, 2019)]\n",
    "\n",
    "# data.rename(columns={'time_idx' : 'time'}, inplace=True)  \n",
    "\n",
    "# # data[5:15]  \n",
    "# data.insert(1, \"time_idx\", data['years'])  \n",
    "# # df = data.assign(time_dx = data.time * 10)\n",
    "\n",
    "# time_idx = 0\n",
    "# for year in years:\n",
    "#     data['time_idx'] = data['time_idx'].replace([year], time_idx)\n",
    "#     time_idx = time_idx + 1\n",
    "    \n",
    "# data['years'] = data['years'].astype(str)\n",
    "# data['county'] = data['county'].astype(str)\n",
    "# data['time'] = data['time'].astype(str)\n",
    "\n",
    "# dff = data[ data['years'] == '2018' ]\n",
    "# dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "F-uXD_srqwLW",
    "outputId": "8a8a0424-2e67-4dd2-be62-b6b0bf46bfc3"
   },
   "outputs": [],
   "source": [
    "data['years'] = data['years'].astype(str)\n",
    "data['county'] = data['county'].astype(str)\n",
    "data['time_idx'] = data['time_idx'].astype(np.int64)\n",
    "# data.head()\n",
    "print(type(data['band_0_500'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "LL4gooLRnkdv",
    "outputId": "cb1d012b-c336-4683-d2d9-f454d61c1cb1"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "from pytorch_forecasting.metrics import MAE, RMSE\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "train_data = data[ data[\"years\"] != \"2018\" ]\n",
    "valid_data = data[ data[\"years\"] == \"2018\" ]\n",
    "\n",
    "bins_name = list()   #list([\"yield\"])\n",
    "for bin in range(0, 512):\n",
    "    bins_name.append(f'bin{bin}')\n",
    "\n",
    "# print(bins_name)\n",
    "\n",
    "bins_name = list()\n",
    "for band in tqdm(range(0, 9)):\n",
    "    for bins in range(0, 512):\n",
    "        bins_name.append( f'band_{band}_{bins}' )\n",
    "\n",
    "encoder_length = 20\n",
    "group=[\"years\", \"county\"]\n",
    "unknown_categoricals=[\"years\", \"county\", \"bands\"]\n",
    "static_categoricals=[\"years\", \"county\"]\n",
    "known_reals=[\"sownareas\"]\n",
    "\n",
    "train_dataset_with_covariates = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    group_ids=group,\n",
    "    target=\"yield\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=encoder_length,\n",
    "    max_encoder_length=encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=1,\n",
    "    time_varying_unknown_reals=bins_name,  #[\"yield\"],\n",
    "    # time_varying_unknown_categoricals=[\"county\", \"bands\"],\n",
    "    # time_varying_known_reals=known_reals,\n",
    "    # time_varying_known_categoricals=[\"years\"],\n",
    "    # static_categoricals=[\"years\", \"county\"],\n",
    ")\n",
    "\n",
    "valid_dataset_with_covariates = TimeSeriesDataSet(\n",
    "    valid_data,\n",
    "    group_ids=group,\n",
    "    target=\"yield\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=encoder_length,\n",
    "    max_encoder_length=encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=1,\n",
    "    time_varying_unknown_reals=bins_name,   #[\"yield\"],\n",
    "    # time_varying_unknown_categoricals=[\"county\", \"bands\"],\n",
    "    # time_varying_known_reals=known_reals,\n",
    "    # time_varying_known_categoricals=[\"years\"],\n",
    "    # static_categoricals=[\"years\", \"county\"],\n",
    ")\n",
    "\n",
    "model = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset_with_covariates,\n",
    "    # learning_rate=0.03,\n",
    "    # hidden_size=16,\n",
    "    # attention_head_size=4,\n",
    "    # dropout=0.1,\n",
    "    # hidden_continuous_size=8,\n",
    "    # output_size=1,  # 7 quantiles by default\n",
    "    loss=MAE()+RMSE(),\n",
    "    # log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    # reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# summarize(model,max_depth=-1)  # print model summary\n",
    "# model.hparams\n",
    "\n",
    "# fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import MAE\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "    \n",
    "# convert datasets to dataloaders for training\n",
    "batch_size = 48\n",
    "train_dataloader = train_dataset_with_covariates.to_dataloader(train=True,  batch_size=batch_size, num_workers=2)\n",
    "valid_dataloader = valid_dataset_with_covariates.to_dataloader(train=False, batch_size=batch_size, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset to a dataloader\n",
    "# dataloader = dataset.to_dataloader(batch_size=4)\n",
    "\n",
    "# and load the first batch\n",
    "x, y = next(iter(valid_dataloader))\n",
    "# print(\"x =\", x)\n",
    "# print(\"\\ny =\", y)\n",
    "# print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger_name = f\"TFT: batch_size={batch_size}, encoder_length={encoder_length}, group={group}, known_reals={known_reals}, loss=MAE\"\n",
    "\n",
    "logger = TensorBoardLogger('/tf_logs', name=logger_name)\n",
    "\n",
    "# trainer = Trainer(gpus=1, max_epochs=100, limit_train_batches=2606, logger=logger)\n",
    "trainer = Trainer(accelerator='gpu', devices=1, logger=logger, max_epochs=35)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "# trainer.validate(model=model, dataloaders=valid_dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "# best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "# best_tft = FullyConnectedModelWithCovariates.load_from_checkpoint(best_model_path)\n",
    "trainer.save_checkpoint(\"tft1_best_model.ckpt\")\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(\"tft1_best_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(valid_dataloader)])\n",
    "predictions = best_tft.predict(valid_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(actuals), actuals.shape, type(predictions), predictions.shape)\n",
    "print(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = [X for X in range(0, actuals.shape[0])]\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(20,5))\n",
    "\n",
    "ax1.plot(X, actuals, color='b', label=\"Actual\")\n",
    "ax1.plot(X, predictions, color='r', label=\"Predicted\")\n",
    "ax1.set_title(logger_name)\n",
    "\n",
    "files = os.path.join(home_dir, f'TFT.png')\n",
    "plt.savefig(files, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm65lJFvnnLs",
    "outputId": "ffd88daa-bbd8-4b3a-c1f8-e693f3ffece0"
   },
   "outputs": [],
   "source": [
    "max_prediction_length = 3\n",
    "max_encoder_length = 8\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "# print(training_cutoff)\n",
    "# x = data[lambda x: x.time_idx <= training_cutoff]\n",
    "# print()\n",
    "\n",
    "bins_name = list([\"yield\"])\n",
    "for bin in range(0, 512):\n",
    "  bins_name.append(f'bin{bin}')\n",
    "\n",
    "print(bins_name)\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx = \"time_idx\",\n",
    "    target = \"yield\",\n",
    "    group_ids = [\"county\", \"bands\", \"time\"],\n",
    "    min_encoder_length = max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length = max_encoder_length,\n",
    "    min_prediction_length = 1,\n",
    "    max_prediction_length = max_prediction_length,\n",
    "    # static_categoricals = [\"county\"],\n",
    "    # static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    # time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    # variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    # time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    # time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals = bins_name,\n",
    "    allow_missing_timesteps = True,\n",
    "    # target_normalizer=GroupNormalizer(\n",
    "    #     groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    # ),  # use softplus and normalize by group\n",
    "    # add_relative_time_idx = True,\n",
    "    # add_target_scales = True,\n",
    "    # add_encoder_length = True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 1  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train =  True, batch_size = batch_size, num_workers = 0)\n",
    "val_dataloader = validation.to_dataloader(train = False, batch_size = batch_size, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gThPXEaensCI",
    "outputId": "45c75a22-e2c8-4538-f11e-eaf1aea74050"
   },
   "outputs": [],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(valid_dataloader)])\n",
    "baseline_predictions = Baseline().predict(valid_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BR2PH1m8opGv"
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "# pl.seed_everything(42)\n",
    "# trainer = pl.Trainer(\n",
    "#     gpus=0,\n",
    "#     # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "#     # of the gradient for recurrent neural networks\n",
    "#     gradient_clip_val=0.1,\n",
    "#     auto_lr_find = True,\n",
    "# )\n",
    "\n",
    "\n",
    "# tft = TemporalFusionTransformer.from_dataset(\n",
    "#     training,\n",
    "#     # not meaningful for finding the learning rate but otherwise very important\n",
    "#     learning_rate=0.03,\n",
    "#     hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "#     # number of attention heads. Set to up to 4 for large datasets\n",
    "#     attention_head_size=1,\n",
    "#     dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "#     hidden_continuous_size=8,  # set to <= hidden_size\n",
    "#     output_size=1,  # 7 quantiles by default\n",
    "#     loss=QuantileLoss(),\n",
    "#     # reduce learning rate if no improvement in validation loss after x epochs\n",
    "#     reduce_on_plateau_patience=4,\n",
    "# )\n",
    "# print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQexRoPJopqa"
   },
   "outputs": [],
   "source": [
    "# # find optimal learning rate\n",
    "# res = trainer.tuner.lr_find(\n",
    "#     tft,\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "#     max_lr=10.0,\n",
    "#     min_lr=1e-6,\n",
    "# )\n",
    "\n",
    "# # res = trainer.tuner.lr_find(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader,)\n",
    "\n",
    "# print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "# fig = res.plot(show=True, suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8ohrZoqosSX",
    "outputId": "4f54da2d-924c-4403-93ee-6ce56f78cc4c"
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    gpus=0,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=1,  # 7 quantiles by default\n",
    "    loss=MAPE(),  #QuantileLoss(), #MAPE(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zcFzxHVrVQ-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorboard as tb \n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939,
     "referenced_widgets": [
      "14d07476dd484e5e8a7bca7bf59ceae5",
      "c56fd12d72db4e4caf6d5ef0ade8b9f8",
      "fa10f2402f224290815d92ee89213162",
      "daf65e7e84e34266929b680250bc7a46",
      "ba34c1e6d0cb4b03870cb4aef1b6c32c",
      "cdd9d4ddccdc4e06a76aafddce2701f0",
      "ae9c80f166694da09e56af90999a7c6b",
      "5eeae71bc8384c98921f6ead0351b047",
      "74f31ab6b038471ca73833d340ba5606",
      "88d278124f704f90a67d37da11072342",
      "325556a59ba44f10bea30d875b032bcd"
     ]
    },
    "id": "L3O1F_Joo0YG",
    "outputId": "a2851582-3695-4376-9460-bdf095cbcd12"
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyhBzIoi5cqP"
   },
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtZA-Mom5gaW"
   },
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXtVdTBs5jZP"
   },
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoYevMoT5wGA"
   },
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQT6Kxwl53gu"
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cufHwzV8pLiR"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08YeXDvqo3ZE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14d07476dd484e5e8a7bca7bf59ceae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c56fd12d72db4e4caf6d5ef0ade8b9f8",
       "IPY_MODEL_fa10f2402f224290815d92ee89213162",
       "IPY_MODEL_daf65e7e84e34266929b680250bc7a46"
      ],
      "layout": "IPY_MODEL_ba34c1e6d0cb4b03870cb4aef1b6c32c"
     }
    },
    "325556a59ba44f10bea30d875b032bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eeae71bc8384c98921f6ead0351b047": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74f31ab6b038471ca73833d340ba5606": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88d278124f704f90a67d37da11072342": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae9c80f166694da09e56af90999a7c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba34c1e6d0cb4b03870cb4aef1b6c32c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "c56fd12d72db4e4caf6d5ef0ade8b9f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdd9d4ddccdc4e06a76aafddce2701f0",
      "placeholder": "​",
      "style": "IPY_MODEL_ae9c80f166694da09e56af90999a7c6b",
      "value": "Sanity Checking DataLoader 0:   0%"
     }
    },
    "cdd9d4ddccdc4e06a76aafddce2701f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daf65e7e84e34266929b680250bc7a46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88d278124f704f90a67d37da11072342",
      "placeholder": "​",
      "style": "IPY_MODEL_325556a59ba44f10bea30d875b032bcd",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "fa10f2402f224290815d92ee89213162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eeae71bc8384c98921f6ead0351b047",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74f31ab6b038471ca73833d340ba5606",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
